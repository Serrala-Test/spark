<p>Spark uses Hadoop client libraries for HDFS and YARN. Starting in version Spark 1.4, the project packages “Hadoop free” builds that lets you more easily connect a single Spark binary to any Hadoop version. To use these builds, you need to modify <code>SPARK_DIST_CLASSPATH</code> to include Hadoop’s package jars. The most convenient place to do this is by adding an entry in <code>conf/spark-env.sh</code>.</p>

<p>This page describes how to connect Spark to Hadoop for different types of distributions.</p>

<h1 id="apache-hadoop">Apache Hadoop</h1>
<p>For Apache distributions, you can use Hadoop’s ‘classpath’ command. For instance:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">### in conf/spark-env.sh ###</span>

<span class="c"># If &#39;hadoop&#39; binary is on your PATH</span>
<span class="nb">export </span><span class="nv">SPARK_DIST_CLASSPATH</span><span class="o">=</span><span class="k">$(</span>hadoop classpath<span class="k">)</span>

<span class="c"># With explicit path to &#39;hadoop&#39; binary</span>
<span class="nb">export </span><span class="nv">SPARK_DIST_CLASSPATH</span><span class="o">=</span><span class="k">$(</span>/path/to/hadoop/bin/hadoop classpath<span class="k">)</span>

<span class="c"># Passing a Hadoop configuration directory</span>
<span class="nb">export </span><span class="nv">SPARK_DIST_CLASSPATH</span><span class="o">=</span><span class="k">$(</span>hadoop --config /path/to/configs classpath<span class="k">)</span></code></pre></div>

