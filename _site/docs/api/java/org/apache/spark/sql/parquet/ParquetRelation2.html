<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_71) on Thu Apr 02 14:27:47 PDT 2015 -->
<title>ParquetRelation2 (Spark 1.4.0 JavaDoc)</title>
<meta name="date" content="2015-04-02">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="ParquetRelation2 (Spark 1.4.0 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation.html" title="class in org.apache.spark.sql.parquet"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/parquet/ParquetRelation2.html" target="_top">Frames</a></li>
<li><a href="ParquetRelation2.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.parquet</div>
<h2 title="Class ParquetRelation2" class="title">Class ParquetRelation2</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">org.apache.spark.sql.sources.BaseRelation</a></li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.parquet.ParquetRelation2</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, <a href="../../../../../org/apache/spark/mapreduce/SparkHadoopMapReduceUtil.html" title="interface in org.apache.spark.mapreduce">SparkHadoopMapReduceUtil</a>, <a href="../../../../../org/apache/spark/sql/sources/CatalystScan.html" title="interface in org.apache.spark.sql.sources">CatalystScan</a>, <a href="../../../../../org/apache/spark/sql/sources/InsertableRelation.html" title="interface in org.apache.spark.sql.sources">InsertableRelation</a>, scala.Equals, scala.Product</dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">ParquetRelation2</span>
extends <a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>
implements <a href="../../../../../org/apache/spark/sql/sources/CatalystScan.html" title="interface in org.apache.spark.sql.sources">CatalystScan</a>, <a href="../../../../../org/apache/spark/sql/sources/InsertableRelation.html" title="interface in org.apache.spark.sql.sources">InsertableRelation</a>, <a href="../../../../../org/apache/spark/mapreduce/SparkHadoopMapReduceUtil.html" title="interface in org.apache.spark.mapreduce">SparkHadoopMapReduceUtil</a>, <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, scala.Product, scala.Serializable</pre>
<div class="block">An alternative to <a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation.html" title="class in org.apache.spark.sql.parquet"><code>ParquetRelation</code></a> that plugs in using the data sources API.  This class is
 intended as a full replacement of the Parquet support in Spark SQL.  The old implementation will
 be deprecated and eventually removed once this version is proved to be stable enough.
 <p>
 Compared with the old implementation, this class has the following notable differences:
 <p>
  - Partitioning discovery: Hive style multi-level partitions are auto discovered.
  - Metadata discovery: Parquet is a format comes with schema evolving support.  This data source
    can detect and merge schemas from all Parquet part-files as long as they are compatible.
    Also, metadata and <code>FileStatus</code>es are cached for better performance.
  - Statistics: Statistics for the size of the table are automatically populated during schema
    discovery.</div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../serialized-form.html#org.apache.spark.sql.parquet.ParquetRelation2">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet">ParquetRelation2.PartitionValues</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues$.html" title="class in org.apache.spark.sql.parquet">ParquetRelation2.PartitionValues$</a></strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#ParquetRelation2(scala.collection.Seq,%20scala.collection.immutable.Map,%20scala.Option,%20scala.Option,%20org.apache.spark.sql.SQLContext)">ParquetRelation2</a></strong>(scala.collection.Seq&lt;String&gt;&nbsp;paths,
                scala.collection.immutable.Map&lt;String,String&gt;&nbsp;parameters,
                scala.Option&lt;org.apache.spark.sql.types.StructType&gt;&nbsp;maybeSchema,
                scala.Option&lt;<a href="../../../../../org/apache/spark/sql/parquet/PartitionSpec.html" title="class in org.apache.spark.sql.parquet">PartitionSpec</a>&gt;&nbsp;maybePartitionSpec,
                <a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.Row&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#buildScan(scala.collection.Seq,%20scala.collection.Seq)">buildScan</a></strong>(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;output,
         scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;predicates)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#DEFAULT_PARTITION_NAME()">DEFAULT_PARTITION_NAME</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#equals(java.lang.Object)">equals</a></strong>(Object&nbsp;other)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#hashCode()">hashCode</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.spark.sql.catalyst.expressions.Literal</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#inferPartitionColumnValue(java.lang.String,%20java.lang.String)">inferPartitionColumnValue</a></strong>(String&nbsp;raw,
                         String&nbsp;defaultPartitionName)</code>
<div class="block">Converts a string to a <code>Literal</code> with automatic type inference.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#insert(org.apache.spark.sql.DataFrame,%20boolean)">insert</a></strong>(<a href="../../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;data,
      boolean&nbsp;overwrite)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#isPartitioned()">isPartitioned</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.Option&lt;<a href="../../../../../org/apache/spark/sql/parquet/PartitionSpec.html" title="class in org.apache.spark.sql.parquet">PartitionSpec</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#maybePartitionSpec()">maybePartitionSpec</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.Option&lt;org.apache.spark.sql.types.StructType&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#maybeSchema()">maybeSchema</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#MERGE_SCHEMA()">MERGE_SCHEMA</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.spark.sql.types.StructType</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#mergeMetastoreParquetSchema(org.apache.spark.sql.types.StructType,%20org.apache.spark.sql.types.StructType)">mergeMetastoreParquetSchema</a></strong>(org.apache.spark.sql.types.StructType&nbsp;metastoreSchema,
                           org.apache.spark.sql.types.StructType&nbsp;parquetSchema)</code>
<div class="block">Reconciles Hive Metastore case insensitivity issue and data type conflicts between Metastore
 schema and Parquet schema.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.spark.sql.types.StructType</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#mergeMissingNullableFields(org.apache.spark.sql.types.StructType,%20org.apache.spark.sql.types.StructType)">mergeMissingNullableFields</a></strong>(org.apache.spark.sql.types.StructType&nbsp;metastoreSchema,
                          org.apache.spark.sql.types.StructType&nbsp;parquetSchema)</code>
<div class="block">Returns the original schema from the Parquet file with any missing nullable fields from the
 Hive Metastore schema merged in.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#METASTORE_SCHEMA()">METASTORE_SCHEMA</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.collection.immutable.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#parameters()">parameters</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet">ParquetRelation2.PartitionValues</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#parsePartition(org.apache.hadoop.fs.Path,%20java.lang.String)">parsePartition</a></strong>(org.apache.hadoop.fs.Path&nbsp;path,
              String&nbsp;defaultPartitionName)</code>
<div class="block">Parses a single partition, returns column names and values of each partition column.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../../../org/apache/spark/sql/parquet/PartitionSpec.html" title="class in org.apache.spark.sql.parquet">PartitionSpec</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#parsePartitions(scala.collection.Seq,%20java.lang.String)">parsePartitions</a></strong>(scala.collection.Seq&lt;org.apache.hadoop.fs.Path&gt;&nbsp;paths,
               String&nbsp;defaultPartitionName)</code>
<div class="block">Given a group of qualified paths, tries to parse them and returns a partition specification.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.types.StructType</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#partitionColumns()">partitionColumns</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/sql/parquet/Partition.html" title="class in org.apache.spark.sql.parquet">Partition</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#partitions()">partitions</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/parquet/PartitionSpec.html" title="class in org.apache.spark.sql.parquet">PartitionSpec</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#partitionSpec()">partitionSpec</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.collection.Seq&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#paths()">paths</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.Option&lt;org.apache.spark.sql.types.StructType&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#readSchema(scala.collection.Seq,%20org.apache.spark.sql.SQLContext)">readSchema</a></strong>(scala.collection.Seq&lt;parquet.hadoop.Footer&gt;&nbsp;footers,
          <a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet">ParquetRelation2.PartitionValues</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#resolvePartitions(scala.collection.Seq)">resolvePartitions</a></strong>(scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet">ParquetRelation2.PartitionValues</a>&gt;&nbsp;values)</code>
<div class="block">Resolves possible type conflicts between partitions by up-casting "lower" types.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.types.StructType</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#schema()">schema</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#sizeInBytes()">sizeInBytes</a></strong>()</code>
<div class="block">Returns an estimated size of this relation in bytes.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#sparkContext()">sparkContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.html#sqlContext()">sqlContext</a></strong>()</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>getClass, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.mapreduce.SparkHadoopMapReduceUtil">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.mapreduce.<a href="../../../../../org/apache/spark/mapreduce/SparkHadoopMapReduceUtil.html" title="interface in org.apache.spark.mapreduce">SparkHadoopMapReduceUtil</a></h3>
<code><a href="../../../../../org/apache/spark/mapreduce/SparkHadoopMapReduceUtil.html#firstAvailableClass(java.lang.String,%20java.lang.String)">firstAvailableClass</a>, <a href="../../../../../org/apache/spark/mapreduce/SparkHadoopMapReduceUtil.html#newJobContext(org.apache.hadoop.conf.Configuration,%20org.apache.hadoop.mapreduce.JobID)">newJobContext</a>, <a href="../../../../../org/apache/spark/mapreduce/SparkHadoopMapReduceUtil.html#newTaskAttemptContext(org.apache.hadoop.conf.Configuration,%20org.apache.hadoop.mapreduce.TaskAttemptID)">newTaskAttemptContext</a>, <a href="../../../../../org/apache/spark/mapreduce/SparkHadoopMapReduceUtil.html#newTaskAttemptID(java.lang.String,%20int,%20boolean,%20int,%20int)">newTaskAttemptID</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_scala.Product">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;scala.Product</h3>
<code>productArity, productElement, productIterator, productPrefix</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_scala.Equals">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;scala.Equals</h3>
<code>canEqual</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="ParquetRelation2(scala.collection.Seq, scala.collection.immutable.Map, scala.Option, scala.Option, org.apache.spark.sql.SQLContext)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>ParquetRelation2</h4>
<pre>public&nbsp;ParquetRelation2(scala.collection.Seq&lt;String&gt;&nbsp;paths,
                scala.collection.immutable.Map&lt;String,String&gt;&nbsp;parameters,
                scala.Option&lt;org.apache.spark.sql.types.StructType&gt;&nbsp;maybeSchema,
                scala.Option&lt;<a href="../../../../../org/apache/spark/sql/parquet/PartitionSpec.html" title="class in org.apache.spark.sql.parquet">PartitionSpec</a>&gt;&nbsp;maybePartitionSpec,
                <a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="MERGE_SCHEMA()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MERGE_SCHEMA</h4>
<pre>public static&nbsp;String&nbsp;MERGE_SCHEMA()</pre>
</li>
</ul>
<a name="DEFAULT_PARTITION_NAME()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>DEFAULT_PARTITION_NAME</h4>
<pre>public static&nbsp;String&nbsp;DEFAULT_PARTITION_NAME()</pre>
</li>
</ul>
<a name="METASTORE_SCHEMA()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>METASTORE_SCHEMA</h4>
<pre>public static&nbsp;String&nbsp;METASTORE_SCHEMA()</pre>
</li>
</ul>
<a name="readSchema(scala.collection.Seq, org.apache.spark.sql.SQLContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>readSchema</h4>
<pre>public static&nbsp;scala.Option&lt;org.apache.spark.sql.types.StructType&gt;&nbsp;readSchema(scala.collection.Seq&lt;parquet.hadoop.Footer&gt;&nbsp;footers,
                                                             <a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</pre>
</li>
</ul>
<a name="mergeMetastoreParquetSchema(org.apache.spark.sql.types.StructType, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mergeMetastoreParquetSchema</h4>
<pre>public static&nbsp;org.apache.spark.sql.types.StructType&nbsp;mergeMetastoreParquetSchema(org.apache.spark.sql.types.StructType&nbsp;metastoreSchema,
                                                                org.apache.spark.sql.types.StructType&nbsp;parquetSchema)</pre>
<div class="block">Reconciles Hive Metastore case insensitivity issue and data type conflicts between Metastore
 schema and Parquet schema.
 <p>
 Hive doesn't retain case information, while Parquet is case sensitive. On the other hand, the
 schema read from Parquet files may be incomplete (e.g. older versions of Parquet doesn't
 distinguish binary and string).  This method generates a correct schema by merging Metastore
 schema data types and Parquet schema field names.</div>
</li>
</ul>
<a name="mergeMissingNullableFields(org.apache.spark.sql.types.StructType, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mergeMissingNullableFields</h4>
<pre>public static&nbsp;org.apache.spark.sql.types.StructType&nbsp;mergeMissingNullableFields(org.apache.spark.sql.types.StructType&nbsp;metastoreSchema,
                                                               org.apache.spark.sql.types.StructType&nbsp;parquetSchema)</pre>
<div class="block">Returns the original schema from the Parquet file with any missing nullable fields from the
 Hive Metastore schema merged in.
 <p>
 When constructing a DataFrame from a collection of structured data, the resulting object has
 a schema corresponding to the union of the fields present in each element of the collection.
 Spark SQL simply assigns a null value to any field that isn't present for a particular row.
 In some cases, it is possible that a given table partition stored as a Parquet file doesn't
 contain a particular nullable field in its schema despite that field being present in the
 table schema obtained from the Hive Metastore. This method returns a schema representing the
 Parquet file schema along with any additional nullable fields from the Metastore schema
 merged in.</div>
</li>
</ul>
<a name="parsePartitions(scala.collection.Seq, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parsePartitions</h4>
<pre>public static&nbsp;<a href="../../../../../org/apache/spark/sql/parquet/PartitionSpec.html" title="class in org.apache.spark.sql.parquet">PartitionSpec</a>&nbsp;parsePartitions(scala.collection.Seq&lt;org.apache.hadoop.fs.Path&gt;&nbsp;paths,
                            String&nbsp;defaultPartitionName)</pre>
<div class="block">Given a group of qualified paths, tries to parse them and returns a partition specification.
 For example, given:
 <pre><code>
   hdfs://&lt;host&gt;:&lt;port&gt;/path/to/partition/a=1/b=hello/c=3.14
   hdfs://&lt;host&gt;:&lt;port&gt;/path/to/partition/a=2/b=world/c=6.28
 </code></pre>
 it returns:
 <pre><code>
   PartitionSpec(
     partitionColumns = StructType(
       StructField(name = "a", dataType = IntegerType, nullable = true),
       StructField(name = "b", dataType = StringType, nullable = true),
       StructField(name = "c", dataType = DoubleType, nullable = true)),
     partitions = Seq(
       Partition(
         values = Row(1, "hello", 3.14),
         path = "hdfs://&lt;host&gt;:&lt;port&gt;/path/to/partition/a=1/b=hello/c=3.14"),
       Partition(
         values = Row(2, "world", 6.28),
         path = "hdfs://&lt;host&gt;:&lt;port&gt;/path/to/partition/a=2/b=world/c=6.28")))
 </code></pre></div>
</li>
</ul>
<a name="parsePartition(org.apache.hadoop.fs.Path, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parsePartition</h4>
<pre>public static&nbsp;<a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet">ParquetRelation2.PartitionValues</a>&nbsp;parsePartition(org.apache.hadoop.fs.Path&nbsp;path,
                                              String&nbsp;defaultPartitionName)</pre>
<div class="block">Parses a single partition, returns column names and values of each partition column.  For
 example, given:
 <pre><code>
   path = hdfs://&lt;host&gt;:&lt;port&gt;/path/to/partition/a=42/b=hello/c=3.14
 </code></pre>
 it returns:
 <pre><code>
   PartitionValues(
     Seq("a", "b", "c"),
     Seq(
       Literal(42, IntegerType),
       Literal("hello", StringType),
       Literal(3.14, FloatType)))
 </code></pre></div>
</li>
</ul>
<a name="resolvePartitions(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resolvePartitions</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet">ParquetRelation2.PartitionValues</a>&gt;&nbsp;resolvePartitions(scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet">ParquetRelation2.PartitionValues</a>&gt;&nbsp;values)</pre>
<div class="block">Resolves possible type conflicts between partitions by up-casting "lower" types.  The up-
 casting order is:
 <pre><code>
   NullType -&gt;
   IntegerType -&gt; LongType -&gt;
   FloatType -&gt; DoubleType -&gt; DecimalType.Unlimited -&gt;
   StringType
 </code></pre></div>
</li>
</ul>
<a name="inferPartitionColumnValue(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>inferPartitionColumnValue</h4>
<pre>public static&nbsp;org.apache.spark.sql.catalyst.expressions.Literal&nbsp;inferPartitionColumnValue(String&nbsp;raw,
                                                                          String&nbsp;defaultPartitionName)</pre>
<div class="block">Converts a string to a <code>Literal</code> with automatic type inference.  Currently only supports
 <code>IntegerType</code>, <code>LongType</code>, <code>FloatType</code>, <code>DoubleType</code>, <code>DecimalType.Unlimited</code>, and
 <code>StringType</code>.</div>
</li>
</ul>
<a name="paths()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paths</h4>
<pre>public&nbsp;scala.collection.Seq&lt;String&gt;&nbsp;paths()</pre>
</li>
</ul>
<a name="parameters()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parameters</h4>
<pre>public&nbsp;scala.collection.immutable.Map&lt;String,String&gt;&nbsp;parameters()</pre>
</li>
</ul>
<a name="maybeSchema()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maybeSchema</h4>
<pre>public&nbsp;scala.Option&lt;org.apache.spark.sql.types.StructType&gt;&nbsp;maybeSchema()</pre>
</li>
</ul>
<a name="maybePartitionSpec()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maybePartitionSpec</h4>
<pre>public&nbsp;scala.Option&lt;<a href="../../../../../org/apache/spark/sql/parquet/PartitionSpec.html" title="class in org.apache.spark.sql.parquet">PartitionSpec</a>&gt;&nbsp;maybePartitionSpec()</pre>
</li>
</ul>
<a name="sqlContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sqlContext</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#sqlContext()">sqlContext</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a></code></dd>
</dl>
</li>
</ul>
<a name="equals(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>equals</h4>
<pre>public&nbsp;boolean&nbsp;equals(Object&nbsp;other)</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>equals</code>&nbsp;in interface&nbsp;<code>scala.Equals</code></dd>
<dt><strong>Overrides:</strong></dt>
<dd><code>equals</code>&nbsp;in class&nbsp;<code>Object</code></dd>
</dl>
</li>
</ul>
<a name="hashCode()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hashCode</h4>
<pre>public&nbsp;int&nbsp;hashCode()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code>hashCode</code>&nbsp;in class&nbsp;<code>Object</code></dd>
</dl>
</li>
</ul>
<a name="sparkContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkContext</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext()</pre>
</li>
</ul>
<a name="partitionSpec()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionSpec</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/parquet/PartitionSpec.html" title="class in org.apache.spark.sql.parquet">PartitionSpec</a>&nbsp;partitionSpec()</pre>
</li>
</ul>
<a name="partitionColumns()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionColumns</h4>
<pre>public&nbsp;org.apache.spark.sql.types.StructType&nbsp;partitionColumns()</pre>
</li>
</ul>
<a name="partitions()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitions</h4>
<pre>public&nbsp;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/sql/parquet/Partition.html" title="class in org.apache.spark.sql.parquet">Partition</a>&gt;&nbsp;partitions()</pre>
</li>
</ul>
<a name="isPartitioned()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isPartitioned</h4>
<pre>public&nbsp;boolean&nbsp;isPartitioned()</pre>
</li>
</ul>
<a name="schema()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>schema</h4>
<pre>public&nbsp;org.apache.spark.sql.types.StructType&nbsp;schema()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#schema()">schema</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a></code></dd>
</dl>
</li>
</ul>
<a name="sizeInBytes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sizeInBytes</h4>
<pre>public&nbsp;long&nbsp;sizeInBytes()</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#sizeInBytes()">BaseRelation</a></code></strong></div>
<div class="block">Returns an estimated size of this relation in bytes. This information is used by the planner
 to decided when it is safe to broadcast a relation and can be overridden by sources that
 know the size ahead of time. By default, the system will assume that tables are too
 large to broadcast. This method will be called multiple times during query planning
 and thus should not perform expensive operations for each invocation.
 <p>
 Note that it is always better to overestimate size than underestimate, because underestimation
 could lead to execution plans that are suboptimal (i.e. broadcasting a very large table).</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#sizeInBytes()">sizeInBytes</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a></code></dd>
</dl>
</li>
</ul>
<a name="buildScan(scala.collection.Seq, scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>buildScan</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.Row&gt;&nbsp;buildScan(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;output,
                                      scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;predicates)</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/sources/CatalystScan.html#buildScan(scala.collection.Seq,%20scala.collection.Seq)">buildScan</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/CatalystScan.html" title="interface in org.apache.spark.sql.sources">CatalystScan</a></code></dd>
</dl>
</li>
</ul>
<a name="insert(org.apache.spark.sql.DataFrame, boolean)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>insert</h4>
<pre>public&nbsp;void&nbsp;insert(<a href="../../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;data,
          boolean&nbsp;overwrite)</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/sources/InsertableRelation.html#insert(org.apache.spark.sql.DataFrame,%20boolean)">insert</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/InsertableRelation.html" title="interface in org.apache.spark.sql.sources">InsertableRelation</a></code></dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation.html" title="class in org.apache.spark.sql.parquet"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/parquet/ParquetRelation2.PartitionValues.html" title="class in org.apache.spark.sql.parquet"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/parquet/ParquetRelation2.html" target="_top">Frames</a></li>
<li><a href="ParquetRelation2.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
