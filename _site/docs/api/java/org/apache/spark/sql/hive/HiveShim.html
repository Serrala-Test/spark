<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_71) on Thu Apr 02 14:27:48 PDT 2015 -->
<title>HiveShim (Spark 1.4.0 JavaDoc)</title>
<meta name="date" content="2015-04-02">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="HiveShim (Spark 1.4.0 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/hive/HiveQl.TransformableNode.html" title="class in org.apache.spark.sql.hive"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/hive/HiveSimpleUdf.html" title="class in org.apache.spark.sql.hive"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/hive/HiveShim.html" target="_top">Frames</a></li>
<li><a href="HiveShim.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.hive</div>
<h2 title="Class HiveShim" class="title">Class HiveShim</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.hive.HiveShim</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public class <span class="strong">HiveShim</span>
extends Object</pre>
<div class="block">A compatibility layer for interacting with Hive version 0.13.1.</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#HiveShim()">HiveShim</a></strong>()</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#appendReadColumns(org.apache.hadoop.conf.Configuration,%20scala.collection.Seq,%20scala.collection.Seq)">appendReadColumns</a></strong>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                 scala.collection.Seq&lt;Integer&gt;&nbsp;ids,
                 scala.collection.Seq&lt;String&gt;&nbsp;names)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;scala.runtime.Nothing$&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#compatibilityBlackList()">compatibilityBlackList</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.common.type.HiveDecimal</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#createDecimal(java.math.BigDecimal)">createDecimal</a></strong>(java.math.BigDecimal&nbsp;bd)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#createDefaultDBIfNeeded(org.apache.spark.sql.hive.HiveContext)">createDefaultDBIfNeeded</a></strong>(<a href="../../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a>&nbsp;context)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static java.util.ArrayList&lt;Object&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#createDriverResultsArray()">createDriverResultsArray</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#decimalMetastoreString(org.apache.spark.sql.types.DecimalType)">decimalMetastoreString</a></strong>(org.apache.spark.sql.types.DecimalType&nbsp;decimalType)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#decimalTypeInfo(org.apache.spark.sql.types.DecimalType)">decimalTypeInfo</a></strong>(org.apache.spark.sql.types.DecimalType&nbsp;decimalType)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.spark.sql.types.DecimalType</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#decimalTypeInfoToCatalyst(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector)">decimalTypeInfoToCatalyst</a></strong>(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector&nbsp;inspector)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static java.util.Set&lt;org.apache.hadoop.hive.ql.metadata.Partition&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getAllPartitionsOf(org.apache.hadoop.hive.ql.metadata.Hive,%20org.apache.hadoop.hive.ql.metadata.Table)">getAllPartitionsOf</a></strong>(org.apache.hadoop.hive.ql.metadata.Hive&nbsp;client,
                  org.apache.hadoop.hive.ql.metadata.Table&nbsp;tbl)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.io.BytesWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getBinaryWritable(java.lang.Object)">getBinaryWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getBinaryWritableConstantObjectInspector(java.lang.Object)">getBinaryWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.io.BooleanWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getBooleanWritable(java.lang.Object)">getBooleanWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getBooleanWritableConstantObjectInspector(java.lang.Object)">getBooleanWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.io.ByteWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getByteWritable(java.lang.Object)">getByteWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getByteWritableConstantObjectInspector(java.lang.Object)">getByteWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.ql.processors.CommandProcessor</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getCommandProcessor(java.lang.String[],%20org.apache.hadoop.hive.conf.HiveConf)">getCommandProcessor</a></strong>(String[]&nbsp;cmd,
                   org.apache.hadoop.hive.conf.HiveConf&nbsp;conf)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getConvertedOI(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,%20org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)">getConvertedOI</a></strong>(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;inputOI,
              org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;outputOI)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getDataLocationPath(org.apache.hadoop.hive.ql.metadata.Partition)">getDataLocationPath</a></strong>(org.apache.hadoop.hive.ql.metadata.Partition&nbsp;p)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.io.DateWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getDateWritable(java.lang.Object)">getDateWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getDateWritableConstantObjectInspector(java.lang.Object)">getDateWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.io.HiveDecimalWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getDecimalWritable(java.lang.Object)">getDecimalWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getDecimalWritableConstantObjectInspector(java.lang.Object)">getDecimalWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.io.DoubleWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getDoubleWritable(java.lang.Object)">getDoubleWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getDoubleWritableConstantObjectInspector(java.lang.Object)">getDoubleWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getExternalTmpPath(org.apache.hadoop.hive.ql.Context,%20org.apache.hadoop.fs.Path)">getExternalTmpPath</a></strong>(org.apache.hadoop.hive.ql.Context&nbsp;context,
                  org.apache.hadoop.fs.Path&nbsp;path)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.io.FloatWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getFloatWritable(java.lang.Object)">getFloatWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getFloatWritableConstantObjectInspector(java.lang.Object)">getFloatWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.io.IntWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getIntWritable(java.lang.Object)">getIntWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getIntWritableConstantObjectInspector(java.lang.Object)">getIntWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.io.LongWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getLongWritable(java.lang.Object)">getLongWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getLongWritableConstantObjectInspector(java.lang.Object)">getLongWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.io.NullWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getPrimitiveNullWritable()">getPrimitiveNullWritable</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getPrimitiveNullWritableConstantObjectInspector()">getPrimitiveNullWritableConstantObjectInspector</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.io.ShortWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getShortWritable(java.lang.Object)">getShortWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getShortWritableConstantObjectInspector(java.lang.Object)">getShortWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getStatsSetupConstRawDataSize()">getStatsSetupConstRawDataSize</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getStatsSetupConstTotalSize()">getStatsSetupConstTotalSize</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.io.Text</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getStringWritable(java.lang.Object)">getStringWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getStringWritableConstantObjectInspector(java.lang.Object)">getStringWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.ql.plan.TableDesc</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getTableDesc(java.lang.Class,%20java.lang.Class,%20java.lang.Class,%20java.util.Properties)">getTableDesc</a></strong>(Class&lt;? extends org.apache.hadoop.hive.serde2.Deserializer&gt;&nbsp;serdeClass,
            Class&lt;? extends org.apache.hadoop.mapred.InputFormat&lt;?,?&gt;&gt;&nbsp;inputFormatClass,
            Class&lt;?&gt;&nbsp;outputFormatClass,
            java.util.Properties&nbsp;properties)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.io.TimestampWritable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getTimestampWritable(java.lang.Object)">getTimestampWritable</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#getTimestampWritableConstantObjectInspector(java.lang.Object)">getTimestampWritableConstantObjectInspector</a></strong>(Object&nbsp;value)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.io.Writable</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#prepareWritable(org.apache.hadoop.io.Writable)">prepareWritable</a></strong>(org.apache.hadoop.io.Writable&nbsp;w)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.mutable.Buffer&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#processResults(java.util.ArrayList)">processResults</a></strong>(java.util.ArrayList&lt;Object&gt;&nbsp;results)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#setLocation(org.apache.hadoop.hive.ql.metadata.Table,%20org.apache.hadoop.hive.ql.plan.CreateTableDesc)">setLocation</a></strong>(org.apache.hadoop.hive.ql.metadata.Table&nbsp;tbl,
           org.apache.hadoop.hive.ql.plan.CreateTableDesc&nbsp;crtTbl)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#setTblNullFormat(org.apache.hadoop.hive.ql.plan.CreateTableDesc,%20org.apache.hadoop.hive.ql.metadata.Table)">setTblNullFormat</a></strong>(org.apache.hadoop.hive.ql.plan.CreateTableDesc&nbsp;crtTbl,
                org.apache.hadoop.hive.ql.metadata.Table&nbsp;tbl)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.spark.sql.types.Decimal</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#toCatalystDecimal(org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveDecimalObjectInspector,%20java.lang.Object)">toCatalystDecimal</a></strong>(org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveDecimalObjectInspector&nbsp;hdoi,
                 Object&nbsp;data)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#version()">version</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.hive.ql.plan.FileSinkDesc</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveShim.html#wrapperToFileSinkDesc(org.apache.spark.sql.hive.ShimFileSinkDesc)">wrapperToFileSinkDesc</a></strong>(<a href="../../../../../org/apache/spark/sql/hive/ShimFileSinkDesc.html" title="class in org.apache.spark.sql.hive">ShimFileSinkDesc</a>&nbsp;w)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="HiveShim()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>HiveShim</h4>
<pre>public&nbsp;HiveShim()</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="version()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>version</h4>
<pre>public static&nbsp;String&nbsp;version()</pre>
</li>
</ul>
<a name="getTableDesc(java.lang.Class, java.lang.Class, java.lang.Class, java.util.Properties)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getTableDesc</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.ql.plan.TableDesc&nbsp;getTableDesc(Class&lt;? extends org.apache.hadoop.hive.serde2.Deserializer&gt;&nbsp;serdeClass,
                                                    Class&lt;? extends org.apache.hadoop.mapred.InputFormat&lt;?,?&gt;&gt;&nbsp;inputFormatClass,
                                                    Class&lt;?&gt;&nbsp;outputFormatClass,
                                                    java.util.Properties&nbsp;properties)</pre>
</li>
</ul>
<a name="getStringWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStringWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getStringWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getIntWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIntWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getIntWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getDoubleWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDoubleWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getDoubleWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getBooleanWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getBooleanWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getBooleanWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getLongWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLongWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getLongWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getFloatWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFloatWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getFloatWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getShortWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getShortWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getShortWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getByteWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getByteWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getByteWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getBinaryWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getBinaryWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getBinaryWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getDateWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDateWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getDateWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getTimestampWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getTimestampWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getTimestampWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getDecimalWritableConstantObjectInspector(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDecimalWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getDecimalWritableConstantObjectInspector(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getPrimitiveNullWritableConstantObjectInspector()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPrimitiveNullWritableConstantObjectInspector</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getPrimitiveNullWritableConstantObjectInspector()</pre>
</li>
</ul>
<a name="getStringWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStringWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.io.Text&nbsp;getStringWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getIntWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIntWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.io.IntWritable&nbsp;getIntWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getDoubleWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDoubleWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.io.DoubleWritable&nbsp;getDoubleWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getBooleanWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getBooleanWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.io.BooleanWritable&nbsp;getBooleanWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getLongWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLongWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.io.LongWritable&nbsp;getLongWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getFloatWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFloatWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.io.FloatWritable&nbsp;getFloatWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getShortWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getShortWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.io.ShortWritable&nbsp;getShortWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getByteWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getByteWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.io.ByteWritable&nbsp;getByteWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getBinaryWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getBinaryWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.io.BytesWritable&nbsp;getBinaryWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getDateWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDateWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.io.DateWritable&nbsp;getDateWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getTimestampWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getTimestampWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.io.TimestampWritable&nbsp;getTimestampWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getDecimalWritable(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDecimalWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.io.HiveDecimalWritable&nbsp;getDecimalWritable(Object&nbsp;value)</pre>
</li>
</ul>
<a name="getPrimitiveNullWritable()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPrimitiveNullWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.io.NullWritable&nbsp;getPrimitiveNullWritable()</pre>
</li>
</ul>
<a name="createDriverResultsArray()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDriverResultsArray</h4>
<pre>public static&nbsp;java.util.ArrayList&lt;Object&gt;&nbsp;createDriverResultsArray()</pre>
</li>
</ul>
<a name="processResults(java.util.ArrayList)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>processResults</h4>
<pre>public static&nbsp;scala.collection.mutable.Buffer&lt;String&gt;&nbsp;processResults(java.util.ArrayList&lt;Object&gt;&nbsp;results)</pre>
</li>
</ul>
<a name="getStatsSetupConstTotalSize()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStatsSetupConstTotalSize</h4>
<pre>public static&nbsp;String&nbsp;getStatsSetupConstTotalSize()</pre>
</li>
</ul>
<a name="getStatsSetupConstRawDataSize()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStatsSetupConstRawDataSize</h4>
<pre>public static&nbsp;String&nbsp;getStatsSetupConstRawDataSize()</pre>
</li>
</ul>
<a name="createDefaultDBIfNeeded(org.apache.spark.sql.hive.HiveContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDefaultDBIfNeeded</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;String&gt;&nbsp;createDefaultDBIfNeeded(<a href="../../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a>&nbsp;context)</pre>
</li>
</ul>
<a name="getCommandProcessor(java.lang.String[], org.apache.hadoop.hive.conf.HiveConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getCommandProcessor</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.ql.processors.CommandProcessor&nbsp;getCommandProcessor(String[]&nbsp;cmd,
                                                                        org.apache.hadoop.hive.conf.HiveConf&nbsp;conf)</pre>
</li>
</ul>
<a name="createDecimal(java.math.BigDecimal)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDecimal</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.common.type.HiveDecimal&nbsp;createDecimal(java.math.BigDecimal&nbsp;bd)</pre>
</li>
</ul>
<a name="appendReadColumns(org.apache.hadoop.conf.Configuration, scala.collection.Seq, scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>appendReadColumns</h4>
<pre>public static&nbsp;void&nbsp;appendReadColumns(org.apache.hadoop.conf.Configuration&nbsp;conf,
                     scala.collection.Seq&lt;Integer&gt;&nbsp;ids,
                     scala.collection.Seq&lt;String&gt;&nbsp;names)</pre>
</li>
</ul>
<a name="getExternalTmpPath(org.apache.hadoop.hive.ql.Context, org.apache.hadoop.fs.Path)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getExternalTmpPath</h4>
<pre>public static&nbsp;org.apache.hadoop.fs.Path&nbsp;getExternalTmpPath(org.apache.hadoop.hive.ql.Context&nbsp;context,
                                           org.apache.hadoop.fs.Path&nbsp;path)</pre>
</li>
</ul>
<a name="getDataLocationPath(org.apache.hadoop.hive.ql.metadata.Partition)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDataLocationPath</h4>
<pre>public static&nbsp;org.apache.hadoop.fs.Path&nbsp;getDataLocationPath(org.apache.hadoop.hive.ql.metadata.Partition&nbsp;p)</pre>
</li>
</ul>
<a name="getAllPartitionsOf(org.apache.hadoop.hive.ql.metadata.Hive, org.apache.hadoop.hive.ql.metadata.Table)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllPartitionsOf</h4>
<pre>public static&nbsp;java.util.Set&lt;org.apache.hadoop.hive.ql.metadata.Partition&gt;&nbsp;getAllPartitionsOf(org.apache.hadoop.hive.ql.metadata.Hive&nbsp;client,
                                                                             org.apache.hadoop.hive.ql.metadata.Table&nbsp;tbl)</pre>
</li>
</ul>
<a name="compatibilityBlackList()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>compatibilityBlackList</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;scala.runtime.Nothing$&gt;&nbsp;compatibilityBlackList()</pre>
</li>
</ul>
<a name="setLocation(org.apache.hadoop.hive.ql.metadata.Table, org.apache.hadoop.hive.ql.plan.CreateTableDesc)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLocation</h4>
<pre>public static&nbsp;void&nbsp;setLocation(org.apache.hadoop.hive.ql.metadata.Table&nbsp;tbl,
               org.apache.hadoop.hive.ql.plan.CreateTableDesc&nbsp;crtTbl)</pre>
</li>
</ul>
<a name="wrapperToFileSinkDesc(org.apache.spark.sql.hive.ShimFileSinkDesc)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>wrapperToFileSinkDesc</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.ql.plan.FileSinkDesc&nbsp;wrapperToFileSinkDesc(<a href="../../../../../org/apache/spark/sql/hive/ShimFileSinkDesc.html" title="class in org.apache.spark.sql.hive">ShimFileSinkDesc</a>&nbsp;w)</pre>
</li>
</ul>
<a name="decimalMetastoreString(org.apache.spark.sql.types.DecimalType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>decimalMetastoreString</h4>
<pre>public static&nbsp;String&nbsp;decimalMetastoreString(org.apache.spark.sql.types.DecimalType&nbsp;decimalType)</pre>
</li>
</ul>
<a name="decimalTypeInfo(org.apache.spark.sql.types.DecimalType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>decimalTypeInfo</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.typeinfo.TypeInfo&nbsp;decimalTypeInfo(org.apache.spark.sql.types.DecimalType&nbsp;decimalType)</pre>
</li>
</ul>
<a name="decimalTypeInfoToCatalyst(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>decimalTypeInfoToCatalyst</h4>
<pre>public static&nbsp;org.apache.spark.sql.types.DecimalType&nbsp;decimalTypeInfoToCatalyst(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector&nbsp;inspector)</pre>
</li>
</ul>
<a name="toCatalystDecimal(org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveDecimalObjectInspector, java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toCatalystDecimal</h4>
<pre>public static&nbsp;org.apache.spark.sql.types.Decimal&nbsp;toCatalystDecimal(org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveDecimalObjectInspector&nbsp;hdoi,
                                                   Object&nbsp;data)</pre>
</li>
</ul>
<a name="getConvertedOI(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConvertedOI</h4>
<pre>public static&nbsp;org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;getConvertedOI(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;inputOI,
                                                                           org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector&nbsp;outputOI)</pre>
</li>
</ul>
<a name="prepareWritable(org.apache.hadoop.io.Writable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>prepareWritable</h4>
<pre>public static&nbsp;org.apache.hadoop.io.Writable&nbsp;prepareWritable(org.apache.hadoop.io.Writable&nbsp;w)</pre>
</li>
</ul>
<a name="setTblNullFormat(org.apache.hadoop.hive.ql.plan.CreateTableDesc, org.apache.hadoop.hive.ql.metadata.Table)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>setTblNullFormat</h4>
<pre>public static&nbsp;Object&nbsp;setTblNullFormat(org.apache.hadoop.hive.ql.plan.CreateTableDesc&nbsp;crtTbl,
                      org.apache.hadoop.hive.ql.metadata.Table&nbsp;tbl)</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/hive/HiveQl.TransformableNode.html" title="class in org.apache.spark.sql.hive"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/hive/HiveSimpleUdf.html" title="class in org.apache.spark.sql.hive"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/hive/HiveShim.html" target="_top">Frames</a></li>
<li><a href="HiveShim.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
