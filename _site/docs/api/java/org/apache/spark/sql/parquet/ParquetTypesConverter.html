<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_71) on Thu Apr 02 14:27:47 PDT 2015 -->
<title>ParquetTypesConverter (Spark 1.4.0 JavaDoc)</title>
<meta name="date" content="2015-04-02">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="ParquetTypesConverter (Spark 1.4.0 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypeInfo.html" title="class in org.apache.spark.sql.parquet"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/parquet/Partition.html" title="class in org.apache.spark.sql.parquet"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/parquet/ParquetTypesConverter.html" target="_top">Frames</a></li>
<li><a href="ParquetTypesConverter.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.parquet</div>
<h2 title="Class ParquetTypesConverter" class="title">Class ParquetTypesConverter</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.parquet.ParquetTypesConverter</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd><a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">ParquetTypesConverter</span>
extends Object
implements <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></pre>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#ParquetTypesConverter()">ParquetTypesConverter</a></strong>()</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static int[]</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#BYTES_FOR_PRECISION()">BYTES_FOR_PRECISION</a></strong>()</code>
<div class="block">Compute the FIXED_LEN_BYTE_ARRAY length needed to represent a given DECIMAL precision.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static parquet.schema.MessageType</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#convertFromAttributes(scala.collection.Seq,%20boolean)">convertFromAttributes</a></strong>(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;attributes,
                     boolean&nbsp;toThriftSchemaNames)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#convertFromString(java.lang.String)">convertFromString</a></strong>(String&nbsp;string)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#convertToAttributes(parquet.schema.Type,%20boolean,%20boolean)">convertToAttributes</a></strong>(parquet.schema.Type&nbsp;parquetSchema,
                   boolean&nbsp;isBinaryAsString,
                   boolean&nbsp;isInt96AsTimestamp)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#convertToString(scala.collection.Seq)">convertToString</a></strong>(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;schema)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static parquet.schema.Type</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#fromDataType(org.apache.spark.sql.types.DataType,%20java.lang.String,%20boolean,%20boolean,%20boolean)">fromDataType</a></strong>(org.apache.spark.sql.types.DataType&nbsp;ctype,
            String&nbsp;name,
            boolean&nbsp;nullable,
            boolean&nbsp;inArray,
            boolean&nbsp;toThriftSchemaNames)</code>
<div class="block">Converts a given Catalyst <code>DataType</code> into
 the corresponding Parquet <code>Type</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.Option&lt;<a href="../../../../../org/apache/spark/sql/parquet/ParquetTypeInfo.html" title="class in org.apache.spark.sql.parquet">ParquetTypeInfo</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#fromPrimitiveDataType(org.apache.spark.sql.types.DataType)">fromPrimitiveDataType</a></strong>(org.apache.spark.sql.types.DataType&nbsp;ctype)</code>
<div class="block">For a given Catalyst <code>DataType</code> return
 the name of the corresponding Parquet primitive type or None if the given type
 is not primitive.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#isPrimitiveType(org.apache.spark.sql.types.DataType)">isPrimitiveType</a></strong>(org.apache.spark.sql.types.DataType&nbsp;ctype)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static parquet.hadoop.metadata.ParquetMetadata</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#readMetaData(org.apache.hadoop.fs.Path,%20scala.Option)">readMetaData</a></strong>(org.apache.hadoop.fs.Path&nbsp;origPath,
            scala.Option&lt;org.apache.hadoop.conf.Configuration&gt;&nbsp;configuration)</code>
<div class="block">Try to read Parquet metadata at the given Path.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#readSchemaFromFile(org.apache.hadoop.fs.Path,%20scala.Option,%20boolean,%20boolean)">readSchemaFromFile</a></strong>(org.apache.hadoop.fs.Path&nbsp;origPath,
                  scala.Option&lt;org.apache.hadoop.conf.Configuration&gt;&nbsp;conf,
                  boolean&nbsp;isBinaryAsString,
                  boolean&nbsp;isInt96AsTimestamp)</code>
<div class="block">Reads in Parquet Metadata from the given path and tries to extract the schema
 (Catalyst attributes) from the application-specific key-value map.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.spark.sql.types.DataType</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#toDataType(parquet.schema.Type,%20boolean,%20boolean)">toDataType</a></strong>(parquet.schema.Type&nbsp;parquetType,
          boolean&nbsp;isBinaryAsString,
          boolean&nbsp;isInt96AsTimestamp)</code>
<div class="block">Converts a given Parquet <code>Type</code> into the corresponding
 <code>DataType</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.spark.sql.types.DataType</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#toPrimitiveDataType(parquet.schema.PrimitiveType,%20boolean,%20boolean)">toPrimitiveDataType</a></strong>(parquet.schema.PrimitiveType&nbsp;parquetType,
                   boolean&nbsp;binaryAsString,
                   boolean&nbsp;int96AsTimestamp)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypesConverter.html#writeMetaData(scala.collection.Seq,%20org.apache.hadoop.fs.Path,%20org.apache.hadoop.conf.Configuration)">writeMetaData</a></strong>(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;attributes,
             org.apache.hadoop.fs.Path&nbsp;origPath,
             org.apache.hadoop.conf.Configuration&nbsp;conf)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="ParquetTypesConverter()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>ParquetTypesConverter</h4>
<pre>public&nbsp;ParquetTypesConverter()</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="isPrimitiveType(org.apache.spark.sql.types.DataType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isPrimitiveType</h4>
<pre>public static&nbsp;boolean&nbsp;isPrimitiveType(org.apache.spark.sql.types.DataType&nbsp;ctype)</pre>
</li>
</ul>
<a name="toPrimitiveDataType(parquet.schema.PrimitiveType, boolean, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toPrimitiveDataType</h4>
<pre>public static&nbsp;org.apache.spark.sql.types.DataType&nbsp;toPrimitiveDataType(parquet.schema.PrimitiveType&nbsp;parquetType,
                                                      boolean&nbsp;binaryAsString,
                                                      boolean&nbsp;int96AsTimestamp)</pre>
</li>
</ul>
<a name="toDataType(parquet.schema.Type, boolean, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toDataType</h4>
<pre>public static&nbsp;org.apache.spark.sql.types.DataType&nbsp;toDataType(parquet.schema.Type&nbsp;parquetType,
                                             boolean&nbsp;isBinaryAsString,
                                             boolean&nbsp;isInt96AsTimestamp)</pre>
<div class="block">Converts a given Parquet <code>Type</code> into the corresponding
 <code>DataType</code>.
 <p>
 We apply the following conversion rules:
 <ul>
   <li> Primitive types are converter to the corresponding primitive type.</li>
   <li> Group types that have a single field that is itself a group, which has repetition
        level <code>REPEATED</code>, are treated as follows:<ul>
          <li> If the nested group has name <code>values</code>, the surrounding group is converted
               into an <code>ArrayType</code> with the corresponding field type (primitive or
               complex) as element type.</li>
          <li> If the nested group has name <code>map</code> and two fields (named <code>key</code> and <code>value</code>),
               the surrounding group is converted into a <code>MapType</code>
               with the corresponding key and value (value possibly complex) types.
               Note that we currently assume map values are not nullable.</li>
   <li> Other group types are converted into a <code>StructType</code> with the corresponding
        field types.</li></ul></li>
 </ul>
 Note that fields are determined to be <code>nullable</code> if and only if their Parquet repetition
 level is not <code>REQUIRED</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>parquetType</code> - The type to convert.</dd>
<dt><span class="strong">Returns:</span></dt><dd>The corresponding Catalyst type.</dd></dl>
</li>
</ul>
<a name="fromPrimitiveDataType(org.apache.spark.sql.types.DataType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fromPrimitiveDataType</h4>
<pre>public static&nbsp;scala.Option&lt;<a href="../../../../../org/apache/spark/sql/parquet/ParquetTypeInfo.html" title="class in org.apache.spark.sql.parquet">ParquetTypeInfo</a>&gt;&nbsp;fromPrimitiveDataType(org.apache.spark.sql.types.DataType&nbsp;ctype)</pre>
<div class="block">For a given Catalyst <code>DataType</code> return
 the name of the corresponding Parquet primitive type or None if the given type
 is not primitive.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>ctype</code> - The type to convert</dd>
<dt><span class="strong">Returns:</span></dt><dd>The name of the corresponding Parquet type properties</dd></dl>
</li>
</ul>
<a name="BYTES_FOR_PRECISION()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>BYTES_FOR_PRECISION</h4>
<pre>public static&nbsp;int[]&nbsp;BYTES_FOR_PRECISION()</pre>
<div class="block">Compute the FIXED_LEN_BYTE_ARRAY length needed to represent a given DECIMAL precision.</div>
</li>
</ul>
<a name="fromDataType(org.apache.spark.sql.types.DataType, java.lang.String, boolean, boolean, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fromDataType</h4>
<pre>public static&nbsp;parquet.schema.Type&nbsp;fromDataType(org.apache.spark.sql.types.DataType&nbsp;ctype,
                               String&nbsp;name,
                               boolean&nbsp;nullable,
                               boolean&nbsp;inArray,
                               boolean&nbsp;toThriftSchemaNames)</pre>
<div class="block">Converts a given Catalyst <code>DataType</code> into
 the corresponding Parquet <code>Type</code>.
 <p>
 The conversion follows the rules below:
 <ul>
   <li> Primitive types are converted into Parquet's primitive types.</li>
   <li> <code>StructType</code>s are converted
        into Parquet's <code>GroupType</code> with the corresponding field types.</li>
   <li> <code>ArrayType</code>s are converted
        into a 2-level nested group, where the outer group has the inner
        group as sole field. The inner group has name <code>values</code> and
        repetition level <code>REPEATED</code> and has the element type of
        the array as schema. We use Parquet's <code>ConversionPatterns</code> for this
        purpose.</li>
   <li> <code>MapType</code>s are converted
        into a nested (2-level) Parquet <code>GroupType</code> with two fields: a key
        type and a value type. The nested group has repetition level
        <code>REPEATED</code> and name <code>map</code>. We use Parquet's <code>ConversionPatterns</code>
        for this purpose</li>
 </ul>
 Parquet's repetition level is generally set according to the following rule:
 <ul>
   <li> If the call to <code>fromDataType</code> is recursive inside an enclosing <code>ArrayType</code> or
   <code>MapType</code>, then the repetition level is set to <code>REPEATED</code>.</li>
   <li> Otherwise, if the attribute whose type is converted is <code>nullable</code>, the Parquet
   type gets repetition level <code>OPTIONAL</code> and otherwise <code>REQUIRED</code>.</li>
 </ul>
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>ctype</code> - The type to convert</dd><dd><code>name</code> - The name of the <code>Attribute</code>
             whose type is converted</dd><dd><code>nullable</code> - When true indicates that the attribute is nullable</dd><dd><code>inArray</code> - When true indicates that this is a nested attribute inside an array.</dd>
<dt><span class="strong">Returns:</span></dt><dd>The corresponding Parquet type.</dd></dl>
</li>
</ul>
<a name="convertToAttributes(parquet.schema.Type, boolean, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>convertToAttributes</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;convertToAttributes(parquet.schema.Type&nbsp;parquetSchema,
                                                                                            boolean&nbsp;isBinaryAsString,
                                                                                            boolean&nbsp;isInt96AsTimestamp)</pre>
</li>
</ul>
<a name="convertFromAttributes(scala.collection.Seq, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>convertFromAttributes</h4>
<pre>public static&nbsp;parquet.schema.MessageType&nbsp;convertFromAttributes(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;attributes,
                                               boolean&nbsp;toThriftSchemaNames)</pre>
</li>
</ul>
<a name="convertFromString(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>convertFromString</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;convertFromString(String&nbsp;string)</pre>
</li>
</ul>
<a name="convertToString(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>convertToString</h4>
<pre>public static&nbsp;String&nbsp;convertToString(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;schema)</pre>
</li>
</ul>
<a name="writeMetaData(scala.collection.Seq, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>writeMetaData</h4>
<pre>public static&nbsp;void&nbsp;writeMetaData(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;attributes,
                 org.apache.hadoop.fs.Path&nbsp;origPath,
                 org.apache.hadoop.conf.Configuration&nbsp;conf)</pre>
</li>
</ul>
<a name="readMetaData(org.apache.hadoop.fs.Path, scala.Option)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>readMetaData</h4>
<pre>public static&nbsp;parquet.hadoop.metadata.ParquetMetadata&nbsp;readMetaData(org.apache.hadoop.fs.Path&nbsp;origPath,
                                                   scala.Option&lt;org.apache.hadoop.conf.Configuration&gt;&nbsp;configuration)</pre>
<div class="block">Try to read Parquet metadata at the given Path. We first see if there is a summary file
 in the parent directory. If so, this is used. Else we read the actual footer at the given
 location.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>origPath</code> - The path at which we expect one (or more) Parquet files.</dd><dd><code>configuration</code> - The Hadoop configuration to use.</dd>
<dt><span class="strong">Returns:</span></dt><dd>The <code>ParquetMetadata</code> containing among other things the schema.</dd></dl>
</li>
</ul>
<a name="readSchemaFromFile(org.apache.hadoop.fs.Path, scala.Option, boolean, boolean)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>readSchemaFromFile</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;readSchemaFromFile(org.apache.hadoop.fs.Path&nbsp;origPath,
                                                                                           scala.Option&lt;org.apache.hadoop.conf.Configuration&gt;&nbsp;conf,
                                                                                           boolean&nbsp;isBinaryAsString,
                                                                                           boolean&nbsp;isInt96AsTimestamp)</pre>
<div class="block">Reads in Parquet Metadata from the given path and tries to extract the schema
 (Catalyst attributes) from the application-specific key-value map. If this
 is empty it falls back to converting from the Parquet file schema which
 may lead to an upcast of types (e.g., {byte, short} to int).
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>origPath</code> - The path at which we expect one (or more) Parquet files.</dd><dd><code>conf</code> - The Hadoop configuration to use.</dd>
<dt><span class="strong">Returns:</span></dt><dd>A list of attributes that make up the schema.</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/parquet/ParquetTypeInfo.html" title="class in org.apache.spark.sql.parquet"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/parquet/Partition.html" title="class in org.apache.spark.sql.parquet"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/parquet/ParquetTypesConverter.html" target="_top">Frames</a></li>
<li><a href="ParquetTypesConverter.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
