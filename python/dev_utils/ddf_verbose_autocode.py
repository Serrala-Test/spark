"""
Autogeneration of code for dynamic dataframe.
Check result in `pyspark/sql/dynamic_dataframe.py`
"""
fluent_methods = {
    "alias": ["*args", "**kwargs"],
    "checkpoint": ["*args", "**kwargs"],
    "coalesce": ["*args", "**kwargs"],
    "crossJoin": ["*args", "**kwargs"],
    "distinct": [],
    "drop": ["*args", "**kwargs"],
    "dropDuplicates": ["*args", "**kwargs"],
    "dropna": ["*args", "**kwargs"],
    "fillna": ["*args", "**kwargs"],
    "filter": ["*args", "**kwargs"],
    "exceptAll": ["*args", "**kwargs"],
    "hint": ["*args", "**kwargs"],
    "intersect": ["*args", "**kwargs"],
    "intersectAll": ["*args", "**kwargs"],
    "join": ["*args", "**kwargs"],
    "limit": ["*args", "**kwargs"],
    "localCheckpoint": ["*args", "**kwargs"],
    "orderBy": ["*args", "**kwargs"],
    "repartition": ["*args", "**kwargs"],
    "repartitionByRange": ["*args", "**kwargs"],
    "replace": ["*args", "**kwargs"],
    "sample": ["*args", "**kwargs"],
    "sampleBy": ["*args", "**kwargs"],
    "select": ["*args"],
    "selectExpr": ["*args"],
    "sort": ["*args", "**kwargs"],
    "sortWithinPartitions": ["*args", "**kwargs"],
    "subtract": ["*args", "**kwargs"],
    "transform": ["*args", "**kwargs"],
    "union": ["*args", "**kwargs"],
    "unionByName": ["*args", "**kwargs"],
    "withColumn": ["*args", "**kwargs"],
    "withColumnRenamed": ["*args", "**kwargs"],
    "withWatermark": ["*args", "**kwargs"],
}
print(
    '''"""
This code is autogenerated by `dev_utils/ddf_verbose_autocode.py`
"""'''
)
print(
    """
from __future__ import annotations
import typing

from pyspark.sql import DataFrame
"""
)


print(
    """
class DynamicDataFrame(DataFrame):
    def __init__(self, df: DataFrame):
        super().__init__(df._jdf, df.sql_ctx)"""
)


for method in fluent_methods:
    variables = fluent_methods[method]
    signature_1 = ", ".join(["self: DynamicDataFrame"] + variables)
    signature_2 = ", ".join(variables)
    print(
        f"""
    def {method}({signature_1}) -> DynamicDataFrame:
        return self.__class__(super().{method}({signature_2}))"""
    )
print(
    f"""
    def randomSplit(self, *args, **kwargs):
        return [self.__class__(df) for df in super().randomSplit(*args, **kwargs)]"""
)
print(
    f"""
    def toDF(self) -> DataFrame:
        return DataFrame(self._jdf, self.sql_ctx)"""
)
