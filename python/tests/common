function run_test() {
    echo -en "Running test: $1 ... " | tee -a $LOG_FILE
    start=$(date +"%s")
    SPARK_TESTING=1 time "$FWDIR"/bin/pyspark $1 > $LOG_FILE 2>&1

    FAILED=$((PIPESTATUS[0]||$FAILED))

    # Fail and exit on the first test failure.
    if [[ $FAILED != 0 ]]; then
        cat $LOG_FILE | grep -v "^[0-9][0-9]*" # filter all lines starting with a number.
        echo -en "\033[31m"  # Red
        echo "Had test failures; see logs."
        echo -en "\033[0m"  # No color
        exit -1
    else
        now=$(date +"%s")
        echo "ok ($(($now - $start))s)"
    fi
}

function run_core_tests() {
    if [ $DO_CORE_TESTS == 0 ]; then
        return 0
    fi

    echo "Run core tests ..."
    run_test "pyspark.rdd"
    run_test "pyspark.context"
    run_test "pyspark.conf"
    run_test "pyspark.broadcast"
    run_test "pyspark.accumulators"
    run_test "pyspark.serializers"
    run_test "pyspark.profiler"
    run_test "pyspark.shuffle"
    run_test "pyspark.tests"
}

function run_sql_tests() {
    if [ $DO_SQL_TESTS == 0 ]; then
        return 0
    fi

    echo "Run sql tests ..."
    run_test "pyspark.sql.types"
    run_test "pyspark.sql.context"
    run_test "pyspark.sql.column"
    run_test "pyspark.sql.dataframe"
    run_test "pyspark.sql.group"
    run_test "pyspark.sql.functions"
    run_test "pyspark.sql.readwriter"
    run_test "pyspark.sql.window"
    run_test "pyspark.sql.tests"
}

function run_mllib_tests() {
    if [ $DO_MLLIB_TESTS == 0 ]; then
        return 0
    fi

    echo "Run mllib tests ..."
    run_test "pyspark.mllib.classification"
    run_test "pyspark.mllib.clustering"
    run_test "pyspark.mllib.evaluation"
    run_test "pyspark.mllib.feature"
    run_test "pyspark.mllib.fpm"
    run_test "pyspark.mllib.linalg"
    run_test "pyspark.mllib.random"
    run_test "pyspark.mllib.recommendation"
    run_test "pyspark.mllib.regression"
    run_test "pyspark.mllib.stat._statistics"
    run_test "pyspark.mllib.stat.KernelDensity"
    run_test "pyspark.mllib.tree"
    run_test "pyspark.mllib.util"
    run_test "pyspark.mllib.tests"
}

function run_ml_tests() {
    if [ $DO_ML_TESTS == 0 ]; then
        return 0
    fi

    echo "Run ml tests ..."
    run_test "pyspark.ml.feature"
    run_test "pyspark.ml.classification"
    run_test "pyspark.ml.recommendation"
    run_test "pyspark.ml.regression"
    run_test "pyspark.ml.tuning"
    run_test "pyspark.ml.tests"
    run_test "pyspark.ml.evaluation"
}

function run_streaming_tests() {
    if [ $DO_STREAMING_TESTS == 0 ]; then
        return 0
    fi

    echo "Run streaming tests ..."

    KAFKA_ASSEMBLY_DIR="$FWDIR"/external/kafka-assembly
    JAR_PATH="${KAFKA_ASSEMBLY_DIR}/target/scala-${SPARK_SCALA_VERSION}"
    for f in "${JAR_PATH}"/spark-streaming-kafka-assembly-*.jar; do
      if [[ ! -e "$f" ]]; then
        echo "Failed to find Spark Streaming Kafka assembly jar in $KAFKA_ASSEMBLY_DIR" 1>&2
        echo "You need to build Spark with " \
             "'build/sbt assembly/assembly streaming-kafka-assembly/assembly' or" \
             "'build/mvn package' before running this program" 1>&2
        exit 1
      fi
      KAFKA_ASSEMBLY_JAR="$f"
    done

    export PYSPARK_SUBMIT_ARGS="--jars ${KAFKA_ASSEMBLY_JAR} pyspark-shell"
    run_test "pyspark.streaming.util"
    run_test "pyspark.streaming.tests"
}
