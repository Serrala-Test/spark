/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";
package org.apache.spark.status.protobuf;

enum JobExecutionStatus {
  UNSPECIFIED = 0;
  RUNNING = 1;
  SUCCEEDED = 2;
  FAILED = 3;
  UNKNOWN = 4;
}

message JobData {
  // All IDs are int64 for extendability, even when they are currently int32 in Spark.
  int64 job_id = 1;
  string name = 2;
  optional string description = 3;
  optional int64 submission_time = 4;
  optional int64 completion_time = 5;
  repeated int64 stage_ids = 6;
  optional string job_group = 7;
  JobExecutionStatus status = 8;
  int32 num_tasks = 9;
  int32 num_active_tasks = 10;
  int32 num_completed_tasks = 11;
  int32 num_skipped_tasks = 12;
  int32 num_failed_tasks = 13;
  int32 num_killed_tasks = 14;
  int32 num_completed_indices = 15;
  int32 num_active_stages = 16;
  int32 num_completed_stages = 17;
  int32 num_skipped_stages = 18;
  int32 num_failed_stages = 19;
  map<string, int32> kill_tasks_summary = 20;
}

message JobDataWrapper {
  JobData info = 1;
  repeated int32 skipped_stages = 2;
  optional int64 sql_execution_id = 3;
}

message AccumulableInfo {
  int64 id = 1;
  string name = 2;
  optional string update = 3;
  string value = 4;
}

message TaskDataWrapper {
  int64 task_id = 1;
  int32 index = 2;
  int32 attempt = 3;
  int32 partition_id = 4;
  int64 launch_time = 5;
  int64 result_fetch_start = 6;
  int64 duration = 7;
  string executor_id = 8;
  string host = 9;
  string status = 10;
  string task_locality = 11;
  bool speculative = 12;
  repeated AccumulableInfo accumulator_updates = 13;
  optional string error_message = 14;
  bool has_metrics = 15;
  int64 executor_deserialize_time = 16;
  int64 executor_deserialize_cpu_time = 17;
  int64 executor_run_time = 18;
  int64 executor_cpu_time = 19;
  int64 result_size = 20;
  int64 jvm_gc_time = 21;
  int64 result_serialization_time = 22;
  int64 memory_bytes_spilled = 23;
  int64 disk_bytes_spilled = 24;
  int64 peak_execution_memory = 25;
  int64 input_bytes_read = 26;
  int64 input_records_read = 27;
  int64 output_bytes_written = 28;
  int64 output_records_written = 29;
  int64 shuffle_remote_blocks_fetched = 30;
  int64 shuffle_local_blocks_fetched = 31;
  int64 shuffle_fetch_wait_time = 32;
  int64 shuffle_remote_bytes_read = 33;
  int64 shuffle_remote_bytes_read_to_disk = 34;
  int64 shuffle_local_bytes_read = 35;
  int64 shuffle_records_read = 36;
  int64 shuffle_bytes_written = 37;
  int64 shuffle_write_time = 38;
  int64 shuffle_records_written = 39;
  int64 stage_id = 40;
  int32 stage_attempt_id = 41;
}

message ExecutorMetrics {
  map<string, int64> metrics = 1;
}

message ExecutorStageSummary {
  int64 task_time = 1;
  int32 failed_tasks = 2;
  int32 succeeded_tasks = 3;
  int32 killed_tasks = 4;
  int64 input_bytes = 5;
  int64 input_records = 6;
  int64 output_bytes = 7;
  int64 output_records = 8;
  int64 shuffle_read = 9;
  int64 shuffle_read_records = 10;
  int64 shuffle_write = 11;
  int64 shuffle_write_records = 12;
  int64 memory_bytes_spilled = 13;
  int64 disk_bytes_spilled = 14;
  bool is_blacklisted_for_stage = 15;
  optional ExecutorMetrics peak_memory_metrics = 16;
  bool is_excluded_for_stage = 17;
}

message ExecutorStageSummaryWrapper {
  int64 stage_id = 1;
  int32 stage_attempt_id = 2;
  string executor_id = 3;
  ExecutorStageSummary info = 4;
}

message ExecutorResourceRequest {
  string resource_name = 1;
  int64 amount = 2;
  string discoveryScript = 3;
  string vendor = 4;
}

message TaskResourceRequest {
  string resource_name = 1;
  double amount = 2;
}

message ResourceProfileInfo {
  int32 id = 1;
  map<string, ExecutorResourceRequest> executor_resources = 2;
  map<string, TaskResourceRequest> task_resources = 3;
}

message RuntimeInfo {
  string java_version = 1;
  string java_home = 2;
  string scala_version = 3;
}

message PairStrings {
  string value1 = 1;
  string value2 = 2;
}

message ApplicationEnvironmentInfo {
  RuntimeInfo runtime = 1;
  repeated PairStrings spark_properties = 2;
  repeated PairStrings hadoop_properties = 3;
  repeated PairStrings system_properties = 4;
  repeated PairStrings metrics_properties = 5;
  repeated PairStrings classpath_entries = 6;
  repeated ResourceProfileInfo resource_profiles = 7;
}

message ApplicationEnvironmentInfoWrapper {
  ApplicationEnvironmentInfo info = 1;
}

message ApplicationAttemptInfo {
  optional string attempt_id = 1;
  int64 start_time = 2;
  int64 end_time = 3;
  int64 last_updated = 4;
  int64 duration = 5;
  string spark_user = 6;
  bool completed = 7;
  string app_spark_version = 8;
}

message ApplicationInfo {
  string id = 1;
  string name = 2;
  optional int32 cores_granted = 3;
  optional int32 max_cores = 4;
  optional int32 cores_per_executor = 5;
  optional int32 memory_per_executor_mb = 6;
  repeated ApplicationAttemptInfo attempts = 7;
}

message ApplicationInfoWrapper {
  ApplicationInfo info = 1;
}
