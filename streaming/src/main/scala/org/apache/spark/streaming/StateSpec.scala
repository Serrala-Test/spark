/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.spark.streaming

import scala.reflect.ClassTag

import org.apache.spark.annotation.Experimental
import org.apache.spark.api.java.JavaPairRDD
import org.apache.spark.rdd.RDD
import org.apache.spark.{HashPartitioner, Partitioner}


/**
 * :: Experimental ::
 * Abstract class representing all the specifications of the DStream transformation
 * `trackStateByKey` operation of a
 * [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] (Scala) or a
 * [[org.apache.spark.streaming.api.java.JavaPairDStream JavaPairDStream]] (Java).
 * Use the [[org.apache.spark.streaming.StateSpec StateSpec.apply()]] or
 * [[org.apache.spark.streaming.StateSpec StateSpec.create()]] to create instances of
 * this class.
 *
 * Example in Scala:
 * {{{
 *    val spec = StateSpec(trackingFunction).numPartitions(10)
 *
 *    val emittedRecordDStream = keyValueDStream.trackStateByKey[StateType, EmittedDataType](spec)
 * }}}
 *
 * Example in Java:
 * {{{
 *    StateStateSpec[StateType, EmittedDataType] spec =
 *      StateStateSpec.create[StateType, EmittedDataType](trackingFunction).numPartition(10);
 *
 *    JavaDStream[EmittedDataType] emittedRecordDStream =
 *      javaPairDStream.trackStateByKey[StateType, EmittedDataType](spec);
 * }}}
 */
@Experimental
sealed abstract class StateSpec[K, V, S, T] extends Serializable {

  /** Set the RDD containing the initial states that will be used by `trackStateByKey`*/
  def initialState(rdd: RDD[(K, S)]): this.type

  /** Set the RDD containing the initial states that will be used by `trackStateByKey`*/
  def initialState(javaPairRDD: JavaPairRDD[K, S]): this.type

  /**
   * Set the number of partitions by which the state RDDs generated by `trackStateByKey`
   * will be partitioned. Hash partitioning will be used on the
   */
  def numPartitions(numPartitions: Int): this.type

  /**
   * Set the partitioner by which the state RDDs generated by `trackStateByKey` will be
   * be partitioned.
   */
  def partitioner(partitioner: Partitioner): this.type

  /**
   * Set the duration after which the state of an idle key will be removed. A key and its state is
   * considered idle if it has not received any data for at least the given duration. The state
   * tracking function will be called one final time on the idle states that are going to be
   * removed; [[org.apache.spark.streaming.State State.isTimingOut()]] set
   * to `true` in that call.
   */
  def timeout(idleDuration: Duration): this.type
}


/**
 * :: Experimental ::
 * Builder object for creating instances of [[org.apache.spark.streaming.StateSpec StateSpec]]
 * that is used for specifying the parameters of the DStream transformation
 * `trackStateByKey` operation of a
 * [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] (Scala) or a
 * [[org.apache.spark.streaming.api.java.JavaPairDStream JavaPairDStream]] (Java).
 *
 * Example in Scala:
 * {{{
 *    val spec = StateSpec(trackingFunction).numPartitions(10)
 *
 *    val emittedRecordDStream = keyValueDStream.trackStateByKey[StateType, EmittedDataType](spec)
 * }}}
 *
 * Example in Java:
 * {{{
 *    StateStateSpec[StateType, EmittedDataType] spec =
 *      StateStateSpec.create[StateType, EmittedDataType](trackingFunction).numPartition(10);
 *
 *    JavaDStream[EmittedDataType] emittedRecordDStream =
 *      javaPairDStream.trackStateByKey[StateType, EmittedDataType](spec);
 * }}}
 */
@Experimental
object StateSpec {
  /**
   *
   * @param trackingFunction
   * @tparam KeyType Class of keys
   * @tparam ValueType
   * @tparam StateType
   * @tparam EmittedType
   * @return
   */
  def apply[KeyType, ValueType, StateType, EmittedType](
      trackingFunction: (KeyType, Option[ValueType], State[StateType]) => Option[EmittedType]
    ): StateSpec[KeyType, ValueType, StateType, EmittedType] = {
    new StateSpecImpl[KeyType, ValueType, StateType, EmittedType](trackingFunction)
  }

  def create[KeyType, ValueType, StateType, EmittedType](
      trackingFunction: (KeyType, Option[ValueType], State[StateType]) => Option[EmittedType]
    ): StateSpec[KeyType, ValueType, StateType, EmittedType] = {
    apply(trackingFunction)
  }
}


/** Internal implementation of [[org.apache.spark.streaming.StateSpec]] interface. */
private[streaming]
case class StateSpecImpl[K, V, S, T](
    function: (K, Option[V], State[S]) => Option[T]) extends StateSpec[K, V, S, T] {

  require(function != null)

  @volatile private var partitioner: Partitioner = null
  @volatile private var initialStateRDD: RDD[(K, S)] = null
  @volatile private var timeoutInterval: Duration = null

  def initialState(rdd: RDD[(K, S)]): this.type = {
    this.initialStateRDD = rdd
    this
  }

  def initialState(javaPairRDD: JavaPairRDD[K, S]): this.type = {
    this.initialStateRDD = javaPairRDD.rdd
    this
  }


  def numPartitions(numPartitions: Int): this.type = {
    this.partitioner(new HashPartitioner(numPartitions))
    this
  }

  def partitioner(partitioner: Partitioner): this.type = {
    this.partitioner = partitioner
    this
  }

  def timeout(interval: Duration): this.type = {
    this.timeoutInterval = interval
    this
  }

  // ================= Private Methods =================

  private[streaming] def getFunction(): (K, Option[V], State[S]) => Option[T] = function

  private[streaming] def getInitialStateRDD(): Option[RDD[(K, S)]] = Option(initialStateRDD)

  private[streaming] def getPartitioner(): Option[Partitioner] = Option(partitioner)

  private[streaming] def getTimeoutInterval(): Option[Duration] = Option(timeoutInterval)
}
