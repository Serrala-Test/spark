#!/usr/bin/env bash

set -x
set -e

FWDIR="$(cd `dirname $0`/..; pwd)"
SHA=$(git rev-parse HEAD)

# Compile spark jars into dist folder
export LOCAL_SBT_DIR=1
export SBT_HOME=$FWDIR/sbt
export SCALA_HOME=$HOME/.sbt/boot/scala-2.10.3

# Find JAVA_HOME on OS X and Linux
uname=$(uname)
if [[ "$uname" == "Darwin" ]]; then
  JAVA_HOME=$(/usr/libexec/java_home -v 1.7)
else
  JAVA_HOME=/usr/lib/jvm/default-java/
fi
export JAVA_HOME=$JAVA_HOME

./make-distribution.sh --skip-java-test -Phive -Dhadoop.version=$(cat SHOPIFY_HADOOP_VERSION)

if [ "$?" != "0" ] || [ -e "$FWDIR/lib/spark-assembly*hadoop*.jar" ]; then
  echo "Failed to make spark distro using sbt."
  exit 1
fi

# Remove everything not in dist or conf
find * -maxdepth 0 -name 'dist' -o -name 'conf' -prune -o -exec rm -rf '{}' ';'

# Copy everything out of dist that doesn't exist already
mv -n dist/* .
echo $SHA > ./GIT_SHA
