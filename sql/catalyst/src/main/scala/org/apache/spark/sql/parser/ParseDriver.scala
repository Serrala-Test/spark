/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.spark.sql.parser


import java.util

import org.antlr.runtime._
import org.antlr.runtime.tree.CommonTree

import org.apache.spark.Logging

/**
 * The ParseDriver takes a SQL command and turns this into an AST.
 *
 * This is based on Hive's org.apache.hadoop.hive.ql.parse.ParseDriver
 */
object ParseDriver extends Logging {
  def parse(command: String, conf: ParserConf): ASTNode = {
    logInfo(s"Parsing command: $command")

    // Create lexer.
    val lexer = new SparkSqlLexer(new ANTLRNoCaseStringStream(command))
    val tokens = new TokenRewriteStream(lexer)
    lexer.setParserConf(conf)

    // Create the parser.
    val parser = new SparkSqlParser(tokens)
    parser.setParserConf(conf)

    try {
      val result = parser.statement()

      // Check lexer errors.
      val errors = new util.ArrayList[ParseError]
      errors.addAll(lexer.errors)
      errors.addAll(parser.errors)
      if (errors.size > 0) {
        logInfo(s"Parse failed.")
        throw new ParseException(errors)
      }

      // Return the AST node from the result.
      logInfo(s"Parse completed.")

      // Find the non null token tree in the result.
      def nonNullToken(tree: CommonTree): CommonTree = {
        if (tree.token != null || tree.getChildCount == 0) tree
        else nonNullToken(tree.getChild(0).asInstanceOf[CommonTree])
      }
      val tree = nonNullToken(result.getTree)

      // Make sure all boundaries are set.
      tree.setUnknownTokenBoundaries()

      // Construct the immutable AST.
      def createASTNode(tree: CommonTree): ASTNode = {
        val children = (0 until tree.getChildCount).map { i =>
          createASTNode(tree.getChild(i).asInstanceOf[CommonTree])
        }.toList
        ASTNode(tree.token, tree.getTokenStartIndex, tree.getTokenStopIndex, children, tokens)
      }
      createASTNode(tree)
    }
    catch {
      case e: RecognitionException =>
        logInfo(s"Parse failed.")
        throw new ParseException(parser.errors)
    }
  }
}

/**
 * This string stream provides the lexer with upper case characters only. This greatly simplifies
 * lexing the stream, while we can maintain the original command.
 *
 * This is based on Hive's org.apache.hadoop.hive.ql.parse.ParseDriver.ANTLRNoCaseStringStream
 *
 * The comment below (taken from the original class) describes the rationale for doing this:
 *
 * This class provides and implementation for a case insensitive token checker for the lexical
 * analysis part of antlr. By converting the token stream into upper case at the time when lexical
 * rules are checked, this class ensures that the lexical rules need to just match the token with
 * upper case letters as opposed to combination of upper case and lower case characters. This is
 * purely used for matching lexical rules. The actual token text is stored in the same way as the
 * user input without actually converting it into an upper case. The token values are generated by
 * the consume() function of the super class ANTLRStringStream. The LA() function is the lookahead
 * function and is purely used for matching lexical rules. This also means that the grammar will
 * only accept capitalized tokens in case it is run from other tools like antlrworks which do not
 * have the ANTLRNoCaseStringStream implementation.
 */

private[parser] class ANTLRNoCaseStringStream(input: String) extends ANTLRStringStream(input) {
  override def LA(i: Int): Int = {
    val la = super.LA(i)
    if (la == 0 || la == CharStream.EOF) la
    else Character.toUpperCase(la)
  }
}
