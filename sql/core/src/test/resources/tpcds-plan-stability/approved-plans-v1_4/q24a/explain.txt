== Physical Plan ==
* Project (45)
+- * Filter (44)
   +- * HashAggregate (43)
      +- Exchange (42)
         +- * HashAggregate (41)
            +- * HashAggregate (40)
               +- Exchange (39)
                  +- * HashAggregate (38)
                     +- * Project (37)
                        +- * BroadcastHashJoin Inner BuildRight (36)
                           :- * Project (30)
                           :  +- * BroadcastHashJoin Inner BuildRight (29)
                           :     :- * Project (23)
                           :     :  +- * BroadcastHashJoin Inner BuildRight (22)
                           :     :     :- * Project (16)
                           :     :     :  +- * BroadcastHashJoin Inner BuildRight (15)
                           :     :     :     :- * Project (9)
                           :     :     :     :  +- * BroadcastHashJoin Inner BuildRight (8)
                           :     :     :     :     :- * Filter (3)
                           :     :     :     :     :  +- * ColumnarToRow (2)
                           :     :     :     :     :     +- Scan parquet default.store_sales (1)
                           :     :     :     :     +- BroadcastExchange (7)
                           :     :     :     :        +- * Filter (6)
                           :     :     :     :           +- * ColumnarToRow (5)
                           :     :     :     :              +- Scan parquet default.store_returns (4)
                           :     :     :     +- BroadcastExchange (14)
                           :     :     :        +- * Project (13)
                           :     :     :           +- * Filter (12)
                           :     :     :              +- * ColumnarToRow (11)
                           :     :     :                 +- Scan parquet default.store (10)
                           :     :     +- BroadcastExchange (21)
                           :     :        +- * Project (20)
                           :     :           +- * Filter (19)
                           :     :              +- * ColumnarToRow (18)
                           :     :                 +- Scan parquet default.item (17)
                           :     +- BroadcastExchange (28)
                           :        +- * Project (27)
                           :           +- * Filter (26)
                           :              +- * ColumnarToRow (25)
                           :                 +- Scan parquet default.customer (24)
                           +- BroadcastExchange (35)
                              +- * Project (34)
                                 +- * Filter (33)
                                    +- * ColumnarToRow (32)
                                       +- Scan parquet default.customer_address (31)


(1) Scan parquet default.store_sales
Output [5]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_net_paid#5]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_ticket_number), IsNotNull(ss_item_sk), IsNotNull(ss_store_sk), IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_item_sk:int,ss_customer_sk:int,ss_store_sk:int,ss_ticket_number:int,ss_net_paid:decimal(7,2)>

(2) ColumnarToRow [codegen id : 6]
Input [5]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_net_paid#5]

(3) Filter [codegen id : 6]
Input [5]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_net_paid#5]
Condition : (((isnotnull(ss_ticket_number#4) AND isnotnull(ss_item_sk#1)) AND isnotnull(ss_store_sk#3)) AND isnotnull(ss_customer_sk#2))

(4) Scan parquet default.store_returns
Output [2]: [sr_item_sk#6, sr_ticket_number#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_returns]
PushedFilters: [IsNotNull(sr_ticket_number), IsNotNull(sr_item_sk)]
ReadSchema: struct<sr_item_sk:bigint,sr_ticket_number:bigint>

(5) ColumnarToRow [codegen id : 1]
Input [2]: [sr_item_sk#6, sr_ticket_number#7]

(6) Filter [codegen id : 1]
Input [2]: [sr_item_sk#6, sr_ticket_number#7]
Condition : (isnotnull(sr_ticket_number#7) AND isnotnull(sr_item_sk#6))

(7) BroadcastExchange
Input [2]: [sr_item_sk#6, sr_ticket_number#7]
Arguments: HashedRelationBroadcastMode(List(input[1, bigint, false], input[0, bigint, false]),false), [id=#8]

(8) BroadcastHashJoin [codegen id : 6]
Left keys [2]: [cast(ss_ticket_number#4 as bigint), cast(ss_item_sk#1 as bigint)]
Right keys [2]: [sr_ticket_number#7, sr_item_sk#6]
Join condition: None

(9) Project [codegen id : 6]
Output [4]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_net_paid#5]
Input [7]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_net_paid#5, sr_item_sk#6, sr_ticket_number#7]

(10) Scan parquet default.store
Output [5]: [s_store_sk#9, s_store_name#10, s_market_id#11, s_state#12, s_zip#13]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_market_id), EqualTo(s_market_id,8), IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_name:string,s_market_id:int,s_state:string,s_zip:string>

(11) ColumnarToRow [codegen id : 2]
Input [5]: [s_store_sk#9, s_store_name#10, s_market_id#11, s_state#12, s_zip#13]

(12) Filter [codegen id : 2]
Input [5]: [s_store_sk#9, s_store_name#10, s_market_id#11, s_state#12, s_zip#13]
Condition : (((isnotnull(s_market_id#11) AND (s_market_id#11 = 8)) AND isnotnull(s_store_sk#9)) AND isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, s_zip#13, 10, false, true)))

(13) Project [codegen id : 2]
Output [4]: [s_store_sk#9, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, s_store_name#10, 50, false, true) AS s_store_name#14, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, s_state#12, 2, false, true) AS s_state#15, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, s_zip#13, 10, false, true) AS s_zip#16]
Input [5]: [s_store_sk#9, s_store_name#10, s_market_id#11, s_state#12, s_zip#13]

(14) BroadcastExchange
Input [4]: [s_store_sk#9, s_store_name#14, s_state#15, s_zip#16]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#17]

(15) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#9]
Join condition: None

(16) Project [codegen id : 6]
Output [6]: [ss_item_sk#1, ss_customer_sk#2, ss_net_paid#5, s_store_name#14, s_state#15, s_zip#16]
Input [8]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_net_paid#5, s_store_sk#9, s_store_name#14, s_state#15, s_zip#16]

(17) Scan parquet default.item
Output [6]: [i_item_sk#18, i_current_price#19, i_size#20, i_color#21, i_units#22, i_manager_id#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_current_price:decimal(7,2),i_size:string,i_color:string,i_units:string,i_manager_id:int>

(18) ColumnarToRow [codegen id : 3]
Input [6]: [i_item_sk#18, i_current_price#19, i_size#20, i_color#21, i_units#22, i_manager_id#23]

(19) Filter [codegen id : 3]
Input [6]: [i_item_sk#18, i_current_price#19, i_size#20, i_color#21, i_units#22, i_manager_id#23]
Condition : ((staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, i_color#21, 20, false, true) = pale                ) AND isnotnull(i_item_sk#18))

(20) Project [codegen id : 3]
Output [6]: [i_item_sk#18, i_current_price#19, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, i_size#20, 20, false, true) AS i_size#24, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, i_color#21, 20, false, true) AS i_color#25, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, i_units#22, 10, false, true) AS i_units#26, i_manager_id#23]
Input [6]: [i_item_sk#18, i_current_price#19, i_size#20, i_color#21, i_units#22, i_manager_id#23]

(21) BroadcastExchange
Input [6]: [i_item_sk#18, i_current_price#19, i_size#24, i_color#25, i_units#26, i_manager_id#23]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#27]

(22) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#18]
Join condition: None

(23) Project [codegen id : 6]
Output [10]: [ss_customer_sk#2, ss_net_paid#5, s_store_name#14, s_state#15, s_zip#16, i_current_price#19, i_size#24, i_color#25, i_units#26, i_manager_id#23]
Input [12]: [ss_item_sk#1, ss_customer_sk#2, ss_net_paid#5, s_store_name#14, s_state#15, s_zip#16, i_item_sk#18, i_current_price#19, i_size#24, i_color#25, i_units#26, i_manager_id#23]

(24) Scan parquet default.customer
Output [4]: [c_customer_sk#28, c_first_name#29, c_last_name#30, c_birth_country#31]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string,c_birth_country:string>

(25) ColumnarToRow [codegen id : 4]
Input [4]: [c_customer_sk#28, c_first_name#29, c_last_name#30, c_birth_country#31]

(26) Filter [codegen id : 4]
Input [4]: [c_customer_sk#28, c_first_name#29, c_last_name#30, c_birth_country#31]
Condition : (isnotnull(c_customer_sk#28) AND isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, c_birth_country#31, 20, false, true)))

(27) Project [codegen id : 4]
Output [4]: [c_customer_sk#28, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, c_first_name#29, 20, false, true) AS c_first_name#32, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, c_last_name#30, 30, false, true) AS c_last_name#33, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, c_birth_country#31, 20, false, true) AS c_birth_country#34]
Input [4]: [c_customer_sk#28, c_first_name#29, c_last_name#30, c_birth_country#31]

(28) BroadcastExchange
Input [4]: [c_customer_sk#28, c_first_name#32, c_last_name#33, c_birth_country#34]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#35]

(29) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_customer_sk#2]
Right keys [1]: [c_customer_sk#28]
Join condition: None

(30) Project [codegen id : 6]
Output [12]: [ss_net_paid#5, s_store_name#14, s_state#15, s_zip#16, i_current_price#19, i_size#24, i_color#25, i_units#26, i_manager_id#23, c_first_name#32, c_last_name#33, c_birth_country#34]
Input [14]: [ss_customer_sk#2, ss_net_paid#5, s_store_name#14, s_state#15, s_zip#16, i_current_price#19, i_size#24, i_color#25, i_units#26, i_manager_id#23, c_customer_sk#28, c_first_name#32, c_last_name#33, c_birth_country#34]

(31) Scan parquet default.customer_address
Output [3]: [ca_state#36, ca_zip#37, ca_country#38]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer_address]
ReadSchema: struct<ca_state:string,ca_zip:string,ca_country:string>

(32) ColumnarToRow [codegen id : 5]
Input [3]: [ca_state#36, ca_zip#37, ca_country#38]

(33) Filter [codegen id : 5]
Input [3]: [ca_state#36, ca_zip#37, ca_country#38]
Condition : (isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, ca_country#38, 20, false, true)) AND isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, ca_zip#37, 10, false, true)))

(34) Project [codegen id : 5]
Output [3]: [staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, ca_state#36, 2, false, true) AS ca_state#39, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, ca_zip#37, 10, false, true) AS ca_zip#40, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, ca_country#38, 20, false, true) AS ca_country#41]
Input [3]: [ca_state#36, ca_zip#37, ca_country#38]

(35) BroadcastExchange
Input [3]: [ca_state#39, ca_zip#40, ca_country#41]
Arguments: HashedRelationBroadcastMode(List(upper(input[2, string, true]), input[1, string, true]),false), [id=#42]

(36) BroadcastHashJoin [codegen id : 6]
Left keys [2]: [c_birth_country#34, s_zip#16]
Right keys [2]: [upper(ca_country#41), ca_zip#40]
Join condition: None

(37) Project [codegen id : 6]
Output [11]: [ss_net_paid#5, s_store_name#14, s_state#15, i_current_price#19, i_size#24, i_color#25, i_units#26, i_manager_id#23, c_first_name#32, c_last_name#33, ca_state#39]
Input [15]: [ss_net_paid#5, s_store_name#14, s_state#15, s_zip#16, i_current_price#19, i_size#24, i_color#25, i_units#26, i_manager_id#23, c_first_name#32, c_last_name#33, c_birth_country#34, ca_state#39, ca_zip#40, ca_country#41]

(38) HashAggregate [codegen id : 6]
Input [11]: [ss_net_paid#5, s_store_name#14, s_state#15, i_current_price#19, i_size#24, i_color#25, i_units#26, i_manager_id#23, c_first_name#32, c_last_name#33, ca_state#39]
Keys [10]: [c_last_name#33, c_first_name#32, s_store_name#14, ca_state#39, s_state#15, i_color#25, i_current_price#19, i_manager_id#23, i_units#26, i_size#24]
Functions [1]: [partial_sum(UnscaledValue(ss_net_paid#5))]
Aggregate Attributes [1]: [sum#43]
Results [11]: [c_last_name#33, c_first_name#32, s_store_name#14, ca_state#39, s_state#15, i_color#25, i_current_price#19, i_manager_id#23, i_units#26, i_size#24, sum#44]

(39) Exchange
Input [11]: [c_last_name#33, c_first_name#32, s_store_name#14, ca_state#39, s_state#15, i_color#25, i_current_price#19, i_manager_id#23, i_units#26, i_size#24, sum#44]
Arguments: hashpartitioning(c_last_name#33, c_first_name#32, s_store_name#14, ca_state#39, s_state#15, i_color#25, i_current_price#19, i_manager_id#23, i_units#26, i_size#24, 5), ENSURE_REQUIREMENTS, [id=#45]

(40) HashAggregate [codegen id : 7]
Input [11]: [c_last_name#33, c_first_name#32, s_store_name#14, ca_state#39, s_state#15, i_color#25, i_current_price#19, i_manager_id#23, i_units#26, i_size#24, sum#44]
Keys [10]: [c_last_name#33, c_first_name#32, s_store_name#14, ca_state#39, s_state#15, i_color#25, i_current_price#19, i_manager_id#23, i_units#26, i_size#24]
Functions [1]: [sum(UnscaledValue(ss_net_paid#5))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_net_paid#5))#46]
Results [4]: [c_last_name#33, c_first_name#32, s_store_name#14, MakeDecimal(sum(UnscaledValue(ss_net_paid#5))#46,17,2) AS netpaid#47]

(41) HashAggregate [codegen id : 7]
Input [4]: [c_last_name#33, c_first_name#32, s_store_name#14, netpaid#47]
Keys [3]: [c_last_name#33, c_first_name#32, s_store_name#14]
Functions [1]: [partial_sum(netpaid#47)]
Aggregate Attributes [2]: [sum#48, isEmpty#49]
Results [5]: [c_last_name#33, c_first_name#32, s_store_name#14, sum#50, isEmpty#51]

(42) Exchange
Input [5]: [c_last_name#33, c_first_name#32, s_store_name#14, sum#50, isEmpty#51]
Arguments: hashpartitioning(c_last_name#33, c_first_name#32, s_store_name#14, 5), ENSURE_REQUIREMENTS, [id=#52]

(43) HashAggregate [codegen id : 8]
Input [5]: [c_last_name#33, c_first_name#32, s_store_name#14, sum#50, isEmpty#51]
Keys [3]: [c_last_name#33, c_first_name#32, s_store_name#14]
Functions [1]: [sum(netpaid#47)]
Aggregate Attributes [1]: [sum(netpaid#47)#53]
Results [5]: [c_last_name#33, c_first_name#32, s_store_name#14, sum(netpaid#47)#53 AS paid#54, sum(netpaid#47)#53 AS sum(netpaid#47)#55]

(44) Filter [codegen id : 8]
Input [5]: [c_last_name#33, c_first_name#32, s_store_name#14, paid#54, sum(netpaid#47)#55]
Condition : (isnotnull(sum(netpaid#47)#55) AND (cast(sum(netpaid#47)#55 as decimal(33,8)) > cast(Subquery scalar-subquery#56, [id=#57] as decimal(33,8))))

(45) Project [codegen id : 8]
Output [4]: [c_last_name#33, c_first_name#32, s_store_name#14, paid#54]
Input [5]: [c_last_name#33, c_first_name#32, s_store_name#14, paid#54, sum(netpaid#47)#55]

===== Subqueries =====

Subquery:1 Hosting operator id = 44 Hosting Expression = Subquery scalar-subquery#56, [id=#57]
* HashAggregate (88)
+- Exchange (87)
   +- * HashAggregate (86)
      +- * HashAggregate (85)
         +- Exchange (84)
            +- * HashAggregate (83)
               +- * Project (82)
                  +- * BroadcastHashJoin Inner BuildRight (81)
                     :- * Project (75)
                     :  +- * BroadcastHashJoin Inner BuildRight (74)
                     :     :- * Project (68)
                     :     :  +- * BroadcastHashJoin Inner BuildRight (67)
                     :     :     :- * Project (61)
                     :     :     :  +- * BroadcastHashJoin Inner BuildRight (60)
                     :     :     :     :- * Project (54)
                     :     :     :     :  +- * BroadcastHashJoin Inner BuildRight (53)
                     :     :     :     :     :- * Filter (48)
                     :     :     :     :     :  +- * ColumnarToRow (47)
                     :     :     :     :     :     +- Scan parquet default.store_sales (46)
                     :     :     :     :     +- BroadcastExchange (52)
                     :     :     :     :        +- * Filter (51)
                     :     :     :     :           +- * ColumnarToRow (50)
                     :     :     :     :              +- Scan parquet default.store_returns (49)
                     :     :     :     +- BroadcastExchange (59)
                     :     :     :        +- * Project (58)
                     :     :     :           +- * Filter (57)
                     :     :     :              +- * ColumnarToRow (56)
                     :     :     :                 +- Scan parquet default.store (55)
                     :     :     +- BroadcastExchange (66)
                     :     :        +- * Project (65)
                     :     :           +- * Filter (64)
                     :     :              +- * ColumnarToRow (63)
                     :     :                 +- Scan parquet default.item (62)
                     :     +- BroadcastExchange (73)
                     :        +- * Project (72)
                     :           +- * Filter (71)
                     :              +- * ColumnarToRow (70)
                     :                 +- Scan parquet default.customer (69)
                     +- BroadcastExchange (80)
                        +- * Project (79)
                           +- * Filter (78)
                              +- * ColumnarToRow (77)
                                 +- Scan parquet default.customer_address (76)


(46) Scan parquet default.store_sales
Output [5]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_net_paid#5]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_ticket_number), IsNotNull(ss_item_sk), IsNotNull(ss_store_sk), IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_item_sk:int,ss_customer_sk:int,ss_store_sk:int,ss_ticket_number:int,ss_net_paid:decimal(7,2)>

(47) ColumnarToRow [codegen id : 6]
Input [5]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_net_paid#5]

(48) Filter [codegen id : 6]
Input [5]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_net_paid#5]
Condition : (((isnotnull(ss_ticket_number#4) AND isnotnull(ss_item_sk#1)) AND isnotnull(ss_store_sk#3)) AND isnotnull(ss_customer_sk#2))

(49) Scan parquet default.store_returns
Output [2]: [sr_item_sk#6, sr_ticket_number#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_returns]
PushedFilters: [IsNotNull(sr_ticket_number), IsNotNull(sr_item_sk)]
ReadSchema: struct<sr_item_sk:bigint,sr_ticket_number:bigint>

(50) ColumnarToRow [codegen id : 1]
Input [2]: [sr_item_sk#6, sr_ticket_number#7]

(51) Filter [codegen id : 1]
Input [2]: [sr_item_sk#6, sr_ticket_number#7]
Condition : (isnotnull(sr_ticket_number#7) AND isnotnull(sr_item_sk#6))

(52) BroadcastExchange
Input [2]: [sr_item_sk#6, sr_ticket_number#7]
Arguments: HashedRelationBroadcastMode(List(input[1, bigint, false], input[0, bigint, false]),false), [id=#58]

(53) BroadcastHashJoin [codegen id : 6]
Left keys [2]: [cast(ss_ticket_number#4 as bigint), cast(ss_item_sk#1 as bigint)]
Right keys [2]: [sr_ticket_number#7, sr_item_sk#6]
Join condition: None

(54) Project [codegen id : 6]
Output [4]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_net_paid#5]
Input [7]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_net_paid#5, sr_item_sk#6, sr_ticket_number#7]

(55) Scan parquet default.store
Output [5]: [s_store_sk#9, s_store_name#10, s_market_id#11, s_state#12, s_zip#13]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_market_id), EqualTo(s_market_id,8), IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_name:string,s_market_id:int,s_state:string,s_zip:string>

(56) ColumnarToRow [codegen id : 2]
Input [5]: [s_store_sk#9, s_store_name#10, s_market_id#11, s_state#12, s_zip#13]

(57) Filter [codegen id : 2]
Input [5]: [s_store_sk#9, s_store_name#10, s_market_id#11, s_state#12, s_zip#13]
Condition : (((isnotnull(s_market_id#11) AND (s_market_id#11 = 8)) AND isnotnull(s_store_sk#9)) AND isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, s_zip#13, 10, false, true)))

(58) Project [codegen id : 2]
Output [4]: [s_store_sk#9, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, s_store_name#10, 50, false, true) AS s_store_name#59, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, s_state#12, 2, false, true) AS s_state#60, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, s_zip#13, 10, false, true) AS s_zip#61]
Input [5]: [s_store_sk#9, s_store_name#10, s_market_id#11, s_state#12, s_zip#13]

(59) BroadcastExchange
Input [4]: [s_store_sk#9, s_store_name#59, s_state#60, s_zip#61]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#62]

(60) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#9]
Join condition: None

(61) Project [codegen id : 6]
Output [6]: [ss_item_sk#1, ss_customer_sk#2, ss_net_paid#5, s_store_name#59, s_state#60, s_zip#61]
Input [8]: [ss_item_sk#1, ss_customer_sk#2, ss_store_sk#3, ss_net_paid#5, s_store_sk#9, s_store_name#59, s_state#60, s_zip#61]

(62) Scan parquet default.item
Output [6]: [i_item_sk#18, i_current_price#19, i_size#20, i_color#21, i_units#22, i_manager_id#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_current_price:decimal(7,2),i_size:string,i_color:string,i_units:string,i_manager_id:int>

(63) ColumnarToRow [codegen id : 3]
Input [6]: [i_item_sk#18, i_current_price#19, i_size#20, i_color#21, i_units#22, i_manager_id#23]

(64) Filter [codegen id : 3]
Input [6]: [i_item_sk#18, i_current_price#19, i_size#20, i_color#21, i_units#22, i_manager_id#23]
Condition : isnotnull(i_item_sk#18)

(65) Project [codegen id : 3]
Output [6]: [i_item_sk#18, i_current_price#19, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, i_size#20, 20, false, true) AS i_size#63, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, i_color#21, 20, false, true) AS i_color#64, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, i_units#22, 10, false, true) AS i_units#65, i_manager_id#23]
Input [6]: [i_item_sk#18, i_current_price#19, i_size#20, i_color#21, i_units#22, i_manager_id#23]

(66) BroadcastExchange
Input [6]: [i_item_sk#18, i_current_price#19, i_size#63, i_color#64, i_units#65, i_manager_id#23]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#66]

(67) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#18]
Join condition: None

(68) Project [codegen id : 6]
Output [10]: [ss_customer_sk#2, ss_net_paid#5, s_store_name#59, s_state#60, s_zip#61, i_current_price#19, i_size#63, i_color#64, i_units#65, i_manager_id#23]
Input [12]: [ss_item_sk#1, ss_customer_sk#2, ss_net_paid#5, s_store_name#59, s_state#60, s_zip#61, i_item_sk#18, i_current_price#19, i_size#63, i_color#64, i_units#65, i_manager_id#23]

(69) Scan parquet default.customer
Output [4]: [c_customer_sk#28, c_first_name#29, c_last_name#30, c_birth_country#31]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string,c_birth_country:string>

(70) ColumnarToRow [codegen id : 4]
Input [4]: [c_customer_sk#28, c_first_name#29, c_last_name#30, c_birth_country#31]

(71) Filter [codegen id : 4]
Input [4]: [c_customer_sk#28, c_first_name#29, c_last_name#30, c_birth_country#31]
Condition : (isnotnull(c_customer_sk#28) AND isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, c_birth_country#31, 20, false, true)))

(72) Project [codegen id : 4]
Output [4]: [c_customer_sk#28, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, c_first_name#29, 20, false, true) AS c_first_name#67, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, c_last_name#30, 30, false, true) AS c_last_name#68, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, c_birth_country#31, 20, false, true) AS c_birth_country#69]
Input [4]: [c_customer_sk#28, c_first_name#29, c_last_name#30, c_birth_country#31]

(73) BroadcastExchange
Input [4]: [c_customer_sk#28, c_first_name#67, c_last_name#68, c_birth_country#69]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#70]

(74) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_customer_sk#2]
Right keys [1]: [c_customer_sk#28]
Join condition: None

(75) Project [codegen id : 6]
Output [12]: [ss_net_paid#5, s_store_name#59, s_state#60, s_zip#61, i_current_price#19, i_size#63, i_color#64, i_units#65, i_manager_id#23, c_first_name#67, c_last_name#68, c_birth_country#69]
Input [14]: [ss_customer_sk#2, ss_net_paid#5, s_store_name#59, s_state#60, s_zip#61, i_current_price#19, i_size#63, i_color#64, i_units#65, i_manager_id#23, c_customer_sk#28, c_first_name#67, c_last_name#68, c_birth_country#69]

(76) Scan parquet default.customer_address
Output [3]: [ca_state#36, ca_zip#37, ca_country#38]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer_address]
ReadSchema: struct<ca_state:string,ca_zip:string,ca_country:string>

(77) ColumnarToRow [codegen id : 5]
Input [3]: [ca_state#36, ca_zip#37, ca_country#38]

(78) Filter [codegen id : 5]
Input [3]: [ca_state#36, ca_zip#37, ca_country#38]
Condition : (isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, ca_country#38, 20, false, true)) AND isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, ca_zip#37, 10, false, true)))

(79) Project [codegen id : 5]
Output [3]: [staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, ca_state#36, 2, false, true) AS ca_state#71, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, paddingWithLengthCheck, ca_zip#37, 10, false, true) AS ca_zip#72, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, lengthCheck, ca_country#38, 20, false, true) AS ca_country#73]
Input [3]: [ca_state#36, ca_zip#37, ca_country#38]

(80) BroadcastExchange
Input [3]: [ca_state#71, ca_zip#72, ca_country#73]
Arguments: HashedRelationBroadcastMode(List(upper(input[2, string, true]), input[1, string, true]),false), [id=#74]

(81) BroadcastHashJoin [codegen id : 6]
Left keys [2]: [c_birth_country#69, s_zip#61]
Right keys [2]: [upper(ca_country#73), ca_zip#72]
Join condition: None

(82) Project [codegen id : 6]
Output [11]: [ss_net_paid#5, s_store_name#59, s_state#60, i_current_price#19, i_size#63, i_color#64, i_units#65, i_manager_id#23, c_first_name#67, c_last_name#68, ca_state#71]
Input [15]: [ss_net_paid#5, s_store_name#59, s_state#60, s_zip#61, i_current_price#19, i_size#63, i_color#64, i_units#65, i_manager_id#23, c_first_name#67, c_last_name#68, c_birth_country#69, ca_state#71, ca_zip#72, ca_country#73]

(83) HashAggregate [codegen id : 6]
Input [11]: [ss_net_paid#5, s_store_name#59, s_state#60, i_current_price#19, i_size#63, i_color#64, i_units#65, i_manager_id#23, c_first_name#67, c_last_name#68, ca_state#71]
Keys [10]: [c_last_name#68, c_first_name#67, s_store_name#59, ca_state#71, s_state#60, i_color#64, i_current_price#19, i_manager_id#23, i_units#65, i_size#63]
Functions [1]: [partial_sum(UnscaledValue(ss_net_paid#5))]
Aggregate Attributes [1]: [sum#75]
Results [11]: [c_last_name#68, c_first_name#67, s_store_name#59, ca_state#71, s_state#60, i_color#64, i_current_price#19, i_manager_id#23, i_units#65, i_size#63, sum#76]

(84) Exchange
Input [11]: [c_last_name#68, c_first_name#67, s_store_name#59, ca_state#71, s_state#60, i_color#64, i_current_price#19, i_manager_id#23, i_units#65, i_size#63, sum#76]
Arguments: hashpartitioning(c_last_name#68, c_first_name#67, s_store_name#59, ca_state#71, s_state#60, i_color#64, i_current_price#19, i_manager_id#23, i_units#65, i_size#63, 5), ENSURE_REQUIREMENTS, [id=#77]

(85) HashAggregate [codegen id : 7]
Input [11]: [c_last_name#68, c_first_name#67, s_store_name#59, ca_state#71, s_state#60, i_color#64, i_current_price#19, i_manager_id#23, i_units#65, i_size#63, sum#76]
Keys [10]: [c_last_name#68, c_first_name#67, s_store_name#59, ca_state#71, s_state#60, i_color#64, i_current_price#19, i_manager_id#23, i_units#65, i_size#63]
Functions [1]: [sum(UnscaledValue(ss_net_paid#5))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_net_paid#5))#78]
Results [1]: [MakeDecimal(sum(UnscaledValue(ss_net_paid#5))#78,17,2) AS netpaid#47]

(86) HashAggregate [codegen id : 7]
Input [1]: [netpaid#47]
Keys: []
Functions [1]: [partial_avg(netpaid#47)]
Aggregate Attributes [2]: [sum#79, count#80]
Results [2]: [sum#81, count#82]

(87) Exchange
Input [2]: [sum#81, count#82]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [id=#83]

(88) HashAggregate [codegen id : 8]
Input [2]: [sum#81, count#82]
Keys: []
Functions [1]: [avg(netpaid#47)]
Aggregate Attributes [1]: [avg(netpaid#47)#84]
Results [1]: [CheckOverflow((0.050000 * promote_precision(avg(netpaid#47)#84)), DecimalType(24,8), true) AS (0.05 * avg(netpaid))#85]


