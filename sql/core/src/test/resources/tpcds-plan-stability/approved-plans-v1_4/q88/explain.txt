== Physical Plan ==
* BroadcastNestedLoopJoin Inner BuildRight (182)
:- * BroadcastNestedLoopJoin Inner BuildRight (160)
:  :- * BroadcastNestedLoopJoin Inner BuildRight (138)
:  :  :- * BroadcastNestedLoopJoin Inner BuildRight (116)
:  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (94)
:  :  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (72)
:  :  :  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (50)
:  :  :  :  :  :  :- * HashAggregate (28)
:  :  :  :  :  :  :  +- Exchange (27)
:  :  :  :  :  :  :     +- * HashAggregate (26)
:  :  :  :  :  :  :        +- * Project (25)
:  :  :  :  :  :  :           +- * BroadcastHashJoin Inner BuildRight (24)
:  :  :  :  :  :  :              :- * Project (18)
:  :  :  :  :  :  :              :  +- * BroadcastHashJoin Inner BuildRight (17)
:  :  :  :  :  :  :              :     :- * Project (11)
:  :  :  :  :  :  :              :     :  +- * BroadcastHashJoin Inner BuildRight (10)
:  :  :  :  :  :  :              :     :     :- * Project (4)
:  :  :  :  :  :  :              :     :     :  +- * Filter (3)
:  :  :  :  :  :  :              :     :     :     +- * ColumnarToRow (2)
:  :  :  :  :  :  :              :     :     :        +- Scan parquet spark_catalog.default.store_sales (1)
:  :  :  :  :  :  :              :     :     +- BroadcastExchange (9)
:  :  :  :  :  :  :              :     :        +- * Project (8)
:  :  :  :  :  :  :              :     :           +- * Filter (7)
:  :  :  :  :  :  :              :     :              +- * ColumnarToRow (6)
:  :  :  :  :  :  :              :     :                 +- Scan parquet spark_catalog.default.household_demographics (5)
:  :  :  :  :  :  :              :     +- BroadcastExchange (16)
:  :  :  :  :  :  :              :        +- * Project (15)
:  :  :  :  :  :  :              :           +- * Filter (14)
:  :  :  :  :  :  :              :              +- * ColumnarToRow (13)
:  :  :  :  :  :  :              :                 +- Scan parquet spark_catalog.default.time_dim (12)
:  :  :  :  :  :  :              +- BroadcastExchange (23)
:  :  :  :  :  :  :                 +- * Project (22)
:  :  :  :  :  :  :                    +- * Filter (21)
:  :  :  :  :  :  :                       +- * ColumnarToRow (20)
:  :  :  :  :  :  :                          +- Scan parquet spark_catalog.default.store (19)
:  :  :  :  :  :  +- BroadcastExchange (49)
:  :  :  :  :  :     +- * HashAggregate (48)
:  :  :  :  :  :        +- Exchange (47)
:  :  :  :  :  :           +- * HashAggregate (46)
:  :  :  :  :  :              +- * Project (45)
:  :  :  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (44)
:  :  :  :  :  :                    :- * Project (42)
:  :  :  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (41)
:  :  :  :  :  :                    :     :- * Project (35)
:  :  :  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (34)
:  :  :  :  :  :                    :     :     :- * Project (32)
:  :  :  :  :  :                    :     :     :  +- * Filter (31)
:  :  :  :  :  :                    :     :     :     +- * ColumnarToRow (30)
:  :  :  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (29)
:  :  :  :  :  :                    :     :     +- ReusedExchange (33)
:  :  :  :  :  :                    :     +- BroadcastExchange (40)
:  :  :  :  :  :                    :        +- * Project (39)
:  :  :  :  :  :                    :           +- * Filter (38)
:  :  :  :  :  :                    :              +- * ColumnarToRow (37)
:  :  :  :  :  :                    :                 +- Scan parquet spark_catalog.default.time_dim (36)
:  :  :  :  :  :                    +- ReusedExchange (43)
:  :  :  :  :  +- BroadcastExchange (71)
:  :  :  :  :     +- * HashAggregate (70)
:  :  :  :  :        +- Exchange (69)
:  :  :  :  :           +- * HashAggregate (68)
:  :  :  :  :              +- * Project (67)
:  :  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (66)
:  :  :  :  :                    :- * Project (64)
:  :  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (63)
:  :  :  :  :                    :     :- * Project (57)
:  :  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (56)
:  :  :  :  :                    :     :     :- * Project (54)
:  :  :  :  :                    :     :     :  +- * Filter (53)
:  :  :  :  :                    :     :     :     +- * ColumnarToRow (52)
:  :  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (51)
:  :  :  :  :                    :     :     +- ReusedExchange (55)
:  :  :  :  :                    :     +- BroadcastExchange (62)
:  :  :  :  :                    :        +- * Project (61)
:  :  :  :  :                    :           +- * Filter (60)
:  :  :  :  :                    :              +- * ColumnarToRow (59)
:  :  :  :  :                    :                 +- Scan parquet spark_catalog.default.time_dim (58)
:  :  :  :  :                    +- ReusedExchange (65)
:  :  :  :  +- BroadcastExchange (93)
:  :  :  :     +- * HashAggregate (92)
:  :  :  :        +- Exchange (91)
:  :  :  :           +- * HashAggregate (90)
:  :  :  :              +- * Project (89)
:  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (88)
:  :  :  :                    :- * Project (86)
:  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (85)
:  :  :  :                    :     :- * Project (79)
:  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (78)
:  :  :  :                    :     :     :- * Project (76)
:  :  :  :                    :     :     :  +- * Filter (75)
:  :  :  :                    :     :     :     +- * ColumnarToRow (74)
:  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (73)
:  :  :  :                    :     :     +- ReusedExchange (77)
:  :  :  :                    :     +- BroadcastExchange (84)
:  :  :  :                    :        +- * Project (83)
:  :  :  :                    :           +- * Filter (82)
:  :  :  :                    :              +- * ColumnarToRow (81)
:  :  :  :                    :                 +- Scan parquet spark_catalog.default.time_dim (80)
:  :  :  :                    +- ReusedExchange (87)
:  :  :  +- BroadcastExchange (115)
:  :  :     +- * HashAggregate (114)
:  :  :        +- Exchange (113)
:  :  :           +- * HashAggregate (112)
:  :  :              +- * Project (111)
:  :  :                 +- * BroadcastHashJoin Inner BuildRight (110)
:  :  :                    :- * Project (108)
:  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (107)
:  :  :                    :     :- * Project (101)
:  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (100)
:  :  :                    :     :     :- * Project (98)
:  :  :                    :     :     :  +- * Filter (97)
:  :  :                    :     :     :     +- * ColumnarToRow (96)
:  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (95)
:  :  :                    :     :     +- ReusedExchange (99)
:  :  :                    :     +- BroadcastExchange (106)
:  :  :                    :        +- * Project (105)
:  :  :                    :           +- * Filter (104)
:  :  :                    :              +- * ColumnarToRow (103)
:  :  :                    :                 +- Scan parquet spark_catalog.default.time_dim (102)
:  :  :                    +- ReusedExchange (109)
:  :  +- BroadcastExchange (137)
:  :     +- * HashAggregate (136)
:  :        +- Exchange (135)
:  :           +- * HashAggregate (134)
:  :              +- * Project (133)
:  :                 +- * BroadcastHashJoin Inner BuildRight (132)
:  :                    :- * Project (130)
:  :                    :  +- * BroadcastHashJoin Inner BuildRight (129)
:  :                    :     :- * Project (123)
:  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (122)
:  :                    :     :     :- * Project (120)
:  :                    :     :     :  +- * Filter (119)
:  :                    :     :     :     +- * ColumnarToRow (118)
:  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (117)
:  :                    :     :     +- ReusedExchange (121)
:  :                    :     +- BroadcastExchange (128)
:  :                    :        +- * Project (127)
:  :                    :           +- * Filter (126)
:  :                    :              +- * ColumnarToRow (125)
:  :                    :                 +- Scan parquet spark_catalog.default.time_dim (124)
:  :                    +- ReusedExchange (131)
:  +- BroadcastExchange (159)
:     +- * HashAggregate (158)
:        +- Exchange (157)
:           +- * HashAggregate (156)
:              +- * Project (155)
:                 +- * BroadcastHashJoin Inner BuildRight (154)
:                    :- * Project (152)
:                    :  +- * BroadcastHashJoin Inner BuildRight (151)
:                    :     :- * Project (145)
:                    :     :  +- * BroadcastHashJoin Inner BuildRight (144)
:                    :     :     :- * Project (142)
:                    :     :     :  +- * Filter (141)
:                    :     :     :     +- * ColumnarToRow (140)
:                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (139)
:                    :     :     +- ReusedExchange (143)
:                    :     +- BroadcastExchange (150)
:                    :        +- * Project (149)
:                    :           +- * Filter (148)
:                    :              +- * ColumnarToRow (147)
:                    :                 +- Scan parquet spark_catalog.default.time_dim (146)
:                    +- ReusedExchange (153)
+- BroadcastExchange (181)
   +- * HashAggregate (180)
      +- Exchange (179)
         +- * HashAggregate (178)
            +- * Project (177)
               +- * BroadcastHashJoin Inner BuildRight (176)
                  :- * Project (174)
                  :  +- * BroadcastHashJoin Inner BuildRight (173)
                  :     :- * Project (167)
                  :     :  +- * BroadcastHashJoin Inner BuildRight (166)
                  :     :     :- * Project (164)
                  :     :     :  +- * Filter (163)
                  :     :     :     +- * ColumnarToRow (162)
                  :     :     :        +- Scan parquet spark_catalog.default.store_sales (161)
                  :     :     +- ReusedExchange (165)
                  :     +- BroadcastExchange (172)
                  :        +- * Project (171)
                  :           +- * Filter (170)
                  :              +- * ColumnarToRow (169)
                  :                 +- Scan parquet spark_catalog.default.time_dim (168)
                  +- ReusedExchange (175)


(1) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(2) ColumnarToRow [codegen id : 4]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(3) Filter [codegen id : 4]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(4) Project [codegen id : 4]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(5) Scan parquet spark_catalog.default.household_demographics
Output [3]: [hd_demo_sk#5, hd_dep_count#6, hd_vehicle_count#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/household_demographics]
PushedFilters: [Or(Or(And(EqualTo(hd_dep_count,4),LessThanOrEqual(hd_vehicle_count,6)),And(EqualTo(hd_dep_count,2),LessThanOrEqual(hd_vehicle_count,4))),And(EqualTo(hd_dep_count,0),LessThanOrEqual(hd_vehicle_count,2))), IsNotNull(hd_demo_sk)]
ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int,hd_vehicle_count:int>

(6) ColumnarToRow [codegen id : 1]
Input [3]: [hd_demo_sk#5, hd_dep_count#6, hd_vehicle_count#7]

(7) Filter [codegen id : 1]
Input [3]: [hd_demo_sk#5, hd_dep_count#6, hd_vehicle_count#7]
Condition : (((((hd_dep_count#6 = 4) AND (hd_vehicle_count#7 <= 6)) OR ((hd_dep_count#6 = 2) AND (hd_vehicle_count#7 <= 4))) OR ((hd_dep_count#6 = 0) AND (hd_vehicle_count#7 <= 2))) AND isnotnull(hd_demo_sk#5))

(8) Project [codegen id : 1]
Output [1]: [hd_demo_sk#5]
Input [3]: [hd_demo_sk#5, hd_dep_count#6, hd_vehicle_count#7]

(9) BroadcastExchange
Input [1]: [hd_demo_sk#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(10) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(11) Project [codegen id : 4]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(12) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,8), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(13) ColumnarToRow [codegen id : 2]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(14) Filter [codegen id : 2]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 8)) AND (t_minute#10 >= 30)) AND isnotnull(t_time_sk#8))

(15) Project [codegen id : 2]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(16) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(17) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join type: Inner
Join condition: None

(18) Project [codegen id : 4]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(19) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#11, s_store_name#12]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_name), EqualTo(s_store_name,ese), IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_name:string>

(20) ColumnarToRow [codegen id : 3]
Input [2]: [s_store_sk#11, s_store_name#12]

(21) Filter [codegen id : 3]
Input [2]: [s_store_sk#11, s_store_name#12]
Condition : ((isnotnull(s_store_name#12) AND (s_store_name#12 = ese)) AND isnotnull(s_store_sk#11))

(22) Project [codegen id : 3]
Output [1]: [s_store_sk#11]
Input [2]: [s_store_sk#11, s_store_name#12]

(23) BroadcastExchange
Input [1]: [s_store_sk#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(24) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join type: Inner
Join condition: None

(25) Project [codegen id : 4]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(26) HashAggregate [codegen id : 4]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#13]
Results [1]: [count#14]

(27) Exchange
Input [1]: [count#14]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=4]

(28) HashAggregate [codegen id : 40]
Input [1]: [count#14]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#15]
Results [1]: [count(1)#15 AS h8_30_to_9#16]

(29) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(30) ColumnarToRow [codegen id : 8]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(31) Filter [codegen id : 8]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(32) Project [codegen id : 8]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(33) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#5]

(34) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(35) Project [codegen id : 8]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(36) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,9), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(37) ColumnarToRow [codegen id : 6]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(38) Filter [codegen id : 6]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 9)) AND (t_minute#10 < 30)) AND isnotnull(t_time_sk#8))

(39) Project [codegen id : 6]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(40) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=5]

(41) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join type: Inner
Join condition: None

(42) Project [codegen id : 8]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(43) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#11]

(44) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join type: Inner
Join condition: None

(45) Project [codegen id : 8]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(46) HashAggregate [codegen id : 8]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#17]
Results [1]: [count#18]

(47) Exchange
Input [1]: [count#18]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6]

(48) HashAggregate [codegen id : 9]
Input [1]: [count#18]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#19]
Results [1]: [count(1)#19 AS h9_to_9_30#20]

(49) BroadcastExchange
Input [1]: [h9_to_9_30#20]
Arguments: IdentityBroadcastMode, [plan_id=7]

(50) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(51) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(52) ColumnarToRow [codegen id : 13]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(53) Filter [codegen id : 13]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(54) Project [codegen id : 13]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(55) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#5]

(56) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(57) Project [codegen id : 13]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(58) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,9), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(59) ColumnarToRow [codegen id : 11]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(60) Filter [codegen id : 11]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 9)) AND (t_minute#10 >= 30)) AND isnotnull(t_time_sk#8))

(61) Project [codegen id : 11]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(62) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]

(63) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join type: Inner
Join condition: None

(64) Project [codegen id : 13]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(65) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#11]

(66) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join type: Inner
Join condition: None

(67) Project [codegen id : 13]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(68) HashAggregate [codegen id : 13]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#21]
Results [1]: [count#22]

(69) Exchange
Input [1]: [count#22]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=9]

(70) HashAggregate [codegen id : 14]
Input [1]: [count#22]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#23]
Results [1]: [count(1)#23 AS h9_30_to_10#24]

(71) BroadcastExchange
Input [1]: [h9_30_to_10#24]
Arguments: IdentityBroadcastMode, [plan_id=10]

(72) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(73) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(74) ColumnarToRow [codegen id : 18]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(75) Filter [codegen id : 18]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(76) Project [codegen id : 18]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(77) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#5]

(78) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(79) Project [codegen id : 18]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(80) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,10), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(81) ColumnarToRow [codegen id : 16]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(82) Filter [codegen id : 16]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 10)) AND (t_minute#10 < 30)) AND isnotnull(t_time_sk#8))

(83) Project [codegen id : 16]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(84) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=11]

(85) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join type: Inner
Join condition: None

(86) Project [codegen id : 18]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(87) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#11]

(88) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join type: Inner
Join condition: None

(89) Project [codegen id : 18]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(90) HashAggregate [codegen id : 18]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#25]
Results [1]: [count#26]

(91) Exchange
Input [1]: [count#26]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=12]

(92) HashAggregate [codegen id : 19]
Input [1]: [count#26]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#27]
Results [1]: [count(1)#27 AS h10_to_10_30#28]

(93) BroadcastExchange
Input [1]: [h10_to_10_30#28]
Arguments: IdentityBroadcastMode, [plan_id=13]

(94) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(95) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(96) ColumnarToRow [codegen id : 23]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(97) Filter [codegen id : 23]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(98) Project [codegen id : 23]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(99) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#5]

(100) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(101) Project [codegen id : 23]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(102) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,10), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(103) ColumnarToRow [codegen id : 21]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(104) Filter [codegen id : 21]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 10)) AND (t_minute#10 >= 30)) AND isnotnull(t_time_sk#8))

(105) Project [codegen id : 21]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(106) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=14]

(107) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join type: Inner
Join condition: None

(108) Project [codegen id : 23]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(109) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#11]

(110) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join type: Inner
Join condition: None

(111) Project [codegen id : 23]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(112) HashAggregate [codegen id : 23]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#29]
Results [1]: [count#30]

(113) Exchange
Input [1]: [count#30]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=15]

(114) HashAggregate [codegen id : 24]
Input [1]: [count#30]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#31]
Results [1]: [count(1)#31 AS h10_30_to_11#32]

(115) BroadcastExchange
Input [1]: [h10_30_to_11#32]
Arguments: IdentityBroadcastMode, [plan_id=16]

(116) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(117) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(118) ColumnarToRow [codegen id : 28]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(119) Filter [codegen id : 28]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(120) Project [codegen id : 28]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(121) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#5]

(122) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(123) Project [codegen id : 28]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(124) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,11), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(125) ColumnarToRow [codegen id : 26]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(126) Filter [codegen id : 26]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 11)) AND (t_minute#10 < 30)) AND isnotnull(t_time_sk#8))

(127) Project [codegen id : 26]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(128) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=17]

(129) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join type: Inner
Join condition: None

(130) Project [codegen id : 28]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(131) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#11]

(132) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join type: Inner
Join condition: None

(133) Project [codegen id : 28]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(134) HashAggregate [codegen id : 28]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#33]
Results [1]: [count#34]

(135) Exchange
Input [1]: [count#34]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=18]

(136) HashAggregate [codegen id : 29]
Input [1]: [count#34]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#35]
Results [1]: [count(1)#35 AS h11_to_11_30#36]

(137) BroadcastExchange
Input [1]: [h11_to_11_30#36]
Arguments: IdentityBroadcastMode, [plan_id=19]

(138) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(139) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(140) ColumnarToRow [codegen id : 33]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(141) Filter [codegen id : 33]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(142) Project [codegen id : 33]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(143) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#5]

(144) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(145) Project [codegen id : 33]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(146) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,11), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(147) ColumnarToRow [codegen id : 31]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(148) Filter [codegen id : 31]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 11)) AND (t_minute#10 >= 30)) AND isnotnull(t_time_sk#8))

(149) Project [codegen id : 31]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(150) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=20]

(151) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join type: Inner
Join condition: None

(152) Project [codegen id : 33]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(153) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#11]

(154) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join type: Inner
Join condition: None

(155) Project [codegen id : 33]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(156) HashAggregate [codegen id : 33]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#37]
Results [1]: [count#38]

(157) Exchange
Input [1]: [count#38]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=21]

(158) HashAggregate [codegen id : 34]
Input [1]: [count#38]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#39]
Results [1]: [count(1)#39 AS h11_30_to_12#40]

(159) BroadcastExchange
Input [1]: [h11_30_to_12#40]
Arguments: IdentityBroadcastMode, [plan_id=22]

(160) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(161) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(162) ColumnarToRow [codegen id : 38]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(163) Filter [codegen id : 38]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(164) Project [codegen id : 38]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(165) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#5]

(166) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(167) Project [codegen id : 38]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(168) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,12), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(169) ColumnarToRow [codegen id : 36]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(170) Filter [codegen id : 36]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 12)) AND (t_minute#10 < 30)) AND isnotnull(t_time_sk#8))

(171) Project [codegen id : 36]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(172) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=23]

(173) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join type: Inner
Join condition: None

(174) Project [codegen id : 38]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(175) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#11]

(176) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join type: Inner
Join condition: None

(177) Project [codegen id : 38]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(178) HashAggregate [codegen id : 38]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#41]
Results [1]: [count#42]

(179) Exchange
Input [1]: [count#42]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=24]

(180) HashAggregate [codegen id : 39]
Input [1]: [count#42]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#43]
Results [1]: [count(1)#43 AS h12_to_12_30#44]

(181) BroadcastExchange
Input [1]: [h12_to_12_30#44]
Arguments: IdentityBroadcastMode, [plan_id=25]

(182) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

