== Physical Plan ==
TakeOrderedAndProject (47)
+- * HashAggregate (46)
   +- Exchange (45)
      +- * HashAggregate (44)
         +- Union (43)
            :- * Project (16)
            :  +- * Project (15)
            :     +- * BroadcastHashJoin Inner BuildRight (14)
            :        :- * Project (9)
            :        :  +- * BroadcastHashJoin Inner BuildRight (8)
            :        :     :- * Filter (3)
            :        :     :  +- * ColumnarToRow (2)
            :        :     :     +- Scan parquet spark_catalog.default.store_sales (1)
            :        :     +- BroadcastExchange (7)
            :        :        +- * Filter (6)
            :        :           +- * ColumnarToRow (5)
            :        :              +- Scan parquet spark_catalog.default.date_dim (4)
            :        +- BroadcastExchange (13)
            :           +- * Filter (12)
            :              +- * ColumnarToRow (11)
            :                 +- Scan parquet spark_catalog.default.item (10)
            :- * Project (32)
            :  +- * Project (31)
            :     +- * BroadcastHashJoin Inner BuildLeft (30)
            :        :- BroadcastExchange (26)
            :        :  +- * Project (25)
            :        :     +- * BroadcastHashJoin Inner BuildLeft (24)
            :        :        :- BroadcastExchange (20)
            :        :        :  +- * Filter (19)
            :        :        :     +- * ColumnarToRow (18)
            :        :        :        +- Scan parquet spark_catalog.default.web_sales (17)
            :        :        +- * Filter (23)
            :        :           +- * ColumnarToRow (22)
            :        :              +- Scan parquet spark_catalog.default.date_dim (21)
            :        +- * Filter (29)
            :           +- * ColumnarToRow (28)
            :              +- Scan parquet spark_catalog.default.item (27)
            +- * Project (42)
               +- * Project (41)
                  +- * BroadcastHashJoin Inner BuildRight (40)
                     :- * Project (38)
                     :  +- * BroadcastHashJoin Inner BuildRight (37)
                     :     :- * Filter (35)
                     :     :  +- * ColumnarToRow (34)
                     :     :     +- Scan parquet spark_catalog.default.catalog_sales (33)
                     :     +- ReusedExchange (36)
                     +- ReusedExchange (39)


(1) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_item_sk#1, ss_store_sk#2, ss_ext_sales_price#3, ss_sold_date_sk#4]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#4)]
PushedFilters: [IsNull(ss_store_sk), IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int,ss_store_sk:int,ss_ext_sales_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 3]
Input [4]: [ss_item_sk#1, ss_store_sk#2, ss_ext_sales_price#3, ss_sold_date_sk#4]

(3) Filter [codegen id : 3]
Input [4]: [ss_item_sk#1, ss_store_sk#2, ss_ext_sales_price#3, ss_sold_date_sk#4]
Condition : (isnull(ss_store_sk#2) AND isnotnull(ss_item_sk#1))

(4) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#5, d_year#6, d_qoy#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>

(5) ColumnarToRow [codegen id : 1]
Input [3]: [d_date_sk#5, d_year#6, d_qoy#7]

(6) Filter [codegen id : 1]
Input [3]: [d_date_sk#5, d_year#6, d_qoy#7]
Condition : isnotnull(d_date_sk#5)

(7) BroadcastExchange
Input [3]: [d_date_sk#5, d_year#6, d_qoy#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(8) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#4]
Right keys [1]: [d_date_sk#5]
Join type: Inner
Join condition: None

(9) Project [codegen id : 3]
Output [5]: [ss_item_sk#1, ss_store_sk#2, ss_ext_sales_price#3, d_year#6, d_qoy#7]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_ext_sales_price#3, ss_sold_date_sk#4, d_date_sk#5, d_year#6, d_qoy#7]

(10) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#8, i_category#9]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_category:string>

(11) ColumnarToRow [codegen id : 2]
Input [2]: [i_item_sk#8, i_category#9]

(12) Filter [codegen id : 2]
Input [2]: [i_item_sk#8, i_category#9]
Condition : isnotnull(i_item_sk#8)

(13) BroadcastExchange
Input [2]: [i_item_sk#8, i_category#9]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2]

(14) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#8]
Join type: Inner
Join condition: None

(15) Project [codegen id : 3]
Output [5]: [ss_store_sk#2, ss_ext_sales_price#3, i_category#9, d_year#6, d_qoy#7]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_ext_sales_price#3, d_year#6, d_qoy#7, i_item_sk#8, i_category#9]

(16) Project [codegen id : 3]
Output [6]: [store AS channel#10, ss_store_sk#2 AS col_name#11, d_year#6, d_qoy#7, i_category#9, ss_ext_sales_price#3 AS ext_sales_price#12]
Input [5]: [ss_store_sk#2, ss_ext_sales_price#3, i_category#9, d_year#6, d_qoy#7]

(17) Scan parquet spark_catalog.default.web_sales
Output [4]: [ws_item_sk#13, ws_ship_customer_sk#14, ws_ext_sales_price#15, ws_sold_date_sk#16]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#16)]
PushedFilters: [IsNull(ws_ship_customer_sk), IsNotNull(ws_item_sk)]
ReadSchema: struct<ws_item_sk:int,ws_ship_customer_sk:int,ws_ext_sales_price:decimal(7,2)>

(18) ColumnarToRow [codegen id : 4]
Input [4]: [ws_item_sk#13, ws_ship_customer_sk#14, ws_ext_sales_price#15, ws_sold_date_sk#16]

(19) Filter [codegen id : 4]
Input [4]: [ws_item_sk#13, ws_ship_customer_sk#14, ws_ext_sales_price#15, ws_sold_date_sk#16]
Condition : (isnull(ws_ship_customer_sk#14) AND isnotnull(ws_item_sk#13))

(20) BroadcastExchange
Input [4]: [ws_item_sk#13, ws_ship_customer_sk#14, ws_ext_sales_price#15, ws_sold_date_sk#16]
Arguments: HashedRelationBroadcastMode(List(cast(input[3, int, true] as bigint)),false), [plan_id=3]

(21) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#17, d_year#18, d_qoy#19]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>

(22) ColumnarToRow
Input [3]: [d_date_sk#17, d_year#18, d_qoy#19]

(23) Filter
Input [3]: [d_date_sk#17, d_year#18, d_qoy#19]
Condition : isnotnull(d_date_sk#17)

(24) BroadcastHashJoin [codegen id : 5]
Left keys [1]: [ws_sold_date_sk#16]
Right keys [1]: [d_date_sk#17]
Join type: Inner
Join condition: None

(25) Project [codegen id : 5]
Output [5]: [ws_item_sk#13, ws_ship_customer_sk#14, ws_ext_sales_price#15, d_year#18, d_qoy#19]
Input [7]: [ws_item_sk#13, ws_ship_customer_sk#14, ws_ext_sales_price#15, ws_sold_date_sk#16, d_date_sk#17, d_year#18, d_qoy#19]

(26) BroadcastExchange
Input [5]: [ws_item_sk#13, ws_ship_customer_sk#14, ws_ext_sales_price#15, d_year#18, d_qoy#19]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

(27) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#20, i_category#21]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_category:string>

(28) ColumnarToRow
Input [2]: [i_item_sk#20, i_category#21]

(29) Filter
Input [2]: [i_item_sk#20, i_category#21]
Condition : isnotnull(i_item_sk#20)

(30) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ws_item_sk#13]
Right keys [1]: [i_item_sk#20]
Join type: Inner
Join condition: None

(31) Project [codegen id : 6]
Output [5]: [ws_ship_customer_sk#14, ws_ext_sales_price#15, i_category#21, d_year#18, d_qoy#19]
Input [7]: [ws_item_sk#13, ws_ship_customer_sk#14, ws_ext_sales_price#15, d_year#18, d_qoy#19, i_item_sk#20, i_category#21]

(32) Project [codegen id : 6]
Output [6]: [web AS channel#22, ws_ship_customer_sk#14 AS col_name#23, d_year#18, d_qoy#19, i_category#21, ws_ext_sales_price#15 AS ext_sales_price#24]
Input [5]: [ws_ship_customer_sk#14, ws_ext_sales_price#15, i_category#21, d_year#18, d_qoy#19]

(33) Scan parquet spark_catalog.default.catalog_sales
Output [4]: [cs_ship_addr_sk#25, cs_item_sk#26, cs_ext_sales_price#27, cs_sold_date_sk#28]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#28)]
PushedFilters: [IsNull(cs_ship_addr_sk), IsNotNull(cs_item_sk)]
ReadSchema: struct<cs_ship_addr_sk:int,cs_item_sk:int,cs_ext_sales_price:decimal(7,2)>

(34) ColumnarToRow [codegen id : 9]
Input [4]: [cs_ship_addr_sk#25, cs_item_sk#26, cs_ext_sales_price#27, cs_sold_date_sk#28]

(35) Filter [codegen id : 9]
Input [4]: [cs_ship_addr_sk#25, cs_item_sk#26, cs_ext_sales_price#27, cs_sold_date_sk#28]
Condition : (isnull(cs_ship_addr_sk#25) AND isnotnull(cs_item_sk#26))

(36) ReusedExchange [Reuses operator id: 7]
Output [3]: [d_date_sk#29, d_year#30, d_qoy#31]

(37) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [cs_sold_date_sk#28]
Right keys [1]: [d_date_sk#29]
Join type: Inner
Join condition: None

(38) Project [codegen id : 9]
Output [5]: [cs_ship_addr_sk#25, cs_item_sk#26, cs_ext_sales_price#27, d_year#30, d_qoy#31]
Input [7]: [cs_ship_addr_sk#25, cs_item_sk#26, cs_ext_sales_price#27, cs_sold_date_sk#28, d_date_sk#29, d_year#30, d_qoy#31]

(39) ReusedExchange [Reuses operator id: 13]
Output [2]: [i_item_sk#32, i_category#33]

(40) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [cs_item_sk#26]
Right keys [1]: [i_item_sk#32]
Join type: Inner
Join condition: None

(41) Project [codegen id : 9]
Output [5]: [cs_ship_addr_sk#25, cs_ext_sales_price#27, i_category#33, d_year#30, d_qoy#31]
Input [7]: [cs_ship_addr_sk#25, cs_item_sk#26, cs_ext_sales_price#27, d_year#30, d_qoy#31, i_item_sk#32, i_category#33]

(42) Project [codegen id : 9]
Output [6]: [catalog AS channel#34, cs_ship_addr_sk#25 AS col_name#35, d_year#30, d_qoy#31, i_category#33, cs_ext_sales_price#27 AS ext_sales_price#36]
Input [5]: [cs_ship_addr_sk#25, cs_ext_sales_price#27, i_category#33, d_year#30, d_qoy#31]

(43) Union

(44) HashAggregate [codegen id : 10]
Input [6]: [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9, ext_sales_price#12]
Keys [5]: [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9]
Functions [2]: [partial_count(1), partial_sum(UnscaledValue(ext_sales_price#12))]
Aggregate Attributes [2]: [count#37, sum#38]
Results [7]: [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9, count#39, sum#40]

(45) Exchange
Input [7]: [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9, count#39, sum#40]
Arguments: hashpartitioning(channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9, 5), ENSURE_REQUIREMENTS, [plan_id=5]

(46) HashAggregate [codegen id : 11]
Input [7]: [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9, count#39, sum#40]
Keys [5]: [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9]
Functions [2]: [count(1), sum(UnscaledValue(ext_sales_price#12))]
Aggregate Attributes [2]: [count(1)#41, sum(UnscaledValue(ext_sales_price#12))#42]
Results [7]: [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9, count(1)#41 AS sales_cnt#43, MakeDecimal(sum(UnscaledValue(ext_sales_price#12))#42,17,2) AS sales_amt#44]

(47) TakeOrderedAndProject
Input [7]: [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9, sales_cnt#43, sales_amt#44]
Arguments: 100, [channel#10 ASC NULLS FIRST, col_name#11 ASC NULLS FIRST, d_year#6 ASC NULLS FIRST, d_qoy#7 ASC NULLS FIRST, i_category#9 ASC NULLS FIRST], [channel#10, col_name#11, d_year#6, d_qoy#7, i_category#9, sales_cnt#43, sales_amt#44]

