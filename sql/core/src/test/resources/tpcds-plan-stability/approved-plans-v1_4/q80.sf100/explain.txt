== Physical Plan ==
TakeOrderedAndProject (99)
+- * HashAggregate (98)
   +- Exchange (97)
      +- * HashAggregate (96)
         +- * Expand (95)
            +- Union (94)
               :- * HashAggregate (31)
               :  +- Exchange (30)
               :     +- * HashAggregate (29)
               :        +- * Project (28)
               :           +- * BroadcastHashJoin Inner BuildRight (27)
               :              :- * Project (22)
               :              :  +- * BroadcastHashJoin Inner BuildRight (21)
               :              :     :- * Project (19)
               :              :     :  +- * BroadcastHashJoin Inner BuildRight (18)
               :              :     :     :- * Project (16)
               :              :     :     :  +- * BroadcastHashJoin Inner BuildRight (15)
               :              :     :     :     :- * Project (13)
               :              :     :     :     :  +- * SortMergeJoin LeftOuter (12)
               :              :     :     :     :     :- * Sort (5)
               :              :     :     :     :     :  +- Exchange (4)
               :              :     :     :     :     :     +- * Filter (3)
               :              :     :     :     :     :        +- * ColumnarToRow (2)
               :              :     :     :     :     :           +- Scan parquet spark_catalog.default.store_sales (1)
               :              :     :     :     :     +- * Sort (11)
               :              :     :     :     :        +- Exchange (10)
               :              :     :     :     :           +- * Project (9)
               :              :     :     :     :              +- * Filter (8)
               :              :     :     :     :                 +- * ColumnarToRow (7)
               :              :     :     :     :                    +- Scan parquet spark_catalog.default.store_returns (6)
               :              :     :     :     +- ReusedExchange (14)
               :              :     :     +- ReusedExchange (17)
               :              :     +- ReusedExchange (20)
               :              +- BroadcastExchange (26)
               :                 +- * Filter (25)
               :                    +- * ColumnarToRow (24)
               :                       +- Scan parquet spark_catalog.default.store (23)
               :- * HashAggregate (62)
               :  +- Exchange (61)
               :     +- * HashAggregate (60)
               :        +- * Project (59)
               :           +- * BroadcastHashJoin Inner BuildRight (58)
               :              :- * Project (53)
               :              :  +- * BroadcastHashJoin Inner BuildRight (52)
               :              :     :- * Project (50)
               :              :     :  +- * BroadcastHashJoin Inner BuildRight (49)
               :              :     :     :- * Project (47)
               :              :     :     :  +- * BroadcastHashJoin Inner BuildRight (46)
               :              :     :     :     :- * Project (44)
               :              :     :     :     :  +- * SortMergeJoin LeftOuter (43)
               :              :     :     :     :     :- * Sort (36)
               :              :     :     :     :     :  +- Exchange (35)
               :              :     :     :     :     :     +- * Filter (34)
               :              :     :     :     :     :        +- * ColumnarToRow (33)
               :              :     :     :     :     :           +- Scan parquet spark_catalog.default.catalog_sales (32)
               :              :     :     :     :     +- * Sort (42)
               :              :     :     :     :        +- Exchange (41)
               :              :     :     :     :           +- * Project (40)
               :              :     :     :     :              +- * Filter (39)
               :              :     :     :     :                 +- * ColumnarToRow (38)
               :              :     :     :     :                    +- Scan parquet spark_catalog.default.catalog_returns (37)
               :              :     :     :     +- ReusedExchange (45)
               :              :     :     +- ReusedExchange (48)
               :              :     +- ReusedExchange (51)
               :              +- BroadcastExchange (57)
               :                 +- * Filter (56)
               :                    +- * ColumnarToRow (55)
               :                       +- Scan parquet spark_catalog.default.catalog_page (54)
               +- * HashAggregate (93)
                  +- Exchange (92)
                     +- * HashAggregate (91)
                        +- * Project (90)
                           +- * BroadcastHashJoin Inner BuildRight (89)
                              :- * Project (84)
                              :  +- * BroadcastHashJoin Inner BuildRight (83)
                              :     :- * Project (81)
                              :     :  +- * BroadcastHashJoin Inner BuildRight (80)
                              :     :     :- * Project (78)
                              :     :     :  +- * BroadcastHashJoin Inner BuildRight (77)
                              :     :     :     :- * Project (75)
                              :     :     :     :  +- * SortMergeJoin LeftOuter (74)
                              :     :     :     :     :- * Sort (67)
                              :     :     :     :     :  +- Exchange (66)
                              :     :     :     :     :     +- * Filter (65)
                              :     :     :     :     :        +- * ColumnarToRow (64)
                              :     :     :     :     :           +- Scan parquet spark_catalog.default.web_sales (63)
                              :     :     :     :     +- * Sort (73)
                              :     :     :     :        +- Exchange (72)
                              :     :     :     :           +- * Project (71)
                              :     :     :     :              +- * Filter (70)
                              :     :     :     :                 +- * ColumnarToRow (69)
                              :     :     :     :                    +- Scan parquet spark_catalog.default.web_returns (68)
                              :     :     :     +- ReusedExchange (76)
                              :     :     +- ReusedExchange (79)
                              :     +- ReusedExchange (82)
                              +- BroadcastExchange (88)
                                 +- * Filter (87)
                                    +- * ColumnarToRow (86)
                                       +- Scan parquet spark_catalog.default.web_site (85)


(1) Scan parquet spark_catalog.default.store_sales
Output [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#7), dynamicpruningexpression(ss_sold_date_sk#7 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(ss_store_sk), IsNotNull(ss_item_sk), IsNotNull(ss_promo_sk)]
ReadSchema: struct<ss_item_sk:int,ss_store_sk:int,ss_promo_sk:int,ss_ticket_number:int,ss_ext_sales_price:decimal(7,2),ss_net_profit:decimal(7,2)>

(2) ColumnarToRow [codegen id : 1]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]

(3) Filter [codegen id : 1]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Condition : ((((isnotnull(ss_store_sk#2) AND isnotnull(ss_item_sk#1)) AND isnotnull(ss_promo_sk#3)) AND might_contain(runtimefilterexpression(Subquery scalar-subquery#9, [id=#10]), xxhash64(ss_item_sk#1, 42))) AND might_contain(runtimefilterexpression(Subquery scalar-subquery#11, [id=#12]), xxhash64(ss_promo_sk#3, 42)))

(4) Exchange
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Arguments: hashpartitioning(ss_item_sk#1, ss_ticket_number#4, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(5) Sort [codegen id : 2]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Arguments: [ss_item_sk#1 ASC NULLS FIRST, ss_ticket_number#4 ASC NULLS FIRST], false, 0

(6) Scan parquet spark_catalog.default.store_returns
Output [5]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16, sr_returned_date_sk#17]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_returns]
PushedFilters: [IsNotNull(sr_item_sk), IsNotNull(sr_ticket_number)]
ReadSchema: struct<sr_item_sk:int,sr_ticket_number:int,sr_return_amt:decimal(7,2),sr_net_loss:decimal(7,2)>

(7) ColumnarToRow [codegen id : 3]
Input [5]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16, sr_returned_date_sk#17]

(8) Filter [codegen id : 3]
Input [5]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16, sr_returned_date_sk#17]
Condition : (isnotnull(sr_item_sk#13) AND isnotnull(sr_ticket_number#14))

(9) Project [codegen id : 3]
Output [4]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16]
Input [5]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16, sr_returned_date_sk#17]

(10) Exchange
Input [4]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16]
Arguments: hashpartitioning(sr_item_sk#13, sr_ticket_number#14, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(11) Sort [codegen id : 4]
Input [4]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16]
Arguments: [sr_item_sk#13 ASC NULLS FIRST, sr_ticket_number#14 ASC NULLS FIRST], false, 0

(12) SortMergeJoin [codegen id : 9]
Left keys [2]: [ss_item_sk#1, ss_ticket_number#4]
Right keys [2]: [sr_item_sk#13, sr_ticket_number#14]
Join type: LeftOuter
Join condition: None

(13) Project [codegen id : 9]
Output [8]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16]
Input [11]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16]

(14) ReusedExchange [Reuses operator id: 104]
Output [1]: [i_item_sk#18]

(15) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#18]
Join type: Inner
Join condition: None

(16) Project [codegen id : 9]
Output [7]: [ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16]
Input [9]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16, i_item_sk#18]

(17) ReusedExchange [Reuses operator id: 114]
Output [1]: [p_promo_sk#19]

(18) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_promo_sk#3]
Right keys [1]: [p_promo_sk#19]
Join type: Inner
Join condition: None

(19) Project [codegen id : 9]
Output [6]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16]
Input [8]: [ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16, p_promo_sk#19]

(20) ReusedExchange [Reuses operator id: 124]
Output [1]: [d_date_sk#20]

(21) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_sold_date_sk#7]
Right keys [1]: [d_date_sk#20]
Join type: Inner
Join condition: None

(22) Project [codegen id : 9]
Output [5]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#15, sr_net_loss#16]
Input [7]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16, d_date_sk#20]

(23) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#21, s_store_id#22]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_id:string>

(24) ColumnarToRow [codegen id : 8]
Input [2]: [s_store_sk#21, s_store_id#22]

(25) Filter [codegen id : 8]
Input [2]: [s_store_sk#21, s_store_id#22]
Condition : isnotnull(s_store_sk#21)

(26) BroadcastExchange
Input [2]: [s_store_sk#21, s_store_id#22]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=3]

(27) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_store_sk#2]
Right keys [1]: [s_store_sk#21]
Join type: Inner
Join condition: None

(28) Project [codegen id : 9]
Output [5]: [ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#15, sr_net_loss#16, s_store_id#22]
Input [7]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#15, sr_net_loss#16, s_store_sk#21, s_store_id#22]

(29) HashAggregate [codegen id : 9]
Input [5]: [ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#15, sr_net_loss#16, s_store_id#22]
Keys [1]: [s_store_id#22]
Functions [3]: [partial_sum(UnscaledValue(ss_ext_sales_price#5)), partial_sum(coalesce(cast(sr_return_amt#15 as decimal(12,2)), 0.00)), partial_sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#23, sum#24, isEmpty#25, sum#26, isEmpty#27]
Results [6]: [s_store_id#22, sum#28, sum#29, isEmpty#30, sum#31, isEmpty#32]

(30) Exchange
Input [6]: [s_store_id#22, sum#28, sum#29, isEmpty#30, sum#31, isEmpty#32]
Arguments: hashpartitioning(s_store_id#22, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(31) HashAggregate [codegen id : 10]
Input [6]: [s_store_id#22, sum#28, sum#29, isEmpty#30, sum#31, isEmpty#32]
Keys [1]: [s_store_id#22]
Functions [3]: [sum(UnscaledValue(ss_ext_sales_price#5)), sum(coalesce(cast(sr_return_amt#15 as decimal(12,2)), 0.00)), sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(ss_ext_sales_price#5))#33, sum(coalesce(cast(sr_return_amt#15 as decimal(12,2)), 0.00))#34, sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00)))#35]
Results [5]: [MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#5))#33,17,2) AS sales#36, sum(coalesce(cast(sr_return_amt#15 as decimal(12,2)), 0.00))#34 AS returns#37, sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00)))#35 AS profit#38, store channel AS channel#39, concat(store, s_store_id#22) AS id#40]

(32) Scan parquet spark_catalog.default.catalog_sales
Output [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#47), dynamicpruningexpression(cs_sold_date_sk#47 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(cs_catalog_page_sk), IsNotNull(cs_item_sk), IsNotNull(cs_promo_sk)]
ReadSchema: struct<cs_catalog_page_sk:int,cs_item_sk:int,cs_promo_sk:int,cs_order_number:int,cs_ext_sales_price:decimal(7,2),cs_net_profit:decimal(7,2)>

(33) ColumnarToRow [codegen id : 11]
Input [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]

(34) Filter [codegen id : 11]
Input [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]
Condition : ((((isnotnull(cs_catalog_page_sk#41) AND isnotnull(cs_item_sk#42)) AND isnotnull(cs_promo_sk#43)) AND might_contain(runtimefilterexpression(ReusedSubquery Subquery scalar-subquery#9, [id=#10]), xxhash64(cs_item_sk#42, 42))) AND might_contain(runtimefilterexpression(ReusedSubquery Subquery scalar-subquery#11, [id=#12]), xxhash64(cs_promo_sk#43, 42)))

(35) Exchange
Input [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]
Arguments: hashpartitioning(cs_item_sk#42, cs_order_number#44, 5), ENSURE_REQUIREMENTS, [plan_id=5]

(36) Sort [codegen id : 12]
Input [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]
Arguments: [cs_item_sk#42 ASC NULLS FIRST, cs_order_number#44 ASC NULLS FIRST], false, 0

(37) Scan parquet spark_catalog.default.catalog_returns
Output [5]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51, cr_returned_date_sk#52]
Batched: true
Location [not included in comparison]/{warehouse_dir}/catalog_returns]
PushedFilters: [IsNotNull(cr_item_sk), IsNotNull(cr_order_number)]
ReadSchema: struct<cr_item_sk:int,cr_order_number:int,cr_return_amount:decimal(7,2),cr_net_loss:decimal(7,2)>

(38) ColumnarToRow [codegen id : 13]
Input [5]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51, cr_returned_date_sk#52]

(39) Filter [codegen id : 13]
Input [5]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51, cr_returned_date_sk#52]
Condition : (isnotnull(cr_item_sk#48) AND isnotnull(cr_order_number#49))

(40) Project [codegen id : 13]
Output [4]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51]
Input [5]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51, cr_returned_date_sk#52]

(41) Exchange
Input [4]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51]
Arguments: hashpartitioning(cr_item_sk#48, cr_order_number#49, 5), ENSURE_REQUIREMENTS, [plan_id=6]

(42) Sort [codegen id : 14]
Input [4]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51]
Arguments: [cr_item_sk#48 ASC NULLS FIRST, cr_order_number#49 ASC NULLS FIRST], false, 0

(43) SortMergeJoin [codegen id : 19]
Left keys [2]: [cs_item_sk#42, cs_order_number#44]
Right keys [2]: [cr_item_sk#48, cr_order_number#49]
Join type: LeftOuter
Join condition: None

(44) Project [codegen id : 19]
Output [8]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51]
Input [11]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51]

(45) ReusedExchange [Reuses operator id: 104]
Output [1]: [i_item_sk#53]

(46) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_item_sk#42]
Right keys [1]: [i_item_sk#53]
Join type: Inner
Join condition: None

(47) Project [codegen id : 19]
Output [7]: [cs_catalog_page_sk#41, cs_promo_sk#43, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51]
Input [9]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51, i_item_sk#53]

(48) ReusedExchange [Reuses operator id: 114]
Output [1]: [p_promo_sk#54]

(49) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_promo_sk#43]
Right keys [1]: [p_promo_sk#54]
Join type: Inner
Join condition: None

(50) Project [codegen id : 19]
Output [6]: [cs_catalog_page_sk#41, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51]
Input [8]: [cs_catalog_page_sk#41, cs_promo_sk#43, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51, p_promo_sk#54]

(51) ReusedExchange [Reuses operator id: 124]
Output [1]: [d_date_sk#55]

(52) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_sold_date_sk#47]
Right keys [1]: [d_date_sk#55]
Join type: Inner
Join condition: None

(53) Project [codegen id : 19]
Output [5]: [cs_catalog_page_sk#41, cs_ext_sales_price#45, cs_net_profit#46, cr_return_amount#50, cr_net_loss#51]
Input [7]: [cs_catalog_page_sk#41, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51, d_date_sk#55]

(54) Scan parquet spark_catalog.default.catalog_page
Output [2]: [cp_catalog_page_sk#56, cp_catalog_page_id#57]
Batched: true
Location [not included in comparison]/{warehouse_dir}/catalog_page]
PushedFilters: [IsNotNull(cp_catalog_page_sk)]
ReadSchema: struct<cp_catalog_page_sk:int,cp_catalog_page_id:string>

(55) ColumnarToRow [codegen id : 18]
Input [2]: [cp_catalog_page_sk#56, cp_catalog_page_id#57]

(56) Filter [codegen id : 18]
Input [2]: [cp_catalog_page_sk#56, cp_catalog_page_id#57]
Condition : isnotnull(cp_catalog_page_sk#56)

(57) BroadcastExchange
Input [2]: [cp_catalog_page_sk#56, cp_catalog_page_id#57]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=7]

(58) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_catalog_page_sk#41]
Right keys [1]: [cp_catalog_page_sk#56]
Join type: Inner
Join condition: None

(59) Project [codegen id : 19]
Output [5]: [cs_ext_sales_price#45, cs_net_profit#46, cr_return_amount#50, cr_net_loss#51, cp_catalog_page_id#57]
Input [7]: [cs_catalog_page_sk#41, cs_ext_sales_price#45, cs_net_profit#46, cr_return_amount#50, cr_net_loss#51, cp_catalog_page_sk#56, cp_catalog_page_id#57]

(60) HashAggregate [codegen id : 19]
Input [5]: [cs_ext_sales_price#45, cs_net_profit#46, cr_return_amount#50, cr_net_loss#51, cp_catalog_page_id#57]
Keys [1]: [cp_catalog_page_id#57]
Functions [3]: [partial_sum(UnscaledValue(cs_ext_sales_price#45)), partial_sum(coalesce(cast(cr_return_amount#50 as decimal(12,2)), 0.00)), partial_sum((cs_net_profit#46 - coalesce(cast(cr_net_loss#51 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#58, sum#59, isEmpty#60, sum#61, isEmpty#62]
Results [6]: [cp_catalog_page_id#57, sum#63, sum#64, isEmpty#65, sum#66, isEmpty#67]

(61) Exchange
Input [6]: [cp_catalog_page_id#57, sum#63, sum#64, isEmpty#65, sum#66, isEmpty#67]
Arguments: hashpartitioning(cp_catalog_page_id#57, 5), ENSURE_REQUIREMENTS, [plan_id=8]

(62) HashAggregate [codegen id : 20]
Input [6]: [cp_catalog_page_id#57, sum#63, sum#64, isEmpty#65, sum#66, isEmpty#67]
Keys [1]: [cp_catalog_page_id#57]
Functions [3]: [sum(UnscaledValue(cs_ext_sales_price#45)), sum(coalesce(cast(cr_return_amount#50 as decimal(12,2)), 0.00)), sum((cs_net_profit#46 - coalesce(cast(cr_net_loss#51 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(cs_ext_sales_price#45))#68, sum(coalesce(cast(cr_return_amount#50 as decimal(12,2)), 0.00))#69, sum((cs_net_profit#46 - coalesce(cast(cr_net_loss#51 as decimal(12,2)), 0.00)))#70]
Results [5]: [MakeDecimal(sum(UnscaledValue(cs_ext_sales_price#45))#68,17,2) AS sales#71, sum(coalesce(cast(cr_return_amount#50 as decimal(12,2)), 0.00))#69 AS returns#72, sum((cs_net_profit#46 - coalesce(cast(cr_net_loss#51 as decimal(12,2)), 0.00)))#70 AS profit#73, catalog channel AS channel#74, concat(catalog_page, cp_catalog_page_id#57) AS id#75]

(63) Scan parquet spark_catalog.default.web_sales
Output [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#82), dynamicpruningexpression(ws_sold_date_sk#82 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(ws_web_site_sk), IsNotNull(ws_item_sk), IsNotNull(ws_promo_sk)]
ReadSchema: struct<ws_item_sk:int,ws_web_site_sk:int,ws_promo_sk:int,ws_order_number:int,ws_ext_sales_price:decimal(7,2),ws_net_profit:decimal(7,2)>

(64) ColumnarToRow [codegen id : 21]
Input [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]

(65) Filter [codegen id : 21]
Input [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]
Condition : ((((isnotnull(ws_web_site_sk#77) AND isnotnull(ws_item_sk#76)) AND isnotnull(ws_promo_sk#78)) AND might_contain(runtimefilterexpression(ReusedSubquery Subquery scalar-subquery#9, [id=#10]), xxhash64(ws_item_sk#76, 42))) AND might_contain(runtimefilterexpression(ReusedSubquery Subquery scalar-subquery#11, [id=#12]), xxhash64(ws_promo_sk#78, 42)))

(66) Exchange
Input [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]
Arguments: hashpartitioning(ws_item_sk#76, ws_order_number#79, 5), ENSURE_REQUIREMENTS, [plan_id=9]

(67) Sort [codegen id : 22]
Input [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]
Arguments: [ws_item_sk#76 ASC NULLS FIRST, ws_order_number#79 ASC NULLS FIRST], false, 0

(68) Scan parquet spark_catalog.default.web_returns
Output [5]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86, wr_returned_date_sk#87]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_returns]
PushedFilters: [IsNotNull(wr_item_sk), IsNotNull(wr_order_number)]
ReadSchema: struct<wr_item_sk:int,wr_order_number:int,wr_return_amt:decimal(7,2),wr_net_loss:decimal(7,2)>

(69) ColumnarToRow [codegen id : 23]
Input [5]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86, wr_returned_date_sk#87]

(70) Filter [codegen id : 23]
Input [5]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86, wr_returned_date_sk#87]
Condition : (isnotnull(wr_item_sk#83) AND isnotnull(wr_order_number#84))

(71) Project [codegen id : 23]
Output [4]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86]
Input [5]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86, wr_returned_date_sk#87]

(72) Exchange
Input [4]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86]
Arguments: hashpartitioning(wr_item_sk#83, wr_order_number#84, 5), ENSURE_REQUIREMENTS, [plan_id=10]

(73) Sort [codegen id : 24]
Input [4]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86]
Arguments: [wr_item_sk#83 ASC NULLS FIRST, wr_order_number#84 ASC NULLS FIRST], false, 0

(74) SortMergeJoin [codegen id : 29]
Left keys [2]: [ws_item_sk#76, ws_order_number#79]
Right keys [2]: [wr_item_sk#83, wr_order_number#84]
Join type: LeftOuter
Join condition: None

(75) Project [codegen id : 29]
Output [8]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86]
Input [11]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86]

(76) ReusedExchange [Reuses operator id: 104]
Output [1]: [i_item_sk#88]

(77) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_item_sk#76]
Right keys [1]: [i_item_sk#88]
Join type: Inner
Join condition: None

(78) Project [codegen id : 29]
Output [7]: [ws_web_site_sk#77, ws_promo_sk#78, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86]
Input [9]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86, i_item_sk#88]

(79) ReusedExchange [Reuses operator id: 114]
Output [1]: [p_promo_sk#89]

(80) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_promo_sk#78]
Right keys [1]: [p_promo_sk#89]
Join type: Inner
Join condition: None

(81) Project [codegen id : 29]
Output [6]: [ws_web_site_sk#77, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86]
Input [8]: [ws_web_site_sk#77, ws_promo_sk#78, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86, p_promo_sk#89]

(82) ReusedExchange [Reuses operator id: 124]
Output [1]: [d_date_sk#90]

(83) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_sold_date_sk#82]
Right keys [1]: [d_date_sk#90]
Join type: Inner
Join condition: None

(84) Project [codegen id : 29]
Output [5]: [ws_web_site_sk#77, ws_ext_sales_price#80, ws_net_profit#81, wr_return_amt#85, wr_net_loss#86]
Input [7]: [ws_web_site_sk#77, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86, d_date_sk#90]

(85) Scan parquet spark_catalog.default.web_site
Output [2]: [web_site_sk#91, web_site_id#92]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_site]
PushedFilters: [IsNotNull(web_site_sk)]
ReadSchema: struct<web_site_sk:int,web_site_id:string>

(86) ColumnarToRow [codegen id : 28]
Input [2]: [web_site_sk#91, web_site_id#92]

(87) Filter [codegen id : 28]
Input [2]: [web_site_sk#91, web_site_id#92]
Condition : isnotnull(web_site_sk#91)

(88) BroadcastExchange
Input [2]: [web_site_sk#91, web_site_id#92]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=11]

(89) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_web_site_sk#77]
Right keys [1]: [web_site_sk#91]
Join type: Inner
Join condition: None

(90) Project [codegen id : 29]
Output [5]: [ws_ext_sales_price#80, ws_net_profit#81, wr_return_amt#85, wr_net_loss#86, web_site_id#92]
Input [7]: [ws_web_site_sk#77, ws_ext_sales_price#80, ws_net_profit#81, wr_return_amt#85, wr_net_loss#86, web_site_sk#91, web_site_id#92]

(91) HashAggregate [codegen id : 29]
Input [5]: [ws_ext_sales_price#80, ws_net_profit#81, wr_return_amt#85, wr_net_loss#86, web_site_id#92]
Keys [1]: [web_site_id#92]
Functions [3]: [partial_sum(UnscaledValue(ws_ext_sales_price#80)), partial_sum(coalesce(cast(wr_return_amt#85 as decimal(12,2)), 0.00)), partial_sum((ws_net_profit#81 - coalesce(cast(wr_net_loss#86 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#93, sum#94, isEmpty#95, sum#96, isEmpty#97]
Results [6]: [web_site_id#92, sum#98, sum#99, isEmpty#100, sum#101, isEmpty#102]

(92) Exchange
Input [6]: [web_site_id#92, sum#98, sum#99, isEmpty#100, sum#101, isEmpty#102]
Arguments: hashpartitioning(web_site_id#92, 5), ENSURE_REQUIREMENTS, [plan_id=12]

(93) HashAggregate [codegen id : 30]
Input [6]: [web_site_id#92, sum#98, sum#99, isEmpty#100, sum#101, isEmpty#102]
Keys [1]: [web_site_id#92]
Functions [3]: [sum(UnscaledValue(ws_ext_sales_price#80)), sum(coalesce(cast(wr_return_amt#85 as decimal(12,2)), 0.00)), sum((ws_net_profit#81 - coalesce(cast(wr_net_loss#86 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(ws_ext_sales_price#80))#103, sum(coalesce(cast(wr_return_amt#85 as decimal(12,2)), 0.00))#104, sum((ws_net_profit#81 - coalesce(cast(wr_net_loss#86 as decimal(12,2)), 0.00)))#105]
Results [5]: [MakeDecimal(sum(UnscaledValue(ws_ext_sales_price#80))#103,17,2) AS sales#106, sum(coalesce(cast(wr_return_amt#85 as decimal(12,2)), 0.00))#104 AS returns#107, sum((ws_net_profit#81 - coalesce(cast(wr_net_loss#86 as decimal(12,2)), 0.00)))#105 AS profit#108, web channel AS channel#109, concat(web_site, web_site_id#92) AS id#110]

(94) Union

(95) Expand [codegen id : 31]
Input [5]: [sales#36, returns#37, profit#38, channel#39, id#40]
Arguments: [[sales#36, returns#37, profit#38, channel#39, id#40, 0], [sales#36, returns#37, profit#38, channel#39, null, 1], [sales#36, returns#37, profit#38, null, null, 3]], [sales#36, returns#37, profit#38, channel#111, id#112, spark_grouping_id#113]

(96) HashAggregate [codegen id : 31]
Input [6]: [sales#36, returns#37, profit#38, channel#111, id#112, spark_grouping_id#113]
Keys [3]: [channel#111, id#112, spark_grouping_id#113]
Functions [3]: [partial_sum(sales#36), partial_sum(returns#37), partial_sum(profit#38)]
Aggregate Attributes [6]: [sum#114, isEmpty#115, sum#116, isEmpty#117, sum#118, isEmpty#119]
Results [9]: [channel#111, id#112, spark_grouping_id#113, sum#120, isEmpty#121, sum#122, isEmpty#123, sum#124, isEmpty#125]

(97) Exchange
Input [9]: [channel#111, id#112, spark_grouping_id#113, sum#120, isEmpty#121, sum#122, isEmpty#123, sum#124, isEmpty#125]
Arguments: hashpartitioning(channel#111, id#112, spark_grouping_id#113, 5), ENSURE_REQUIREMENTS, [plan_id=13]

(98) HashAggregate [codegen id : 32]
Input [9]: [channel#111, id#112, spark_grouping_id#113, sum#120, isEmpty#121, sum#122, isEmpty#123, sum#124, isEmpty#125]
Keys [3]: [channel#111, id#112, spark_grouping_id#113]
Functions [3]: [sum(sales#36), sum(returns#37), sum(profit#38)]
Aggregate Attributes [3]: [sum(sales#36)#126, sum(returns#37)#127, sum(profit#38)#128]
Results [5]: [channel#111, id#112, sum(sales#36)#126 AS sales#129, sum(returns#37)#127 AS returns#130, sum(profit#38)#128 AS profit#131]

(99) TakeOrderedAndProject
Input [5]: [channel#111, id#112, sales#129, returns#130, profit#131]
Arguments: 100, [channel#111 ASC NULLS FIRST, id#112 ASC NULLS FIRST], [channel#111, id#112, sales#129, returns#130, profit#131]

===== Subqueries =====

Subquery:1 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#9, [id=#10]
ObjectHashAggregate (109)
+- Exchange (108)
   +- ObjectHashAggregate (107)
      +- BroadcastExchangeExecProxy (106)


(100) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#18, i_current_price#132]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_current_price), GreaterThan(i_current_price,50.00), IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_current_price:decimal(7,2)>

(101) ColumnarToRow [codegen id : 1]
Input [2]: [i_item_sk#18, i_current_price#132]

(102) Filter [codegen id : 1]
Input [2]: [i_item_sk#18, i_current_price#132]
Condition : ((isnotnull(i_current_price#132) AND (i_current_price#132 > 50.00)) AND isnotnull(i_item_sk#18))

(103) Project [codegen id : 1]
Output [1]: [i_item_sk#18]
Input [2]: [i_item_sk#18, i_current_price#132]

(104) BroadcastExchange
Input [1]: [i_item_sk#18]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=14]

(105) SubqueryBroadcast
Input [1]: [i_item_sk#18]
Arguments: runtimefilter#9, 0, [i_item_sk#18], [id=#133]

(106) BroadcastExchangeExecProxy
Input [1]: [i_item_sk#134]
Arguments: [i_item_sk#18]

(107) ObjectHashAggregate
Input [1]: [i_item_sk#18]
Keys: []
Functions [1]: [partial_bloom_filter_agg(xxhash64(i_item_sk#18, 42), 101823, 1521109, 0, 0)]
Aggregate Attributes [1]: [buf#135]
Results [1]: [buf#136]

(108) Exchange
Input [1]: [buf#136]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=15]

(109) ObjectHashAggregate
Input [1]: [buf#136]
Keys: []
Functions [1]: [bloom_filter_agg(xxhash64(i_item_sk#18, 42), 101823, 1521109, 0, 0)]
Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(i_item_sk#18, 42), 101823, 1521109, 0, 0)#137]
Results [1]: [bloom_filter_agg(xxhash64(i_item_sk#18, 42), 101823, 1521109, 0, 0)#137 AS bloomFilter#138]

Subquery:2 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#11, [id=#12]
ObjectHashAggregate (119)
+- Exchange (118)
   +- ObjectHashAggregate (117)
      +- BroadcastExchangeExecProxy (116)


(110) Scan parquet spark_catalog.default.promotion
Output [2]: [p_promo_sk#19, p_channel_tv#139]
Batched: true
Location [not included in comparison]/{warehouse_dir}/promotion]
PushedFilters: [IsNotNull(p_channel_tv), EqualTo(p_channel_tv,N), IsNotNull(p_promo_sk)]
ReadSchema: struct<p_promo_sk:int,p_channel_tv:string>

(111) ColumnarToRow [codegen id : 1]
Input [2]: [p_promo_sk#19, p_channel_tv#139]

(112) Filter [codegen id : 1]
Input [2]: [p_promo_sk#19, p_channel_tv#139]
Condition : ((isnotnull(p_channel_tv#139) AND (p_channel_tv#139 = N)) AND isnotnull(p_promo_sk#19))

(113) Project [codegen id : 1]
Output [1]: [p_promo_sk#19]
Input [2]: [p_promo_sk#19, p_channel_tv#139]

(114) BroadcastExchange
Input [1]: [p_promo_sk#19]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=16]

(115) SubqueryBroadcast
Input [1]: [p_promo_sk#19]
Arguments: runtimefilter#11, 0, [p_promo_sk#19], [id=#140]

(116) BroadcastExchangeExecProxy
Input [1]: [p_promo_sk#141]
Arguments: [p_promo_sk#19]

(117) ObjectHashAggregate
Input [1]: [p_promo_sk#19]
Keys: []
Functions [1]: [partial_bloom_filter_agg(xxhash64(p_promo_sk#19, 42), 986, 24246, 0, 0)]
Aggregate Attributes [1]: [buf#142]
Results [1]: [buf#143]

(118) Exchange
Input [1]: [buf#143]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=17]

(119) ObjectHashAggregate
Input [1]: [buf#143]
Keys: []
Functions [1]: [bloom_filter_agg(xxhash64(p_promo_sk#19, 42), 986, 24246, 0, 0)]
Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(p_promo_sk#19, 42), 986, 24246, 0, 0)#144]
Results [1]: [bloom_filter_agg(xxhash64(p_promo_sk#19, 42), 986, 24246, 0, 0)#144 AS bloomFilter#145]

Subquery:3 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#7 IN dynamicpruning#8
BroadcastExchange (124)
+- * Project (123)
   +- * Filter (122)
      +- * ColumnarToRow (121)
         +- Scan parquet spark_catalog.default.date_dim (120)


(120) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#20, d_date#146]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-23), LessThanOrEqual(d_date,2000-09-22), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(121) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#20, d_date#146]

(122) Filter [codegen id : 1]
Input [2]: [d_date_sk#20, d_date#146]
Condition : (((isnotnull(d_date#146) AND (d_date#146 >= 2000-08-23)) AND (d_date#146 <= 2000-09-22)) AND isnotnull(d_date_sk#20))

(123) Project [codegen id : 1]
Output [1]: [d_date_sk#20]
Input [2]: [d_date_sk#20, d_date#146]

(124) BroadcastExchange
Input [1]: [d_date_sk#20]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=18]

Subquery:4 Hosting operator id = 34 Hosting Expression = ReusedSubquery Subquery scalar-subquery#9, [id=#10]

Subquery:5 Hosting operator id = 34 Hosting Expression = ReusedSubquery Subquery scalar-subquery#11, [id=#12]

Subquery:6 Hosting operator id = 32 Hosting Expression = cs_sold_date_sk#47 IN dynamicpruning#8

Subquery:7 Hosting operator id = 65 Hosting Expression = ReusedSubquery Subquery scalar-subquery#9, [id=#10]

Subquery:8 Hosting operator id = 65 Hosting Expression = ReusedSubquery Subquery scalar-subquery#11, [id=#12]

Subquery:9 Hosting operator id = 63 Hosting Expression = ws_sold_date_sk#82 IN dynamicpruning#8


