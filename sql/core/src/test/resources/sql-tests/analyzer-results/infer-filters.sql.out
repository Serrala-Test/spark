-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE i1_tbl (
  t1a integer,
  t1b integer,
  t1c integer,
  t1d integer,
  t1e integer,
  t1f integer
) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`i1_tbl`, false


-- !query
CREATE TABLE i2_tbl (
  t2a integer,
  t2b integer,
  t2c integer,
  t2d integer,
  t2e integer,
  t2f integer
) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`i2_tbl`, false


-- !query
CREATE TABLE i3_tbl (
  t3a integer,
  t3b integer,
  t3c integer,
  t3d integer,
  t3e integer,
  t3f integer
) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`i3_tbl`, false


-- !query
select i3_tbl.* from (
    select * from i1_tbl left semi join (select * from i2_tbl where t2a > 1000) tmp2 on i1_tbl.t1a = tmp2.t2a 
) tmp1 join i3_tbl on tmp1.t1a = i3_tbl.t3a
-- !query analysis
Project [t3a#x, t3b#x, t3c#x, t3d#x, t3e#x, t3f#x]
+- Join Inner, (t1a#x = t3a#x)
   :- SubqueryAlias tmp1
   :  +- Project [t1a#x, t1b#x, t1c#x, t1d#x, t1e#x, t1f#x]
   :     +- Join LeftSemi, (t1a#x = t2a#x)
   :        :- SubqueryAlias spark_catalog.default.i1_tbl
   :        :  +- Relation spark_catalog.default.i1_tbl[t1a#x,t1b#x,t1c#x,t1d#x,t1e#x,t1f#x] parquet
   :        +- SubqueryAlias tmp2
   :           +- Project [t2a#x, t2b#x, t2c#x, t2d#x, t2e#x, t2f#x]
   :              +- Filter (t2a#x > 1000)
   :                 +- SubqueryAlias spark_catalog.default.i2_tbl
   :                    +- Relation spark_catalog.default.i2_tbl[t2a#x,t2b#x,t2c#x,t2d#x,t2e#x,t2f#x] parquet
   +- SubqueryAlias spark_catalog.default.i3_tbl
      +- Relation spark_catalog.default.i3_tbl[t3a#x,t3b#x,t3c#x,t3d#x,t3e#x,t3f#x] parquet


-- !query
select * from i1_tbl join i2_tbl on t1a = t2a and t2a = t1b and t1b = t2b and t2b = t1c and t1c = t2c and t2c = t1d and t1d = t2d and t2d = t1e and t1e = t2e and t2e = t1f
-- !query analysis
Project [t1a#x, t1b#x, t1c#x, t1d#x, t1e#x, t1f#x, t2a#x, t2b#x, t2c#x, t2d#x, t2e#x, t2f#x]
+- Join Inner, (((((t1a#x = t2a#x) AND (t2a#x = t1b#x)) AND (t1b#x = t2b#x)) AND ((t2b#x = t1c#x) AND (t1c#x = t2c#x))) AND ((((t2c#x = t1d#x) AND (t1d#x = t2d#x)) AND (t2d#x = t1e#x)) AND ((t1e#x = t2e#x) AND (t2e#x = t1f#x))))
   :- SubqueryAlias spark_catalog.default.i1_tbl
   :  +- Relation spark_catalog.default.i1_tbl[t1a#x,t1b#x,t1c#x,t1d#x,t1e#x,t1f#x] parquet
   +- SubqueryAlias spark_catalog.default.i2_tbl
      +- Relation spark_catalog.default.i2_tbl[t2a#x,t2b#x,t2c#x,t2d#x,t2e#x,t2f#x] parquet


-- !query
DROP TABLE i1_tbl
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.i1_tbl


-- !query
DROP TABLE i2_tbl
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.i2_tbl


-- !query
DROP TABLE i3_tbl
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.i3_tbl
