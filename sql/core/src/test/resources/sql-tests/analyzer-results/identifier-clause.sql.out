-- Automatically generated by SQLQueryTestSuite
-- !query
SET hivevar:colname = 'c'
-- !query analysis
SetCommand (hivevar:colname,Some('c'))


-- !query
SELECT IDENTIFIER(${colname}'_1') FROM VALUES(1) AS T(c_1)
-- !query analysis
Project [c_1#x]
+- SubqueryAlias T
   +- LocalRelation [c_1#x]


-- !query
SELECT IDENTIFIER('c1') FROM VALUES(1) AS T(c1)
-- !query analysis
Project [c1#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x]


-- !query
SELECT IDENTIFIER('t.c1') FROM VALUES(1) AS T(c1)
-- !query analysis
Project [c1#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x]


-- !query
SELECT IDENTIFIER('`t`.c1') FROM VALUES(1) AS T(c1)
-- !query analysis
Project [c1#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x]


-- !query
SELECT IDENTIFIER('c 1') FROM VALUES(1) AS T(`c 1`)
-- !query analysis
Project [c 1#x]
+- SubqueryAlias T
   +- LocalRelation [c 1#x]


-- !query
SELECT IDENTIFIER('') FROM VALUES(1) AS T(``)
-- !query analysis
Project [#x]
+- SubqueryAlias T
   +- LocalRelation [#x]


-- !query
SELECT IDENTIFIER('c' '1') FROM VALUES(1) AS T(c1)
-- !query analysis
Project [c1#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x]


-- !query
SELECT IDENTIFIER('t').c1 FROM VALUES(1) AS T(c1)
-- !query analysis
Project [c1#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x]


-- !query
SELECT T.IDENTIFIER('c1') FROM VALUES(1) AS T(c1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`T`.`IDENTIFIER`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "T.IDENTIFIER('c1')"
  } ]
}


-- !query
SELECT T1.c1 FROM VALUES(1) AS T1(c1) JOIN VALUES(1) AS T2(c1) USING (IDENTIFIER('c1'))
-- !query analysis
Project [c1#x]
+- Project [c1#x]
   +- Join Inner, (c1#x = c1#x)
      :- SubqueryAlias T1
      :  +- LocalRelation [c1#x]
      +- SubqueryAlias T2
         +- LocalRelation [c1#x]


-- !query
SELECT map('a', 1).IDENTIFIER('a') FROM VALUES(1) AS T(c1)
-- !query analysis
Project [map(a, 1)[a] AS map(a, 1)[a]#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x]


-- !query
SELECT named_struct('a', 1).IDENTIFIER('a') FROM VALUES(1) AS T(c1)
-- !query analysis
Project [named_struct(a, 1).a AS named_struct(a, 1).a#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x]


-- !query
CREATE SCHEMA IF NOT EXISTS s
-- !query analysis
CreateNamespace true
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [s]


-- !query
CREATE VIEW s.tab(c1) AS VALUES(1)
-- !query analysis
CreateViewCommand `spark_catalog`.`s`.`tab`, [(c1,None)], VALUES(1), false, false, PersistedView, true
   +- LocalRelation [col1#x]


-- !query
USE SCHEMA s
-- !query analysis
SetNamespaceCommand [s]


-- !query
SELECT * FROM IDENTIFIER('tab')
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.s.tab
   +- View (`spark_catalog`.`s`.`tab`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
SELECT * FROM IDENTIFIER('s.tab')
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.s.tab
   +- View (`spark_catalog`.`s`.`tab`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
SELECT * FROM s.IDENTIFIER('tab')
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.s.tab
   +- View (`spark_catalog`.`s`.`tab`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
SELECT * FROM IDENTIFIER('`s`.`tab`')
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.s.tab
   +- View (`spark_catalog`.`s`.`tab`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
SELECT * FROM IDENTIFIER('s').IDENTIFIER('tab')
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.s.tab
   +- View (`spark_catalog`.`s`.`tab`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
SELECT * FROM IDENTIFIER('s').tab
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.s.tab
   +- View (`spark_catalog`.`s`.`tab`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
SELECT * FROM IDENTIFIER('t' 'a' 'b')
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.s.tab
   +- View (`spark_catalog`.`s`.`tab`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
SELECT IDENTIFIER('t').* FROM VALUES(1) AS T(c1)
-- !query analysis
Project [c1#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x]


-- !query
SELECT IDENTIFIER('COALESCE')(NULL, 1)
-- !query analysis
Project [coalesce(cast(null as int), 1) AS coalesce(NULL, 1)#x]
+- OneRowRelation


-- !query
SELECT row_number() OVER IDENTIFIER('win') FROM VALUES(1) AS T(c1) WINDOW win AS (ORDER BY c1)
-- !query analysis
Project [row_number() OVER (ORDER BY c1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
+- Project [c1#x, row_number() OVER (ORDER BY c1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, row_number() OVER (ORDER BY c1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [row_number() windowspecdefinition(c1#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS row_number() OVER (ORDER BY c1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [c1#x ASC NULLS FIRST]
      +- Project [c1#x]
         +- SubqueryAlias T
            +- LocalRelation [c1#x]


-- !query
SELECT row_number() OVER win FROM VALUES(1) AS T(c1) WINDOW IDENTIFIER('win') AS (ORDER BY c1)
-- !query analysis
Project [row_number() OVER (ORDER BY c1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
+- Project [c1#x, row_number() OVER (ORDER BY c1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, row_number() OVER (ORDER BY c1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [row_number() windowspecdefinition(c1#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS row_number() OVER (ORDER BY c1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [c1#x ASC NULLS FIRST]
      +- Project [c1#x]
         +- SubqueryAlias T
            +- LocalRelation [c1#x]


-- !query
SELECT * FROM VALUES(1),(2),(3) AS T(c1) ORDER BY IDENTIFIER('c1')
-- !query analysis
Sort [c1#x ASC NULLS FIRST], true
+- Project [c1#x]
   +- SubqueryAlias T
      +- LocalRelation [c1#x]


-- !query
SELECT * FROM VALUES(1),(2),(3) AS T(c1) ORDER BY IDENTIFIER('c1') DESC
-- !query analysis
Sort [c1#x DESC NULLS LAST], true
+- Project [c1#x]
   +- SubqueryAlias T
      +- LocalRelation [c1#x]


-- !query
with identifier('v')(identifier('c1')) AS (VALUES(1)) (SELECT c1 FROM v)
-- !query analysis
WithCTE
:- CTERelationDef xxxx, false
:  +- SubqueryAlias v
:     +- Project [col1#x AS c1#x]
:        +- LocalRelation [col1#x]
+- Project [c1#x]
   +- SubqueryAlias v
      +- CTERelationRef xxxx, true, [c1#x]


-- !query
USE SCHEMA default
-- !query analysis
SetNamespaceCommand [default]


-- !query
DROP VIEW s.tab
-- !query analysis
DropTableCommand `spark_catalog`.`s`.`tab`, false, true, false


-- !query
DROP SCHEMA s
-- !query analysis
DropNamespace false, false
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [s]


-- !query
SELECT IDENTIFIER('abs')(-1)
-- !query analysis
Project [abs(-1) AS abs(-1)#x]
+- OneRowRelation


-- !query
USE IDENTIFIER('default')
-- !query analysis
SetCatalogAndNamespace
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [default]


-- !query
CREATE TABLE IDENTIFIER('tab')(c1 INT) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`tab`, false


-- !query
DROP TABLE IF EXISTS IDENTIFIER('tab')
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`tab`, true, false, false


-- !query
CREATE TABLE tab(IDENTIFIER('c1') INT) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`tab`, false


-- !query
INSERT INTO tab VALUES (1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/tab, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/tab], Append, `spark_catalog`.`default`.`tab`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/tab), [c1]
+- Project [cast(col1#x as int) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO IDENTIFIER('tab') VALUES(1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/tab, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/tab], Append, `spark_catalog`.`default`.`tab`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/tab), [c1]
+- Project [cast(col1#x as int) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO tab(IDENTIFIER('c1')) VALUES(1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/tab, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/tab], Append, `spark_catalog`.`default`.`tab`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/tab), [c1]
+- Project [cast(col1#x as int) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
SELECT c1 FROM tab
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.tab
   +- Relation spark_catalog.default.tab[c1#x] parquet


-- !query
DESCRIBE IDENTIFIER('tab')
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`tab`, false, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS tab
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`tab`, true, false, false


-- !query
CREATE OR REPLACE VIEW IDENTIFIER('v')(c1) AS VALUES(1)
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(c1,None)], VALUES(1), false, true, PersistedView, true
   +- LocalRelation [col1#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
DROP VIEW IDENTIFIER('v')
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, false, true, false


-- !query
CREATE TEMPORARY VIEW IDENTIFIER('v')(c1) AS VALUES(1)
-- !query analysis
CreateViewCommand `v`, [(c1,None)], VALUES(1), false, false, LocalTempView, true
   +- LocalRelation [col1#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias v
   +- View (`v`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
DROP VIEW IDENTIFIER('v')
-- !query analysis
DropTempViewCommand v


-- !query
CREATE OR REPLACE VIEW v(IDENTIFIER('c1')) AS VALUES(1)
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(c1,None)], VALUES(1), false, true, PersistedView, true
   +- LocalRelation [col1#x]


-- !query
SELECT c1 FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(col1#x as int) AS c1#x]
         +- LocalRelation [col1#x]


-- !query
DROP VIEW v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, false, true, false
