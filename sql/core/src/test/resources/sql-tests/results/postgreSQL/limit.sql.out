-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 13


-- !query 0
SELECT '' AS two, unique1, unique2, stringu1
		FROM onek WHERE unique1 > 50
		ORDER BY unique1 LIMIT 2
-- !query 0 schema
struct<two:string,unique1:int,unique2:int,stringu1:string>
-- !query 0 output
	51	76	ZBAAAA
	52	985	ACAAAA


-- !query 1
SELECT '' AS five, unique1, unique2, stringu1
		FROM onek WHERE unique1 > 60
		ORDER BY unique1 LIMIT 5
-- !query 1 schema
struct<five:string,unique1:int,unique2:int,stringu1:string>
-- !query 1 output
	61	560	JCAAAA
	62	633	KCAAAA
	63	296	LCAAAA
	64	479	MCAAAA
	65	64	NCAAAA


-- !query 2
SELECT '' AS two, unique1, unique2, stringu1
		FROM onek WHERE unique1 > 60 AND unique1 < 63
		ORDER BY unique1 LIMIT 5
-- !query 2 schema
struct<two:string,unique1:int,unique2:int,stringu1:string>
-- !query 2 output
	61	560	JCAAAA
	62	633	KCAAAA


-- !query 3
SELECT '' AS three, unique1, unique2, stringu1
		FROM onek WHERE unique1 > 100
		ORDER BY unique1 LIMIT 3 OFFSET 20
-- !query 3 schema
struct<three:string,unique1:int,unique2:int,stringu1:string>
-- !query 3 output
	121	700	REAAAA
	122	519	SEAAAA
	123	777	TEAAAA


-- !query 4
SELECT '' AS zero, unique1, unique2, stringu1
		FROM onek WHERE unique1 < 50
		ORDER BY unique1 DESC LIMIT 8 OFFSET 99
-- !query 4 schema
struct<zero:string,unique1:int,unique2:int,stringu1:string>
-- !query 4 output



-- !query 5
SELECT '' AS eleven, unique1, unique2, stringu1
		FROM onek WHERE unique1 < 50
		ORDER BY unique1 DESC LIMIT 20 OFFSET 39
-- !query 5 schema
struct<eleven:string,unique1:int,unique2:int,stringu1:string>
-- !query 5 output
	10	520	KAAAAA
	9	49	JAAAAA
	8	653	IAAAAA
	7	647	HAAAAA
	6	978	GAAAAA
	5	541	FAAAAA
	4	833	EAAAAA
	3	431	DAAAAA
	2	326	CAAAAA
	1	214	BAAAAA
	0	998	AAAAAA


-- !query 6
SELECT '' AS ten, unique1, unique2, stringu1
		FROM onek
		ORDER BY unique1 OFFSET 990
-- !query 6 schema
struct<>
-- !query 6 output
org.apache.spark.sql.AnalysisException
Only the OFFSET clause is allowed in the LIMIT clause, but the OFFSET
 clause is found to be the outermost node. If you know exactly that OFFSET
 clause does not cause excessive overhead and still want to use it, set
 spark.sql.forceUsingOffsetWithoutLimit to true.;


-- !query 7
SELECT '' AS five, unique1, unique2, stringu1
		FROM onek
		ORDER BY unique1 LIMIT 5 OFFSET 900
-- !query 7 schema
struct<five:string,unique1:int,unique2:int,stringu1:string>
-- !query 7 output
	900	913	QIAAAA
	901	931	RIAAAA
	902	702	SIAAAA
	903	641	TIAAAA
	904	793	UIAAAA


-- !query 8
CREATE OR REPLACE TEMPORARY VIEW INT8_TBL AS SELECT * FROM
  (VALUES
    (123, 456),
    (123, 4567890123456789),
    (4567890123456789, 123),
    (4567890123456789, 4567890123456789),
    (4567890123456789, -4567890123456789))
  AS v(q1, q2)
-- !query 8 schema
struct<>
-- !query 8 output



-- !query 9
select * from int8_tbl limit (case when random() < 0.5 then bigint(null) end)
-- !query 9 schema
struct<>
-- !query 9 output
org.apache.spark.sql.AnalysisException
The limit expression must evaluate to a constant value, but got CASE WHEN (`_nondeterministic` < CAST(0.5BD AS DOUBLE)) THEN CAST(NULL AS BIGINT) END;


-- !query 10
select * from int8_tbl offset (case when random() < 0.5 then bigint(null) end)
-- !query 10 schema
struct<>
-- !query 10 output
org.apache.spark.sql.AnalysisException
The offset expression must evaluate to a constant value, but got CASE WHEN (`_nondeterministic` < CAST(0.5BD AS DOUBLE)) THEN CAST(NULL AS BIGINT) END;


-- !query 11
DROP VIEW INT8_TBL
-- !query 11 schema
struct<>
-- !query 11 output



-- !query 12
select sum(tenthous) as s1, sum(tenthous) + random()*0 as s2
  from tenk1 group by thousand order by thousand limit 3
-- !query 12 schema
struct<s1:bigint,s2:double>
-- !query 12 output
45000	45000.0
45010	45010.0
45020	45020.0
