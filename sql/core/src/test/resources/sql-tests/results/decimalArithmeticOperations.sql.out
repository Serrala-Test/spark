-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 45


-- !query 0
CREATE TEMPORARY VIEW t AS SELECT 1.0 as a, 0.0 as b
-- !query 0 schema
struct<>
-- !query 0 output



-- !query 1
select a / b from t
-- !query 1 schema
struct<(CAST(a AS DECIMAL(2,1)) / CAST(b AS DECIMAL(2,1))):decimal(8,6)>
-- !query 1 output
NULL


-- !query 2
select a % b from t
-- !query 2 schema
struct<(CAST(a AS DECIMAL(2,1)) % CAST(b AS DECIMAL(2,1))):decimal(1,1)>
-- !query 2 output
NULL


-- !query 3
select pmod(a, b) from t
-- !query 3 schema
struct<pmod(CAST(a AS DECIMAL(2,1)), CAST(b AS DECIMAL(2,1))):decimal(1,1)>
-- !query 3 output
NULL


-- !query 4
create table decimals_test(id int, a decimal(38,18), b decimal(38,18)) using parquet
-- !query 4 schema
struct<>
-- !query 4 output



-- !query 5
insert into decimals_test values(1, 100.0, 999.0), (2, 12345.123, 12345.123),
  (3, 0.1234567891011, 1234.1), (4, 123456789123456789.0, 1.123456789123456789)
-- !query 5 schema
struct<>
-- !query 5 output



-- !query 6
select id, a+b, a-b, a*b, a/b from decimals_test order by id
-- !query 6 schema
struct<id:int,(a + b):decimal(38,17),(a - b):decimal(38,17),(a * b):decimal(38,6),(a / b):decimal(38,6)>
-- !query 6 output
1	1099	-899	99900	0.1001
2	24690.246	0	152402061.885129	1
3	1234.2234567891011	-1233.9765432108989	152.358023	0.0001
4	123456789123456790.12345678912345679	123456789123456787.87654321087654321	138698367904130467.515623	109890109097814272.043109


-- !query 7
select id, a*10, b/10 from decimals_test order by id
-- !query 7 schema
struct<id:int,(CAST(a AS DECIMAL(38,18)) * CAST(CAST(10 AS DECIMAL(2,0)) AS DECIMAL(38,18))):decimal(38,15),(CAST(b AS DECIMAL(38,18)) / CAST(CAST(10 AS DECIMAL(2,0)) AS DECIMAL(38,18))):decimal(38,18)>
-- !query 7 output
1	1000	99.9
2	123451.23	1234.5123
3	1.234567891011	123.41
4	1234567891234567890	0.112345678912345679


-- !query 8
select 10.3 * 3.0
-- !query 8 schema
struct<(CAST(10.3 AS DECIMAL(3,1)) * CAST(3.0 AS DECIMAL(3,1))):decimal(6,2)>
-- !query 8 output
30.9


-- !query 9
select 10.3000 * 3.0
-- !query 9 schema
struct<(CAST(10.3000 AS DECIMAL(6,4)) * CAST(3.0 AS DECIMAL(6,4))):decimal(9,5)>
-- !query 9 output
30.9


-- !query 10
select 10.30000 * 30.0
-- !query 10 schema
struct<(CAST(10.30000 AS DECIMAL(7,5)) * CAST(30.0 AS DECIMAL(7,5))):decimal(11,6)>
-- !query 10 output
309


-- !query 11
select 10.300000000000000000 * 3.000000000000000000
-- !query 11 schema
struct<(CAST(10.300000000000000000 AS DECIMAL(20,18)) * CAST(3.000000000000000000 AS DECIMAL(20,18))):decimal(38,34)>
-- !query 11 output
30.9


-- !query 12
select 10.300000000000000000 * 3.0000000000000000000
-- !query 12 schema
struct<(CAST(10.300000000000000000 AS DECIMAL(21,19)) * CAST(3.0000000000000000000 AS DECIMAL(21,19))):decimal(38,34)>
-- !query 12 output
30.9


-- !query 13
select (5e36 + 0.1) + 5e36
-- !query 13 schema
struct<(CAST((CAST(5E+36 AS DECIMAL(38,1)) + CAST(0.1 AS DECIMAL(38,1))) AS DECIMAL(38,1)) + CAST(5E+36 AS DECIMAL(38,1))):decimal(38,1)>
-- !query 13 output
NULL


-- !query 14
select (-4e36 - 0.1) - 7e36
-- !query 14 schema
struct<(CAST((CAST(-4E+36 AS DECIMAL(38,1)) - CAST(0.1 AS DECIMAL(38,1))) AS DECIMAL(38,1)) - CAST(7E+36 AS DECIMAL(38,1))):decimal(38,1)>
-- !query 14 output
NULL


-- !query 15
select 12345678901234567890.0 * 12345678901234567890.0
-- !query 15 schema
struct<(12345678901234567890.0 * 12345678901234567890.0):decimal(38,2)>
-- !query 15 output
NULL


-- !query 16
select 1e35 / 0.1
-- !query 16 schema
struct<(CAST(1E+35 AS DECIMAL(37,1)) / CAST(0.1 AS DECIMAL(37,1))):decimal(38,6)>
-- !query 16 output
NULL


-- !query 17
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query 17 schema
struct<(CAST(123456789123456789.1234567890 AS DECIMAL(36,18)) * CAST(1.123456789123456789 AS DECIMAL(36,18))):decimal(38,18)>
-- !query 17 output
138698367904130467.654320988515622621


-- !query 18
set spark.sql.decimalOperations.allowPrecisionLoss=false
-- !query 18 schema
struct<key:string,value:string>
-- !query 18 output
spark.sql.decimalOperations.allowPrecisionLoss	false


-- !query 19
select id, a+b, a-b, a*b, a/b from decimals_test order by id
-- !query 19 schema
struct<id:int,(a + b):decimal(38,18),(a - b):decimal(38,18),(a * b):decimal(38,36),(a / b):decimal(38,18)>
-- !query 19 output
1	1099	-899	NULL	0.1001001001001001
2	24690.246	0	NULL	1
3	1234.2234567891011	-1233.9765432108989	NULL	0.000100037913541123
4	123456789123456790.123456789123456789	123456789123456787.876543210876543211	NULL	109890109097814272.043109406191131436


-- !query 20
select id, a*10, b/10 from decimals_test order by id
-- !query 20 schema
struct<id:int,(CAST(a AS DECIMAL(38,18)) * CAST(CAST(10 AS DECIMAL(2,0)) AS DECIMAL(38,18))):decimal(38,18),(CAST(b AS DECIMAL(38,18)) / CAST(CAST(10 AS DECIMAL(2,0)) AS DECIMAL(38,18))):decimal(38,19)>
-- !query 20 output
1	1000	99.9
2	123451.23	1234.5123
3	1.234567891011	123.41
4	1234567891234567890	0.1123456789123456789


-- !query 21
select 10.3 * 3.0
-- !query 21 schema
struct<(CAST(10.3 AS DECIMAL(3,1)) * CAST(3.0 AS DECIMAL(3,1))):decimal(6,2)>
-- !query 21 output
30.9


-- !query 22
select 10.3000 * 3.0
-- !query 22 schema
struct<(CAST(10.3000 AS DECIMAL(6,4)) * CAST(3.0 AS DECIMAL(6,4))):decimal(9,5)>
-- !query 22 output
30.9


-- !query 23
select 10.30000 * 30.0
-- !query 23 schema
struct<(CAST(10.30000 AS DECIMAL(7,5)) * CAST(30.0 AS DECIMAL(7,5))):decimal(11,6)>
-- !query 23 output
309


-- !query 24
select 10.300000000000000000 * 3.000000000000000000
-- !query 24 schema
struct<(CAST(10.300000000000000000 AS DECIMAL(20,18)) * CAST(3.000000000000000000 AS DECIMAL(20,18))):decimal(38,36)>
-- !query 24 output
30.9


-- !query 25
select 10.300000000000000000 * 3.0000000000000000000
-- !query 25 schema
struct<(CAST(10.300000000000000000 AS DECIMAL(21,19)) * CAST(3.0000000000000000000 AS DECIMAL(21,19))):decimal(38,37)>
-- !query 25 output
NULL


-- !query 26
select (5e36 + 0.1) + 5e36
-- !query 26 schema
struct<(CAST((CAST(5E+36 AS DECIMAL(38,1)) + CAST(0.1 AS DECIMAL(38,1))) AS DECIMAL(38,1)) + CAST(5E+36 AS DECIMAL(38,1))):decimal(38,1)>
-- !query 26 output
NULL


-- !query 27
select (-4e36 - 0.1) - 7e36
-- !query 27 schema
struct<(CAST((CAST(-4E+36 AS DECIMAL(38,1)) - CAST(0.1 AS DECIMAL(38,1))) AS DECIMAL(38,1)) - CAST(7E+36 AS DECIMAL(38,1))):decimal(38,1)>
-- !query 27 output
NULL


-- !query 28
select 12345678901234567890.0 * 12345678901234567890.0
-- !query 28 schema
struct<(12345678901234567890.0 * 12345678901234567890.0):decimal(38,2)>
-- !query 28 output
NULL


-- !query 29
select 1e35 / 0.1
-- !query 29 schema
struct<(CAST(1E+35 AS DECIMAL(37,1)) / CAST(0.1 AS DECIMAL(37,1))):decimal(38,3)>
-- !query 29 output
NULL


-- !query 30
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query 30 schema
struct<(CAST(123456789123456789.1234567890 AS DECIMAL(36,18)) * CAST(1.123456789123456789 AS DECIMAL(36,18))):decimal(38,28)>
-- !query 30 output
NULL


-- !query 31
set spark.sql.decimalOperations.nullOnOverflow=false
-- !query 31 schema
struct<key:string,value:string>
-- !query 31 output
spark.sql.decimalOperations.nullOnOverflow	false


-- !query 32
select id, a+b, a-b, a*b, a/b from decimals_test order by id
-- !query 32 schema
struct<>
-- !query 32 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 255.0 failed 1 times, most recent failure: Lost task 1.0 in stage 255.0 (TID 9377, localhost, executor driver): java.lang.ArithmeticException: Decimal(expanded,99900.000000000000000000000000000000000,38,33}) cannot be represented as Decimal(38, 36).
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$9$$anon$1.hasNext(WholeStageCodegenExec.scala:461)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)
	at org.apache.spark.RangePartitioner$$anonfun$12.apply(Partitioner.scala:300)
	at org.apache.spark.RangePartitioner$$anonfun$12.apply(Partitioner.scala:298)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:845)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:


-- !query 33
select id, a*10, b/10 from decimals_test order by id
-- !query 33 schema
struct<id:int,(CAST(a AS DECIMAL(38,18)) * CAST(CAST(10 AS DECIMAL(2,0)) AS DECIMAL(38,18))):decimal(38,18),(CAST(b AS DECIMAL(38,18)) / CAST(CAST(10 AS DECIMAL(2,0)) AS DECIMAL(38,18))):decimal(38,19)>
-- !query 33 output
1	1000	99.9
2	123451.23	1234.5123
3	1.234567891011	123.41
4	1234567891234567890	0.1123456789123456789


-- !query 34
select 10.3 * 3.0
-- !query 34 schema
struct<(CAST(10.3 AS DECIMAL(3,1)) * CAST(3.0 AS DECIMAL(3,1))):decimal(6,2)>
-- !query 34 output
30.9


-- !query 35
select 10.3000 * 3.0
-- !query 35 schema
struct<(CAST(10.3000 AS DECIMAL(6,4)) * CAST(3.0 AS DECIMAL(6,4))):decimal(9,5)>
-- !query 35 output
30.9


-- !query 36
select 10.30000 * 30.0
-- !query 36 schema
struct<(CAST(10.30000 AS DECIMAL(7,5)) * CAST(30.0 AS DECIMAL(7,5))):decimal(11,6)>
-- !query 36 output
309


-- !query 37
select 10.300000000000000000 * 3.000000000000000000
-- !query 37 schema
struct<(CAST(10.300000000000000000 AS DECIMAL(20,18)) * CAST(3.000000000000000000 AS DECIMAL(20,18))):decimal(38,36)>
-- !query 37 output
30.9


-- !query 38
select 10.300000000000000000 * 3.0000000000000000000
-- !query 38 schema
struct<>
-- !query 38 output
java.lang.ArithmeticException
Decimal(expanded,30.900000000000000000000000000000000000,38,36}) cannot be represented as Decimal(38, 37).


-- !query 39
select (5e36 + 0.1) + 5e36
-- !query 39 schema
struct<>
-- !query 39 output
java.lang.ArithmeticException
Decimal(expanded,10000000000000000000000000000000000000.1,39,1}) cannot be represented as Decimal(38, 1).


-- !query 40
select (-4e36 - 0.1) - 7e36
-- !query 40 schema
struct<>
-- !query 40 output
java.lang.ArithmeticException
Decimal(expanded,-11000000000000000000000000000000000000.1,39,1}) cannot be represented as Decimal(38, 1).


-- !query 41
select 12345678901234567890.0 * 12345678901234567890.0
-- !query 41 schema
struct<>
-- !query 41 output
java.lang.ArithmeticException
Decimal(expanded,1.5241578753238836750190519987501905210E+38,38,-1}) cannot be represented as Decimal(38, 2).


-- !query 42
select 1e35 / 0.1
-- !query 42 schema
struct<>
-- !query 42 output
java.lang.ArithmeticException
Decimal(expanded,1000000000000000000000000000000000000,37,0}) cannot be represented as Decimal(38, 3).


-- !query 43
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query 43 schema
struct<>
-- !query 43 output
java.lang.ArithmeticException
Decimal(expanded,138698367904130467.65432098851562262075,38,20}) cannot be represented as Decimal(38, 28).


-- !query 44
drop table decimals_test
-- !query 44 schema
struct<>
-- !query 44 output

