-- Automatically generated by SQLQueryTestSuite
-- !query
create temp view l (a, b)
as values
    (1, 2.0),
    (1, 2.0),
    (2, 1.0),
    (2, 1.0),
    (3, 3.0),
    (null, null),
    (null, 5.0),
    (6, null)
-- !query schema
struct<>
-- !query output



-- !query
create temp view r (c, d)
as values
    (2, 3.0),
    (2, 3.0),
    (3, 2.0),
    (4, 1.0),
    (null, null),
    (null, 5.0),
    (6, null)
-- !query schema
struct<>
-- !query output



-- !query
select *, (select count(*) from r where l.a = r.c) from l
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
Invalid call to toAttribute on unresolved object


-- !query
select *, (select count(*) from r where l.a = r.c group by c) from l
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
Invalid call to toAttribute on unresolved object


-- !query
select *, (select count(*) from r where l.a = r.c group by 'constant') from l
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
Invalid call to toAttribute on unresolved object


-- !query
select *, (
  select (count(*)) is null
  from r
  where l.a = r.c)
from l
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
Invalid call to toAttribute on unresolved object


-- !query
select *, (
  select (count(*)) is null
  from r
  where l.a = r.c
  group by r.c)
from l
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
Invalid call to toAttribute on unresolved object


-- !query
select *, (select count(*) from r where l.a = r.c having count(*) <= 1) from l
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkException
{
  "errorClass" : "PLAN_VALIDATION_FAILED_RULE_IN_BATCH",
  "messageParameters" : {
    "batch" : "Pullup Correlated Expressions",
    "reason" : "The plan becomes unresolved: 'Project [a#x, b#x, scalar-subquery#x [a#x && (a#x = c#x)] AS scalarsubquery(a)#x]\n:  +- Filter (count(1)#xL <= cast(1 as bigint))\n:     +- Aggregate [c#x], [count(1) AS count(1)#xL, c#x]\n:        +- Project [cast(col1#x as int) AS c#x, cast(col2#x as decimal(2,1)) AS d#x]\n:           +- LocalRelation [col1#x, col2#x]\n+- Project [cast(col1#x as int) AS a#x, cast(col2#x as decimal(2,1)) AS b#x]\n   +- LocalRelation [col1#x, col2#x]\n\nThe previous plan: Project [a#x, b#x, scalar-subquery#x [a#x] AS scalarsubquery(a)#xL]\n:  +- Filter (count(1)#xL <= cast(1 as bigint))\n:     +- Aggregate [count(1) AS count(1)#xL]\n:        +- Filter (outer(a#x) = c#x)\n:           +- Project [cast(col1#x as int) AS c#x, cast(col2#x as decimal(2,1)) AS d#x]\n:              +- LocalRelation [col1#x, col2#x]\n+- Project [cast(col1#x as int) AS a#x, cast(col2#x as decimal(2,1)) AS b#x]\n   +- LocalRelation [col1#x, col2#x]\n",
    "rule" : "org.apache.spark.sql.catalyst.optimizer.PullupCorrelatedPredicates"
  }
}


-- !query
select *, (select count(*) from r where l.a = r.c having count(*) >= 2) from l
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkException
{
  "errorClass" : "PLAN_VALIDATION_FAILED_RULE_IN_BATCH",
  "messageParameters" : {
    "batch" : "Pullup Correlated Expressions",
    "reason" : "The plan becomes unresolved: 'Project [a#x, b#x, scalar-subquery#x [a#x && (a#x = c#x)] AS scalarsubquery(a)#x]\n:  +- Filter (count(1)#xL >= cast(2 as bigint))\n:     +- Aggregate [c#x], [count(1) AS count(1)#xL, c#x]\n:        +- Project [cast(col1#x as int) AS c#x, cast(col2#x as decimal(2,1)) AS d#x]\n:           +- LocalRelation [col1#x, col2#x]\n+- Project [cast(col1#x as int) AS a#x, cast(col2#x as decimal(2,1)) AS b#x]\n   +- LocalRelation [col1#x, col2#x]\n\nThe previous plan: Project [a#x, b#x, scalar-subquery#x [a#x] AS scalarsubquery(a)#xL]\n:  +- Filter (count(1)#xL >= cast(2 as bigint))\n:     +- Aggregate [count(1) AS count(1)#xL]\n:        +- Filter (outer(a#x) = c#x)\n:           +- Project [cast(col1#x as int) AS c#x, cast(col2#x as decimal(2,1)) AS d#x]\n:              +- LocalRelation [col1#x, col2#x]\n+- Project [cast(col1#x as int) AS a#x, cast(col2#x as decimal(2,1)) AS b#x]\n   +- LocalRelation [col1#x, col2#x]\n",
    "rule" : "org.apache.spark.sql.catalyst.optimizer.PullupCorrelatedPredicates"
  }
}


-- !query
set spark.sql.optimizer.decorrelateSubqueryLegacyIncorrectCountHandling.enabled = true
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.optimizer.decorrelateSubqueryLegacyIncorrectCountHandling.enabled	true


-- !query
select *, (select count(*) from r where l.a = r.c) from l
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
Invalid call to toAttribute on unresolved object


-- !query
select *, (select count(*) from r where l.a = r.c group by c) from l
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
Invalid call to toAttribute on unresolved object


-- !query
select *, (select count(*) from r where l.a = r.c group by 'constant') from l
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
Invalid call to toAttribute on unresolved object


-- !query
reset spark.sql.optimizer.decorrelateSubqueryLegacyIncorrectCountHandling.enabled
-- !query schema
struct<>
-- !query output

