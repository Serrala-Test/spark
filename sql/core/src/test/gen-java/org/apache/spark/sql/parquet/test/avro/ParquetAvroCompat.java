/**
 * Autogenerated by Avro
 * 
 * DO NOT EDIT DIRECTLY
 */
package org.apache.spark.sql.parquet.test.avro;  
@SuppressWarnings("all")
@org.apache.avro.specific.AvroGenerated
public class ParquetAvroCompat extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"ParquetAvroCompat\",\"namespace\":\"org.apache.spark.sql.parquet.test.avro\",\"fields\":[{\"name\":\"bool_column\",\"type\":\"boolean\"},{\"name\":\"int_column\",\"type\":\"int\"},{\"name\":\"long_column\",\"type\":\"long\"},{\"name\":\"float_column\",\"type\":\"float\"},{\"name\":\"double_column\",\"type\":\"double\"},{\"name\":\"binary_column\",\"type\":\"bytes\"},{\"name\":\"string_column\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"enum_column\",\"type\":{\"type\":\"enum\",\"name\":\"Suit\",\"symbols\":[\"SPADES\",\"HEARTS\",\"DIAMONDS\",\"CLUBS\"]}},{\"name\":\"maybe_bool_column\",\"type\":[\"null\",\"boolean\"]},{\"name\":\"maybe_int_column\",\"type\":[\"null\",\"int\"]},{\"name\":\"maybe_long_column\",\"type\":[\"null\",\"long\"]},{\"name\":\"maybe_float_column\",\"type\":[\"null\",\"float\"]},{\"name\":\"maybe_double_column\",\"type\":[\"null\",\"double\"]},{\"name\":\"maybe_binary_column\",\"type\":[\"null\",\"bytes\"]},{\"name\":\"maybe_string_column\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}]},{\"name\":\"maybe_enum_column\",\"type\":[\"null\",\"Suit\"]},{\"name\":\"strings_column\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}},{\"name\":\"structs_column\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"record\",\"name\":\"Nested\",\"fields\":[{\"name\":\"nested_ints_column\",\"type\":{\"type\":\"array\",\"items\":\"int\"}},{\"name\":\"nested_string_column\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}]}}},{\"name\":\"string_to_int_column\",\"type\":{\"type\":\"map\",\"values\":\"int\",\"avro.java.string\":\"String\"}},{\"name\":\"complex_column\",\"type\":{\"type\":\"map\",\"values\":{\"type\":\"array\",\"items\":\"Nested\"},\"avro.java.string\":\"String\"}},{\"name\":\"maybe_strings_column\",\"type\":[\"null\",{\"type\":\"array\",\"items\":{\"type\":\"string\",\"avro.java.string\":\"String\"}}]},{\"name\":\"maybe_structs_column\",\"type\":[\"null\",{\"type\":\"array\",\"items\":\"Nested\"}]},{\"name\":\"maybe_string_to_int_column\",\"type\":[\"null\",{\"type\":\"map\",\"values\":\"int\",\"avro.java.string\":\"String\"}]},{\"name\":\"maybe_complex_column\",\"type\":[\"null\",{\"type\":\"map\",\"values\":{\"type\":\"array\",\"items\":\"Nested\"},\"avro.java.string\":\"String\"}]}]}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
  @Deprecated public boolean bool_column;
  @Deprecated public int int_column;
  @Deprecated public long long_column;
  @Deprecated public float float_column;
  @Deprecated public double double_column;
  @Deprecated public java.nio.ByteBuffer binary_column;
  @Deprecated public java.lang.String string_column;
  @Deprecated public org.apache.spark.sql.parquet.test.avro.Suit enum_column;
  @Deprecated public java.lang.Boolean maybe_bool_column;
  @Deprecated public java.lang.Integer maybe_int_column;
  @Deprecated public java.lang.Long maybe_long_column;
  @Deprecated public java.lang.Float maybe_float_column;
  @Deprecated public java.lang.Double maybe_double_column;
  @Deprecated public java.nio.ByteBuffer maybe_binary_column;
  @Deprecated public java.lang.String maybe_string_column;
  @Deprecated public org.apache.spark.sql.parquet.test.avro.Suit maybe_enum_column;
  @Deprecated public java.util.List<java.lang.String> strings_column;
  @Deprecated public java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> structs_column;
  @Deprecated public java.util.Map<java.lang.String,java.lang.Integer> string_to_int_column;
  @Deprecated public java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> complex_column;
  @Deprecated public java.util.List<java.lang.String> maybe_strings_column;
  @Deprecated public java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> maybe_structs_column;
  @Deprecated public java.util.Map<java.lang.String,java.lang.Integer> maybe_string_to_int_column;
  @Deprecated public java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> maybe_complex_column;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>. 
   */
  public ParquetAvroCompat() {}

  /**
   * All-args constructor.
   */
  public ParquetAvroCompat(java.lang.Boolean bool_column, java.lang.Integer int_column, java.lang.Long long_column, java.lang.Float float_column, java.lang.Double double_column, java.nio.ByteBuffer binary_column, java.lang.String string_column, org.apache.spark.sql.parquet.test.avro.Suit enum_column, java.lang.Boolean maybe_bool_column, java.lang.Integer maybe_int_column, java.lang.Long maybe_long_column, java.lang.Float maybe_float_column, java.lang.Double maybe_double_column, java.nio.ByteBuffer maybe_binary_column, java.lang.String maybe_string_column, org.apache.spark.sql.parquet.test.avro.Suit maybe_enum_column, java.util.List<java.lang.String> strings_column, java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> structs_column, java.util.Map<java.lang.String,java.lang.Integer> string_to_int_column, java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> complex_column, java.util.List<java.lang.String> maybe_strings_column, java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> maybe_structs_column, java.util.Map<java.lang.String,java.lang.Integer> maybe_string_to_int_column, java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> maybe_complex_column) {
    this.bool_column = bool_column;
    this.int_column = int_column;
    this.long_column = long_column;
    this.float_column = float_column;
    this.double_column = double_column;
    this.binary_column = binary_column;
    this.string_column = string_column;
    this.enum_column = enum_column;
    this.maybe_bool_column = maybe_bool_column;
    this.maybe_int_column = maybe_int_column;
    this.maybe_long_column = maybe_long_column;
    this.maybe_float_column = maybe_float_column;
    this.maybe_double_column = maybe_double_column;
    this.maybe_binary_column = maybe_binary_column;
    this.maybe_string_column = maybe_string_column;
    this.maybe_enum_column = maybe_enum_column;
    this.strings_column = strings_column;
    this.structs_column = structs_column;
    this.string_to_int_column = string_to_int_column;
    this.complex_column = complex_column;
    this.maybe_strings_column = maybe_strings_column;
    this.maybe_structs_column = maybe_structs_column;
    this.maybe_string_to_int_column = maybe_string_to_int_column;
    this.maybe_complex_column = maybe_complex_column;
  }

  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call. 
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return bool_column;
    case 1: return int_column;
    case 2: return long_column;
    case 3: return float_column;
    case 4: return double_column;
    case 5: return binary_column;
    case 6: return string_column;
    case 7: return enum_column;
    case 8: return maybe_bool_column;
    case 9: return maybe_int_column;
    case 10: return maybe_long_column;
    case 11: return maybe_float_column;
    case 12: return maybe_double_column;
    case 13: return maybe_binary_column;
    case 14: return maybe_string_column;
    case 15: return maybe_enum_column;
    case 16: return strings_column;
    case 17: return structs_column;
    case 18: return string_to_int_column;
    case 19: return complex_column;
    case 20: return maybe_strings_column;
    case 21: return maybe_structs_column;
    case 22: return maybe_string_to_int_column;
    case 23: return maybe_complex_column;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }
  // Used by DatumReader.  Applications should not call. 
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: bool_column = (java.lang.Boolean)value$; break;
    case 1: int_column = (java.lang.Integer)value$; break;
    case 2: long_column = (java.lang.Long)value$; break;
    case 3: float_column = (java.lang.Float)value$; break;
    case 4: double_column = (java.lang.Double)value$; break;
    case 5: binary_column = (java.nio.ByteBuffer)value$; break;
    case 6: string_column = (java.lang.String)value$; break;
    case 7: enum_column = (org.apache.spark.sql.parquet.test.avro.Suit)value$; break;
    case 8: maybe_bool_column = (java.lang.Boolean)value$; break;
    case 9: maybe_int_column = (java.lang.Integer)value$; break;
    case 10: maybe_long_column = (java.lang.Long)value$; break;
    case 11: maybe_float_column = (java.lang.Float)value$; break;
    case 12: maybe_double_column = (java.lang.Double)value$; break;
    case 13: maybe_binary_column = (java.nio.ByteBuffer)value$; break;
    case 14: maybe_string_column = (java.lang.String)value$; break;
    case 15: maybe_enum_column = (org.apache.spark.sql.parquet.test.avro.Suit)value$; break;
    case 16: strings_column = (java.util.List<java.lang.String>)value$; break;
    case 17: structs_column = (java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>)value$; break;
    case 18: string_to_int_column = (java.util.Map<java.lang.String,java.lang.Integer>)value$; break;
    case 19: complex_column = (java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>>)value$; break;
    case 20: maybe_strings_column = (java.util.List<java.lang.String>)value$; break;
    case 21: maybe_structs_column = (java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>)value$; break;
    case 22: maybe_string_to_int_column = (java.util.Map<java.lang.String,java.lang.Integer>)value$; break;
    case 23: maybe_complex_column = (java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>>)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  /**
   * Gets the value of the 'bool_column' field.
   */
  public java.lang.Boolean getBoolColumn() {
    return bool_column;
  }

  /**
   * Sets the value of the 'bool_column' field.
   * @param value the value to set.
   */
  public void setBoolColumn(java.lang.Boolean value) {
    this.bool_column = value;
  }

  /**
   * Gets the value of the 'int_column' field.
   */
  public java.lang.Integer getIntColumn() {
    return int_column;
  }

  /**
   * Sets the value of the 'int_column' field.
   * @param value the value to set.
   */
  public void setIntColumn(java.lang.Integer value) {
    this.int_column = value;
  }

  /**
   * Gets the value of the 'long_column' field.
   */
  public java.lang.Long getLongColumn() {
    return long_column;
  }

  /**
   * Sets the value of the 'long_column' field.
   * @param value the value to set.
   */
  public void setLongColumn(java.lang.Long value) {
    this.long_column = value;
  }

  /**
   * Gets the value of the 'float_column' field.
   */
  public java.lang.Float getFloatColumn() {
    return float_column;
  }

  /**
   * Sets the value of the 'float_column' field.
   * @param value the value to set.
   */
  public void setFloatColumn(java.lang.Float value) {
    this.float_column = value;
  }

  /**
   * Gets the value of the 'double_column' field.
   */
  public java.lang.Double getDoubleColumn() {
    return double_column;
  }

  /**
   * Sets the value of the 'double_column' field.
   * @param value the value to set.
   */
  public void setDoubleColumn(java.lang.Double value) {
    this.double_column = value;
  }

  /**
   * Gets the value of the 'binary_column' field.
   */
  public java.nio.ByteBuffer getBinaryColumn() {
    return binary_column;
  }

  /**
   * Sets the value of the 'binary_column' field.
   * @param value the value to set.
   */
  public void setBinaryColumn(java.nio.ByteBuffer value) {
    this.binary_column = value;
  }

  /**
   * Gets the value of the 'string_column' field.
   */
  public java.lang.String getStringColumn() {
    return string_column;
  }

  /**
   * Sets the value of the 'string_column' field.
   * @param value the value to set.
   */
  public void setStringColumn(java.lang.String value) {
    this.string_column = value;
  }

  /**
   * Gets the value of the 'enum_column' field.
   */
  public org.apache.spark.sql.parquet.test.avro.Suit getEnumColumn() {
    return enum_column;
  }

  /**
   * Sets the value of the 'enum_column' field.
   * @param value the value to set.
   */
  public void setEnumColumn(org.apache.spark.sql.parquet.test.avro.Suit value) {
    this.enum_column = value;
  }

  /**
   * Gets the value of the 'maybe_bool_column' field.
   */
  public java.lang.Boolean getMaybeBoolColumn() {
    return maybe_bool_column;
  }

  /**
   * Sets the value of the 'maybe_bool_column' field.
   * @param value the value to set.
   */
  public void setMaybeBoolColumn(java.lang.Boolean value) {
    this.maybe_bool_column = value;
  }

  /**
   * Gets the value of the 'maybe_int_column' field.
   */
  public java.lang.Integer getMaybeIntColumn() {
    return maybe_int_column;
  }

  /**
   * Sets the value of the 'maybe_int_column' field.
   * @param value the value to set.
   */
  public void setMaybeIntColumn(java.lang.Integer value) {
    this.maybe_int_column = value;
  }

  /**
   * Gets the value of the 'maybe_long_column' field.
   */
  public java.lang.Long getMaybeLongColumn() {
    return maybe_long_column;
  }

  /**
   * Sets the value of the 'maybe_long_column' field.
   * @param value the value to set.
   */
  public void setMaybeLongColumn(java.lang.Long value) {
    this.maybe_long_column = value;
  }

  /**
   * Gets the value of the 'maybe_float_column' field.
   */
  public java.lang.Float getMaybeFloatColumn() {
    return maybe_float_column;
  }

  /**
   * Sets the value of the 'maybe_float_column' field.
   * @param value the value to set.
   */
  public void setMaybeFloatColumn(java.lang.Float value) {
    this.maybe_float_column = value;
  }

  /**
   * Gets the value of the 'maybe_double_column' field.
   */
  public java.lang.Double getMaybeDoubleColumn() {
    return maybe_double_column;
  }

  /**
   * Sets the value of the 'maybe_double_column' field.
   * @param value the value to set.
   */
  public void setMaybeDoubleColumn(java.lang.Double value) {
    this.maybe_double_column = value;
  }

  /**
   * Gets the value of the 'maybe_binary_column' field.
   */
  public java.nio.ByteBuffer getMaybeBinaryColumn() {
    return maybe_binary_column;
  }

  /**
   * Sets the value of the 'maybe_binary_column' field.
   * @param value the value to set.
   */
  public void setMaybeBinaryColumn(java.nio.ByteBuffer value) {
    this.maybe_binary_column = value;
  }

  /**
   * Gets the value of the 'maybe_string_column' field.
   */
  public java.lang.String getMaybeStringColumn() {
    return maybe_string_column;
  }

  /**
   * Sets the value of the 'maybe_string_column' field.
   * @param value the value to set.
   */
  public void setMaybeStringColumn(java.lang.String value) {
    this.maybe_string_column = value;
  }

  /**
   * Gets the value of the 'maybe_enum_column' field.
   */
  public org.apache.spark.sql.parquet.test.avro.Suit getMaybeEnumColumn() {
    return maybe_enum_column;
  }

  /**
   * Sets the value of the 'maybe_enum_column' field.
   * @param value the value to set.
   */
  public void setMaybeEnumColumn(org.apache.spark.sql.parquet.test.avro.Suit value) {
    this.maybe_enum_column = value;
  }

  /**
   * Gets the value of the 'strings_column' field.
   */
  public java.util.List<java.lang.String> getStringsColumn() {
    return strings_column;
  }

  /**
   * Sets the value of the 'strings_column' field.
   * @param value the value to set.
   */
  public void setStringsColumn(java.util.List<java.lang.String> value) {
    this.strings_column = value;
  }

  /**
   * Gets the value of the 'structs_column' field.
   */
  public java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> getStructsColumn() {
    return structs_column;
  }

  /**
   * Sets the value of the 'structs_column' field.
   * @param value the value to set.
   */
  public void setStructsColumn(java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> value) {
    this.structs_column = value;
  }

  /**
   * Gets the value of the 'string_to_int_column' field.
   */
  public java.util.Map<java.lang.String,java.lang.Integer> getStringToIntColumn() {
    return string_to_int_column;
  }

  /**
   * Sets the value of the 'string_to_int_column' field.
   * @param value the value to set.
   */
  public void setStringToIntColumn(java.util.Map<java.lang.String,java.lang.Integer> value) {
    this.string_to_int_column = value;
  }

  /**
   * Gets the value of the 'complex_column' field.
   */
  public java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> getComplexColumn() {
    return complex_column;
  }

  /**
   * Sets the value of the 'complex_column' field.
   * @param value the value to set.
   */
  public void setComplexColumn(java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> value) {
    this.complex_column = value;
  }

  /**
   * Gets the value of the 'maybe_strings_column' field.
   */
  public java.util.List<java.lang.String> getMaybeStringsColumn() {
    return maybe_strings_column;
  }

  /**
   * Sets the value of the 'maybe_strings_column' field.
   * @param value the value to set.
   */
  public void setMaybeStringsColumn(java.util.List<java.lang.String> value) {
    this.maybe_strings_column = value;
  }

  /**
   * Gets the value of the 'maybe_structs_column' field.
   */
  public java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> getMaybeStructsColumn() {
    return maybe_structs_column;
  }

  /**
   * Sets the value of the 'maybe_structs_column' field.
   * @param value the value to set.
   */
  public void setMaybeStructsColumn(java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> value) {
    this.maybe_structs_column = value;
  }

  /**
   * Gets the value of the 'maybe_string_to_int_column' field.
   */
  public java.util.Map<java.lang.String,java.lang.Integer> getMaybeStringToIntColumn() {
    return maybe_string_to_int_column;
  }

  /**
   * Sets the value of the 'maybe_string_to_int_column' field.
   * @param value the value to set.
   */
  public void setMaybeStringToIntColumn(java.util.Map<java.lang.String,java.lang.Integer> value) {
    this.maybe_string_to_int_column = value;
  }

  /**
   * Gets the value of the 'maybe_complex_column' field.
   */
  public java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> getMaybeComplexColumn() {
    return maybe_complex_column;
  }

  /**
   * Sets the value of the 'maybe_complex_column' field.
   * @param value the value to set.
   */
  public void setMaybeComplexColumn(java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> value) {
    this.maybe_complex_column = value;
  }

  /** Creates a new ParquetAvroCompat RecordBuilder */
  public static org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder newBuilder() {
    return new org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder();
  }
  
  /** Creates a new ParquetAvroCompat RecordBuilder by copying an existing Builder */
  public static org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder newBuilder(org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder other) {
    return new org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder(other);
  }
  
  /** Creates a new ParquetAvroCompat RecordBuilder by copying an existing ParquetAvroCompat instance */
  public static org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder newBuilder(org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat other) {
    return new org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder(other);
  }
  
  /**
   * RecordBuilder for ParquetAvroCompat instances.
   */
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<ParquetAvroCompat>
    implements org.apache.avro.data.RecordBuilder<ParquetAvroCompat> {

    private boolean bool_column;
    private int int_column;
    private long long_column;
    private float float_column;
    private double double_column;
    private java.nio.ByteBuffer binary_column;
    private java.lang.String string_column;
    private org.apache.spark.sql.parquet.test.avro.Suit enum_column;
    private java.lang.Boolean maybe_bool_column;
    private java.lang.Integer maybe_int_column;
    private java.lang.Long maybe_long_column;
    private java.lang.Float maybe_float_column;
    private java.lang.Double maybe_double_column;
    private java.nio.ByteBuffer maybe_binary_column;
    private java.lang.String maybe_string_column;
    private org.apache.spark.sql.parquet.test.avro.Suit maybe_enum_column;
    private java.util.List<java.lang.String> strings_column;
    private java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> structs_column;
    private java.util.Map<java.lang.String,java.lang.Integer> string_to_int_column;
    private java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> complex_column;
    private java.util.List<java.lang.String> maybe_strings_column;
    private java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> maybe_structs_column;
    private java.util.Map<java.lang.String,java.lang.Integer> maybe_string_to_int_column;
    private java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> maybe_complex_column;

    /** Creates a new Builder */
    private Builder() {
      super(org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.SCHEMA$);
    }
    
    /** Creates a Builder by copying an existing Builder */
    private Builder(org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.bool_column)) {
        this.bool_column = data().deepCopy(fields()[0].schema(), other.bool_column);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.int_column)) {
        this.int_column = data().deepCopy(fields()[1].schema(), other.int_column);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.long_column)) {
        this.long_column = data().deepCopy(fields()[2].schema(), other.long_column);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.float_column)) {
        this.float_column = data().deepCopy(fields()[3].schema(), other.float_column);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.double_column)) {
        this.double_column = data().deepCopy(fields()[4].schema(), other.double_column);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.binary_column)) {
        this.binary_column = data().deepCopy(fields()[5].schema(), other.binary_column);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.string_column)) {
        this.string_column = data().deepCopy(fields()[6].schema(), other.string_column);
        fieldSetFlags()[6] = true;
      }
      if (isValidValue(fields()[7], other.enum_column)) {
        this.enum_column = data().deepCopy(fields()[7].schema(), other.enum_column);
        fieldSetFlags()[7] = true;
      }
      if (isValidValue(fields()[8], other.maybe_bool_column)) {
        this.maybe_bool_column = data().deepCopy(fields()[8].schema(), other.maybe_bool_column);
        fieldSetFlags()[8] = true;
      }
      if (isValidValue(fields()[9], other.maybe_int_column)) {
        this.maybe_int_column = data().deepCopy(fields()[9].schema(), other.maybe_int_column);
        fieldSetFlags()[9] = true;
      }
      if (isValidValue(fields()[10], other.maybe_long_column)) {
        this.maybe_long_column = data().deepCopy(fields()[10].schema(), other.maybe_long_column);
        fieldSetFlags()[10] = true;
      }
      if (isValidValue(fields()[11], other.maybe_float_column)) {
        this.maybe_float_column = data().deepCopy(fields()[11].schema(), other.maybe_float_column);
        fieldSetFlags()[11] = true;
      }
      if (isValidValue(fields()[12], other.maybe_double_column)) {
        this.maybe_double_column = data().deepCopy(fields()[12].schema(), other.maybe_double_column);
        fieldSetFlags()[12] = true;
      }
      if (isValidValue(fields()[13], other.maybe_binary_column)) {
        this.maybe_binary_column = data().deepCopy(fields()[13].schema(), other.maybe_binary_column);
        fieldSetFlags()[13] = true;
      }
      if (isValidValue(fields()[14], other.maybe_string_column)) {
        this.maybe_string_column = data().deepCopy(fields()[14].schema(), other.maybe_string_column);
        fieldSetFlags()[14] = true;
      }
      if (isValidValue(fields()[15], other.maybe_enum_column)) {
        this.maybe_enum_column = data().deepCopy(fields()[15].schema(), other.maybe_enum_column);
        fieldSetFlags()[15] = true;
      }
      if (isValidValue(fields()[16], other.strings_column)) {
        this.strings_column = data().deepCopy(fields()[16].schema(), other.strings_column);
        fieldSetFlags()[16] = true;
      }
      if (isValidValue(fields()[17], other.structs_column)) {
        this.structs_column = data().deepCopy(fields()[17].schema(), other.structs_column);
        fieldSetFlags()[17] = true;
      }
      if (isValidValue(fields()[18], other.string_to_int_column)) {
        this.string_to_int_column = data().deepCopy(fields()[18].schema(), other.string_to_int_column);
        fieldSetFlags()[18] = true;
      }
      if (isValidValue(fields()[19], other.complex_column)) {
        this.complex_column = data().deepCopy(fields()[19].schema(), other.complex_column);
        fieldSetFlags()[19] = true;
      }
      if (isValidValue(fields()[20], other.maybe_strings_column)) {
        this.maybe_strings_column = data().deepCopy(fields()[20].schema(), other.maybe_strings_column);
        fieldSetFlags()[20] = true;
      }
      if (isValidValue(fields()[21], other.maybe_structs_column)) {
        this.maybe_structs_column = data().deepCopy(fields()[21].schema(), other.maybe_structs_column);
        fieldSetFlags()[21] = true;
      }
      if (isValidValue(fields()[22], other.maybe_string_to_int_column)) {
        this.maybe_string_to_int_column = data().deepCopy(fields()[22].schema(), other.maybe_string_to_int_column);
        fieldSetFlags()[22] = true;
      }
      if (isValidValue(fields()[23], other.maybe_complex_column)) {
        this.maybe_complex_column = data().deepCopy(fields()[23].schema(), other.maybe_complex_column);
        fieldSetFlags()[23] = true;
      }
    }
    
    /** Creates a Builder by copying an existing ParquetAvroCompat instance */
    private Builder(org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat other) {
            super(org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.SCHEMA$);
      if (isValidValue(fields()[0], other.bool_column)) {
        this.bool_column = data().deepCopy(fields()[0].schema(), other.bool_column);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.int_column)) {
        this.int_column = data().deepCopy(fields()[1].schema(), other.int_column);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.long_column)) {
        this.long_column = data().deepCopy(fields()[2].schema(), other.long_column);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.float_column)) {
        this.float_column = data().deepCopy(fields()[3].schema(), other.float_column);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.double_column)) {
        this.double_column = data().deepCopy(fields()[4].schema(), other.double_column);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.binary_column)) {
        this.binary_column = data().deepCopy(fields()[5].schema(), other.binary_column);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.string_column)) {
        this.string_column = data().deepCopy(fields()[6].schema(), other.string_column);
        fieldSetFlags()[6] = true;
      }
      if (isValidValue(fields()[7], other.enum_column)) {
        this.enum_column = data().deepCopy(fields()[7].schema(), other.enum_column);
        fieldSetFlags()[7] = true;
      }
      if (isValidValue(fields()[8], other.maybe_bool_column)) {
        this.maybe_bool_column = data().deepCopy(fields()[8].schema(), other.maybe_bool_column);
        fieldSetFlags()[8] = true;
      }
      if (isValidValue(fields()[9], other.maybe_int_column)) {
        this.maybe_int_column = data().deepCopy(fields()[9].schema(), other.maybe_int_column);
        fieldSetFlags()[9] = true;
      }
      if (isValidValue(fields()[10], other.maybe_long_column)) {
        this.maybe_long_column = data().deepCopy(fields()[10].schema(), other.maybe_long_column);
        fieldSetFlags()[10] = true;
      }
      if (isValidValue(fields()[11], other.maybe_float_column)) {
        this.maybe_float_column = data().deepCopy(fields()[11].schema(), other.maybe_float_column);
        fieldSetFlags()[11] = true;
      }
      if (isValidValue(fields()[12], other.maybe_double_column)) {
        this.maybe_double_column = data().deepCopy(fields()[12].schema(), other.maybe_double_column);
        fieldSetFlags()[12] = true;
      }
      if (isValidValue(fields()[13], other.maybe_binary_column)) {
        this.maybe_binary_column = data().deepCopy(fields()[13].schema(), other.maybe_binary_column);
        fieldSetFlags()[13] = true;
      }
      if (isValidValue(fields()[14], other.maybe_string_column)) {
        this.maybe_string_column = data().deepCopy(fields()[14].schema(), other.maybe_string_column);
        fieldSetFlags()[14] = true;
      }
      if (isValidValue(fields()[15], other.maybe_enum_column)) {
        this.maybe_enum_column = data().deepCopy(fields()[15].schema(), other.maybe_enum_column);
        fieldSetFlags()[15] = true;
      }
      if (isValidValue(fields()[16], other.strings_column)) {
        this.strings_column = data().deepCopy(fields()[16].schema(), other.strings_column);
        fieldSetFlags()[16] = true;
      }
      if (isValidValue(fields()[17], other.structs_column)) {
        this.structs_column = data().deepCopy(fields()[17].schema(), other.structs_column);
        fieldSetFlags()[17] = true;
      }
      if (isValidValue(fields()[18], other.string_to_int_column)) {
        this.string_to_int_column = data().deepCopy(fields()[18].schema(), other.string_to_int_column);
        fieldSetFlags()[18] = true;
      }
      if (isValidValue(fields()[19], other.complex_column)) {
        this.complex_column = data().deepCopy(fields()[19].schema(), other.complex_column);
        fieldSetFlags()[19] = true;
      }
      if (isValidValue(fields()[20], other.maybe_strings_column)) {
        this.maybe_strings_column = data().deepCopy(fields()[20].schema(), other.maybe_strings_column);
        fieldSetFlags()[20] = true;
      }
      if (isValidValue(fields()[21], other.maybe_structs_column)) {
        this.maybe_structs_column = data().deepCopy(fields()[21].schema(), other.maybe_structs_column);
        fieldSetFlags()[21] = true;
      }
      if (isValidValue(fields()[22], other.maybe_string_to_int_column)) {
        this.maybe_string_to_int_column = data().deepCopy(fields()[22].schema(), other.maybe_string_to_int_column);
        fieldSetFlags()[22] = true;
      }
      if (isValidValue(fields()[23], other.maybe_complex_column)) {
        this.maybe_complex_column = data().deepCopy(fields()[23].schema(), other.maybe_complex_column);
        fieldSetFlags()[23] = true;
      }
    }

    /** Gets the value of the 'bool_column' field */
    public java.lang.Boolean getBoolColumn() {
      return bool_column;
    }
    
    /** Sets the value of the 'bool_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setBoolColumn(boolean value) {
      validate(fields()[0], value);
      this.bool_column = value;
      fieldSetFlags()[0] = true;
      return this; 
    }
    
    /** Checks whether the 'bool_column' field has been set */
    public boolean hasBoolColumn() {
      return fieldSetFlags()[0];
    }
    
    /** Clears the value of the 'bool_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearBoolColumn() {
      fieldSetFlags()[0] = false;
      return this;
    }

    /** Gets the value of the 'int_column' field */
    public java.lang.Integer getIntColumn() {
      return int_column;
    }
    
    /** Sets the value of the 'int_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setIntColumn(int value) {
      validate(fields()[1], value);
      this.int_column = value;
      fieldSetFlags()[1] = true;
      return this; 
    }
    
    /** Checks whether the 'int_column' field has been set */
    public boolean hasIntColumn() {
      return fieldSetFlags()[1];
    }
    
    /** Clears the value of the 'int_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearIntColumn() {
      fieldSetFlags()[1] = false;
      return this;
    }

    /** Gets the value of the 'long_column' field */
    public java.lang.Long getLongColumn() {
      return long_column;
    }
    
    /** Sets the value of the 'long_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setLongColumn(long value) {
      validate(fields()[2], value);
      this.long_column = value;
      fieldSetFlags()[2] = true;
      return this; 
    }
    
    /** Checks whether the 'long_column' field has been set */
    public boolean hasLongColumn() {
      return fieldSetFlags()[2];
    }
    
    /** Clears the value of the 'long_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearLongColumn() {
      fieldSetFlags()[2] = false;
      return this;
    }

    /** Gets the value of the 'float_column' field */
    public java.lang.Float getFloatColumn() {
      return float_column;
    }
    
    /** Sets the value of the 'float_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setFloatColumn(float value) {
      validate(fields()[3], value);
      this.float_column = value;
      fieldSetFlags()[3] = true;
      return this; 
    }
    
    /** Checks whether the 'float_column' field has been set */
    public boolean hasFloatColumn() {
      return fieldSetFlags()[3];
    }
    
    /** Clears the value of the 'float_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearFloatColumn() {
      fieldSetFlags()[3] = false;
      return this;
    }

    /** Gets the value of the 'double_column' field */
    public java.lang.Double getDoubleColumn() {
      return double_column;
    }
    
    /** Sets the value of the 'double_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setDoubleColumn(double value) {
      validate(fields()[4], value);
      this.double_column = value;
      fieldSetFlags()[4] = true;
      return this; 
    }
    
    /** Checks whether the 'double_column' field has been set */
    public boolean hasDoubleColumn() {
      return fieldSetFlags()[4];
    }
    
    /** Clears the value of the 'double_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearDoubleColumn() {
      fieldSetFlags()[4] = false;
      return this;
    }

    /** Gets the value of the 'binary_column' field */
    public java.nio.ByteBuffer getBinaryColumn() {
      return binary_column;
    }
    
    /** Sets the value of the 'binary_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setBinaryColumn(java.nio.ByteBuffer value) {
      validate(fields()[5], value);
      this.binary_column = value;
      fieldSetFlags()[5] = true;
      return this; 
    }
    
    /** Checks whether the 'binary_column' field has been set */
    public boolean hasBinaryColumn() {
      return fieldSetFlags()[5];
    }
    
    /** Clears the value of the 'binary_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearBinaryColumn() {
      binary_column = null;
      fieldSetFlags()[5] = false;
      return this;
    }

    /** Gets the value of the 'string_column' field */
    public java.lang.String getStringColumn() {
      return string_column;
    }
    
    /** Sets the value of the 'string_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setStringColumn(java.lang.String value) {
      validate(fields()[6], value);
      this.string_column = value;
      fieldSetFlags()[6] = true;
      return this; 
    }
    
    /** Checks whether the 'string_column' field has been set */
    public boolean hasStringColumn() {
      return fieldSetFlags()[6];
    }
    
    /** Clears the value of the 'string_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearStringColumn() {
      string_column = null;
      fieldSetFlags()[6] = false;
      return this;
    }

    /** Gets the value of the 'enum_column' field */
    public org.apache.spark.sql.parquet.test.avro.Suit getEnumColumn() {
      return enum_column;
    }
    
    /** Sets the value of the 'enum_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setEnumColumn(org.apache.spark.sql.parquet.test.avro.Suit value) {
      validate(fields()[7], value);
      this.enum_column = value;
      fieldSetFlags()[7] = true;
      return this; 
    }
    
    /** Checks whether the 'enum_column' field has been set */
    public boolean hasEnumColumn() {
      return fieldSetFlags()[7];
    }
    
    /** Clears the value of the 'enum_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearEnumColumn() {
      enum_column = null;
      fieldSetFlags()[7] = false;
      return this;
    }

    /** Gets the value of the 'maybe_bool_column' field */
    public java.lang.Boolean getMaybeBoolColumn() {
      return maybe_bool_column;
    }
    
    /** Sets the value of the 'maybe_bool_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeBoolColumn(java.lang.Boolean value) {
      validate(fields()[8], value);
      this.maybe_bool_column = value;
      fieldSetFlags()[8] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_bool_column' field has been set */
    public boolean hasMaybeBoolColumn() {
      return fieldSetFlags()[8];
    }
    
    /** Clears the value of the 'maybe_bool_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeBoolColumn() {
      maybe_bool_column = null;
      fieldSetFlags()[8] = false;
      return this;
    }

    /** Gets the value of the 'maybe_int_column' field */
    public java.lang.Integer getMaybeIntColumn() {
      return maybe_int_column;
    }
    
    /** Sets the value of the 'maybe_int_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeIntColumn(java.lang.Integer value) {
      validate(fields()[9], value);
      this.maybe_int_column = value;
      fieldSetFlags()[9] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_int_column' field has been set */
    public boolean hasMaybeIntColumn() {
      return fieldSetFlags()[9];
    }
    
    /** Clears the value of the 'maybe_int_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeIntColumn() {
      maybe_int_column = null;
      fieldSetFlags()[9] = false;
      return this;
    }

    /** Gets the value of the 'maybe_long_column' field */
    public java.lang.Long getMaybeLongColumn() {
      return maybe_long_column;
    }
    
    /** Sets the value of the 'maybe_long_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeLongColumn(java.lang.Long value) {
      validate(fields()[10], value);
      this.maybe_long_column = value;
      fieldSetFlags()[10] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_long_column' field has been set */
    public boolean hasMaybeLongColumn() {
      return fieldSetFlags()[10];
    }
    
    /** Clears the value of the 'maybe_long_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeLongColumn() {
      maybe_long_column = null;
      fieldSetFlags()[10] = false;
      return this;
    }

    /** Gets the value of the 'maybe_float_column' field */
    public java.lang.Float getMaybeFloatColumn() {
      return maybe_float_column;
    }
    
    /** Sets the value of the 'maybe_float_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeFloatColumn(java.lang.Float value) {
      validate(fields()[11], value);
      this.maybe_float_column = value;
      fieldSetFlags()[11] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_float_column' field has been set */
    public boolean hasMaybeFloatColumn() {
      return fieldSetFlags()[11];
    }
    
    /** Clears the value of the 'maybe_float_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeFloatColumn() {
      maybe_float_column = null;
      fieldSetFlags()[11] = false;
      return this;
    }

    /** Gets the value of the 'maybe_double_column' field */
    public java.lang.Double getMaybeDoubleColumn() {
      return maybe_double_column;
    }
    
    /** Sets the value of the 'maybe_double_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeDoubleColumn(java.lang.Double value) {
      validate(fields()[12], value);
      this.maybe_double_column = value;
      fieldSetFlags()[12] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_double_column' field has been set */
    public boolean hasMaybeDoubleColumn() {
      return fieldSetFlags()[12];
    }
    
    /** Clears the value of the 'maybe_double_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeDoubleColumn() {
      maybe_double_column = null;
      fieldSetFlags()[12] = false;
      return this;
    }

    /** Gets the value of the 'maybe_binary_column' field */
    public java.nio.ByteBuffer getMaybeBinaryColumn() {
      return maybe_binary_column;
    }
    
    /** Sets the value of the 'maybe_binary_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeBinaryColumn(java.nio.ByteBuffer value) {
      validate(fields()[13], value);
      this.maybe_binary_column = value;
      fieldSetFlags()[13] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_binary_column' field has been set */
    public boolean hasMaybeBinaryColumn() {
      return fieldSetFlags()[13];
    }
    
    /** Clears the value of the 'maybe_binary_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeBinaryColumn() {
      maybe_binary_column = null;
      fieldSetFlags()[13] = false;
      return this;
    }

    /** Gets the value of the 'maybe_string_column' field */
    public java.lang.String getMaybeStringColumn() {
      return maybe_string_column;
    }
    
    /** Sets the value of the 'maybe_string_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeStringColumn(java.lang.String value) {
      validate(fields()[14], value);
      this.maybe_string_column = value;
      fieldSetFlags()[14] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_string_column' field has been set */
    public boolean hasMaybeStringColumn() {
      return fieldSetFlags()[14];
    }
    
    /** Clears the value of the 'maybe_string_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeStringColumn() {
      maybe_string_column = null;
      fieldSetFlags()[14] = false;
      return this;
    }

    /** Gets the value of the 'maybe_enum_column' field */
    public org.apache.spark.sql.parquet.test.avro.Suit getMaybeEnumColumn() {
      return maybe_enum_column;
    }
    
    /** Sets the value of the 'maybe_enum_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeEnumColumn(org.apache.spark.sql.parquet.test.avro.Suit value) {
      validate(fields()[15], value);
      this.maybe_enum_column = value;
      fieldSetFlags()[15] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_enum_column' field has been set */
    public boolean hasMaybeEnumColumn() {
      return fieldSetFlags()[15];
    }
    
    /** Clears the value of the 'maybe_enum_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeEnumColumn() {
      maybe_enum_column = null;
      fieldSetFlags()[15] = false;
      return this;
    }

    /** Gets the value of the 'strings_column' field */
    public java.util.List<java.lang.String> getStringsColumn() {
      return strings_column;
    }
    
    /** Sets the value of the 'strings_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setStringsColumn(java.util.List<java.lang.String> value) {
      validate(fields()[16], value);
      this.strings_column = value;
      fieldSetFlags()[16] = true;
      return this; 
    }
    
    /** Checks whether the 'strings_column' field has been set */
    public boolean hasStringsColumn() {
      return fieldSetFlags()[16];
    }
    
    /** Clears the value of the 'strings_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearStringsColumn() {
      strings_column = null;
      fieldSetFlags()[16] = false;
      return this;
    }

    /** Gets the value of the 'structs_column' field */
    public java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> getStructsColumn() {
      return structs_column;
    }
    
    /** Sets the value of the 'structs_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setStructsColumn(java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> value) {
      validate(fields()[17], value);
      this.structs_column = value;
      fieldSetFlags()[17] = true;
      return this; 
    }
    
    /** Checks whether the 'structs_column' field has been set */
    public boolean hasStructsColumn() {
      return fieldSetFlags()[17];
    }
    
    /** Clears the value of the 'structs_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearStructsColumn() {
      structs_column = null;
      fieldSetFlags()[17] = false;
      return this;
    }

    /** Gets the value of the 'string_to_int_column' field */
    public java.util.Map<java.lang.String,java.lang.Integer> getStringToIntColumn() {
      return string_to_int_column;
    }
    
    /** Sets the value of the 'string_to_int_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setStringToIntColumn(java.util.Map<java.lang.String,java.lang.Integer> value) {
      validate(fields()[18], value);
      this.string_to_int_column = value;
      fieldSetFlags()[18] = true;
      return this; 
    }
    
    /** Checks whether the 'string_to_int_column' field has been set */
    public boolean hasStringToIntColumn() {
      return fieldSetFlags()[18];
    }
    
    /** Clears the value of the 'string_to_int_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearStringToIntColumn() {
      string_to_int_column = null;
      fieldSetFlags()[18] = false;
      return this;
    }

    /** Gets the value of the 'complex_column' field */
    public java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> getComplexColumn() {
      return complex_column;
    }
    
    /** Sets the value of the 'complex_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setComplexColumn(java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> value) {
      validate(fields()[19], value);
      this.complex_column = value;
      fieldSetFlags()[19] = true;
      return this; 
    }
    
    /** Checks whether the 'complex_column' field has been set */
    public boolean hasComplexColumn() {
      return fieldSetFlags()[19];
    }
    
    /** Clears the value of the 'complex_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearComplexColumn() {
      complex_column = null;
      fieldSetFlags()[19] = false;
      return this;
    }

    /** Gets the value of the 'maybe_strings_column' field */
    public java.util.List<java.lang.String> getMaybeStringsColumn() {
      return maybe_strings_column;
    }
    
    /** Sets the value of the 'maybe_strings_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeStringsColumn(java.util.List<java.lang.String> value) {
      validate(fields()[20], value);
      this.maybe_strings_column = value;
      fieldSetFlags()[20] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_strings_column' field has been set */
    public boolean hasMaybeStringsColumn() {
      return fieldSetFlags()[20];
    }
    
    /** Clears the value of the 'maybe_strings_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeStringsColumn() {
      maybe_strings_column = null;
      fieldSetFlags()[20] = false;
      return this;
    }

    /** Gets the value of the 'maybe_structs_column' field */
    public java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> getMaybeStructsColumn() {
      return maybe_structs_column;
    }
    
    /** Sets the value of the 'maybe_structs_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeStructsColumn(java.util.List<org.apache.spark.sql.parquet.test.avro.Nested> value) {
      validate(fields()[21], value);
      this.maybe_structs_column = value;
      fieldSetFlags()[21] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_structs_column' field has been set */
    public boolean hasMaybeStructsColumn() {
      return fieldSetFlags()[21];
    }
    
    /** Clears the value of the 'maybe_structs_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeStructsColumn() {
      maybe_structs_column = null;
      fieldSetFlags()[21] = false;
      return this;
    }

    /** Gets the value of the 'maybe_string_to_int_column' field */
    public java.util.Map<java.lang.String,java.lang.Integer> getMaybeStringToIntColumn() {
      return maybe_string_to_int_column;
    }
    
    /** Sets the value of the 'maybe_string_to_int_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeStringToIntColumn(java.util.Map<java.lang.String,java.lang.Integer> value) {
      validate(fields()[22], value);
      this.maybe_string_to_int_column = value;
      fieldSetFlags()[22] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_string_to_int_column' field has been set */
    public boolean hasMaybeStringToIntColumn() {
      return fieldSetFlags()[22];
    }
    
    /** Clears the value of the 'maybe_string_to_int_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeStringToIntColumn() {
      maybe_string_to_int_column = null;
      fieldSetFlags()[22] = false;
      return this;
    }

    /** Gets the value of the 'maybe_complex_column' field */
    public java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> getMaybeComplexColumn() {
      return maybe_complex_column;
    }
    
    /** Sets the value of the 'maybe_complex_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder setMaybeComplexColumn(java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>> value) {
      validate(fields()[23], value);
      this.maybe_complex_column = value;
      fieldSetFlags()[23] = true;
      return this; 
    }
    
    /** Checks whether the 'maybe_complex_column' field has been set */
    public boolean hasMaybeComplexColumn() {
      return fieldSetFlags()[23];
    }
    
    /** Clears the value of the 'maybe_complex_column' field */
    public org.apache.spark.sql.parquet.test.avro.ParquetAvroCompat.Builder clearMaybeComplexColumn() {
      maybe_complex_column = null;
      fieldSetFlags()[23] = false;
      return this;
    }

    @Override
    public ParquetAvroCompat build() {
      try {
        ParquetAvroCompat record = new ParquetAvroCompat();
        record.bool_column = fieldSetFlags()[0] ? this.bool_column : (java.lang.Boolean) defaultValue(fields()[0]);
        record.int_column = fieldSetFlags()[1] ? this.int_column : (java.lang.Integer) defaultValue(fields()[1]);
        record.long_column = fieldSetFlags()[2] ? this.long_column : (java.lang.Long) defaultValue(fields()[2]);
        record.float_column = fieldSetFlags()[3] ? this.float_column : (java.lang.Float) defaultValue(fields()[3]);
        record.double_column = fieldSetFlags()[4] ? this.double_column : (java.lang.Double) defaultValue(fields()[4]);
        record.binary_column = fieldSetFlags()[5] ? this.binary_column : (java.nio.ByteBuffer) defaultValue(fields()[5]);
        record.string_column = fieldSetFlags()[6] ? this.string_column : (java.lang.String) defaultValue(fields()[6]);
        record.enum_column = fieldSetFlags()[7] ? this.enum_column : (org.apache.spark.sql.parquet.test.avro.Suit) defaultValue(fields()[7]);
        record.maybe_bool_column = fieldSetFlags()[8] ? this.maybe_bool_column : (java.lang.Boolean) defaultValue(fields()[8]);
        record.maybe_int_column = fieldSetFlags()[9] ? this.maybe_int_column : (java.lang.Integer) defaultValue(fields()[9]);
        record.maybe_long_column = fieldSetFlags()[10] ? this.maybe_long_column : (java.lang.Long) defaultValue(fields()[10]);
        record.maybe_float_column = fieldSetFlags()[11] ? this.maybe_float_column : (java.lang.Float) defaultValue(fields()[11]);
        record.maybe_double_column = fieldSetFlags()[12] ? this.maybe_double_column : (java.lang.Double) defaultValue(fields()[12]);
        record.maybe_binary_column = fieldSetFlags()[13] ? this.maybe_binary_column : (java.nio.ByteBuffer) defaultValue(fields()[13]);
        record.maybe_string_column = fieldSetFlags()[14] ? this.maybe_string_column : (java.lang.String) defaultValue(fields()[14]);
        record.maybe_enum_column = fieldSetFlags()[15] ? this.maybe_enum_column : (org.apache.spark.sql.parquet.test.avro.Suit) defaultValue(fields()[15]);
        record.strings_column = fieldSetFlags()[16] ? this.strings_column : (java.util.List<java.lang.String>) defaultValue(fields()[16]);
        record.structs_column = fieldSetFlags()[17] ? this.structs_column : (java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>) defaultValue(fields()[17]);
        record.string_to_int_column = fieldSetFlags()[18] ? this.string_to_int_column : (java.util.Map<java.lang.String,java.lang.Integer>) defaultValue(fields()[18]);
        record.complex_column = fieldSetFlags()[19] ? this.complex_column : (java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>>) defaultValue(fields()[19]);
        record.maybe_strings_column = fieldSetFlags()[20] ? this.maybe_strings_column : (java.util.List<java.lang.String>) defaultValue(fields()[20]);
        record.maybe_structs_column = fieldSetFlags()[21] ? this.maybe_structs_column : (java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>) defaultValue(fields()[21]);
        record.maybe_string_to_int_column = fieldSetFlags()[22] ? this.maybe_string_to_int_column : (java.util.Map<java.lang.String,java.lang.Integer>) defaultValue(fields()[22]);
        record.maybe_complex_column = fieldSetFlags()[23] ? this.maybe_complex_column : (java.util.Map<java.lang.String,java.util.List<org.apache.spark.sql.parquet.test.avro.Nested>>) defaultValue(fields()[23]);
        return record;
      } catch (Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }
}
