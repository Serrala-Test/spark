/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.spark.sql.execution.datasources.v2

import scala.jdk.CollectionConverters._

import org.apache.spark.sql.catalyst.InternalRow
import org.apache.spark.sql.catalyst.analysis.ViewAlreadyExistsException
import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, SubqueryExpression, VariableReference}
import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}
import org.apache.spark.sql.connector.catalog.{Identifier, ViewCatalog, ViewInfo}
import org.apache.spark.sql.errors.QueryCompilationErrors
import org.apache.spark.sql.execution.CommandExecutionMode
import org.apache.spark.sql.internal.SQLConf
import org.apache.spark.sql.types.MetadataBuilder
import org.apache.spark.sql.util.SchemaUtils
import org.apache.spark.util.ArrayImplicits.SparkArrayOps

/**
 * Physical plan node for creating a view.
 */
case class CreateViewExec(
    catalog: ViewCatalog,
    ident: Identifier,
    originalText: String,
    query: LogicalPlan,
    userSpecifiedColumns: Seq[(String, Option[String])],
    comment: Option[String],
    properties: Map[String, String],
    allowExisting: Boolean,
    replace: Boolean) extends LeafV2CommandExec {

  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._

  override protected def run(): Seq[InternalRow] = {
    val qe = session.sessionState.executePlan(query, CommandExecutionMode.SKIP)
    qe.assertAnalyzed()
    val analyzedPlan = qe.analyzed

    if (userSpecifiedColumns.nonEmpty) {
      if (userSpecifiedColumns.length > analyzedPlan.output.length) {
        throw QueryCompilationErrors.cannotCreateViewNotEnoughColumnsError(
          ident, userSpecifiedColumns.map(_._1), analyzedPlan)
      } else if (userSpecifiedColumns.length < analyzedPlan.output.length) {
        throw QueryCompilationErrors.cannotCreateViewTooManyColumnsError(
          ident, userSpecifiedColumns.map(_._1), analyzedPlan)
      }
    }

    // When creating a permanent view, not allowed to reference temporary objects.
    // This should be called after `qe.assertAnalyzed()` (i.e., `child` can be resolved)
    verifyTemporaryObjectsNotExists(ident, analyzedPlan)
    verifyAutoGeneratedAliasesNotExists(analyzedPlan, ident)

    val queryOutput = analyzedPlan.schema.fieldNames
    // Generate the query column names,
    // throw an AnalysisException if there exists duplicate column names.
    SchemaUtils.checkColumnNameDuplication(queryOutput.toImmutableArraySeq, SQLConf.get.resolver)

    if (replace) {
      // Detect cyclic view reference on CREATE OR REPLACE VIEW or ALTER VIEW AS.
      checkCyclicViewReference(analyzedPlan, Seq(ident), ident)
    }

    val viewSchema = aliasPlan(analyzedPlan, userSpecifiedColumns).schema
    val columnAliases = userSpecifiedColumns.map(_._1).toArray
    val columnComments = userSpecifiedColumns.map(_._2.getOrElse(null)).toArray

    val engineVersion = "Spark " + org.apache.spark.SPARK_VERSION
    val createEngineVersion = if (replace) None else Some(engineVersion)
    val newProperties = properties ++
        comment.map(ViewCatalog.PROP_COMMENT -> _) ++
        createEngineVersion.map(ViewCatalog.PROP_CREATE_ENGINE_VERSION -> _) +
        (ViewCatalog.PROP_ENGINE_VERSION -> engineVersion)

    val catalogManager = session.sessionState.catalogManager
    val currentCatalog = catalogManager.currentCatalog.name
    val currentNamespace = catalogManager.currentNamespace

    val viewInfo = new ViewInfo(
      ident,
      originalText,
      currentCatalog,
      currentNamespace,
      viewSchema,
      queryOutput,
      columnAliases,
      columnComments,
      newProperties.asJava
    )

    if (replace) {
      // CREATE OR REPLACE VIEW
      catalog.replaceView(viewInfo, true)
    } else {
      try {
        // CREATE VIEW [IF NOT EXISTS]
        catalog.createView(viewInfo)
      } catch {
        case _: ViewAlreadyExistsException if allowExisting => // Ignore
      }
    }

    Seq.empty
  }

  override def output: Seq[Attribute] = Seq.empty

  /**
   * If `userSpecifiedColumns` is defined, alias the analyzed plan to the user specified columns,
   * else return the analyzed plan directly.
   */
  private def aliasPlan(
      analyzedPlan: LogicalPlan,
      userSpecifiedColumns: Seq[(String, Option[String])]): LogicalPlan = {
    if (userSpecifiedColumns.isEmpty) {
      analyzedPlan
    } else {
      val projectList = analyzedPlan.output.zip(userSpecifiedColumns).map {
        case (attr, (colName, None)) => Alias(attr, colName)()
        case (attr, (colName, Some(colComment))) =>
          val meta = new MetadataBuilder().putString("comment", colComment).build()
          Alias(attr, colName)(explicitMetadata = Some(meta))
      }
      val projectedPlan = Project(projectList, analyzedPlan)
      session.sessionState.executePlan(projectedPlan, CommandExecutionMode.SKIP).analyzed
    }
  }

  private def checkCyclicViewReference(
      plan: LogicalPlan,
      path: Seq[Identifier],
      viewIdent: Identifier): Unit = {
    plan match {
      case v: View =>
        val ident = v.desc.ident
        val newPath = path :+ ident
        // If the table identifier equals to the `viewIdent`, current view node is the same with
        // the altered view. We detect a view reference cycle, should throw an AnalysisException.
        if (ident == viewIdent) {
          throw QueryCompilationErrors.recursiveViewDetectedError(viewIdent, newPath)
        } else {
          v.children.foreach { child =>
            checkCyclicViewReference(child, newPath, viewIdent)
          }
        }
      case _ =>
        plan.children.foreach(child => checkCyclicViewReference(child, path, viewIdent))
    }

    // Detect cyclic references from subqueries.
    plan.expressions.foreach { expr =>
      expr match {
        case s: SubqueryExpression =>
          checkCyclicViewReference(s.plan, path, viewIdent)
        case _ => // Do nothing.
      }
    }
  }

  private def verifyAutoGeneratedAliasesNotExists(child: LogicalPlan, name: Identifier): Unit =
    if (!conf.allowAutoGeneratedAliasForView) {
      child.output.foreach { attr =>
        if (attr.metadata.contains("__autoGeneratedAlias")) {
          throw QueryCompilationErrors
            .notAllowedToCreatePermanentViewWithoutAssigningAliasForExpressionError(name, attr)
        }
      }
    }

  /**
   * Permanent views are not allowed to reference temp objects, including temp function and views
   */
  private def verifyTemporaryObjectsNotExists(
      name: Identifier,
      child: LogicalPlan): Unit = {
    import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._
      val tempViews = collectTemporaryViews(child)
      tempViews.foreach { nameParts =>
        throw QueryCompilationErrors.notAllowedToCreatePermanentViewByReferencingTempViewError(
          name, nameParts.quoted)
      }
      val tempVars = collectTemporaryVariables(child)
      tempVars.foreach { nameParts =>
        throw QueryCompilationErrors.notAllowedToCreatePermanentViewByReferencingTempVarError(
          name, nameParts.quoted)
      }
    }


  /**
   * Collect all temporary views and return the identifiers separately.
   */
  private def collectTemporaryViews(child: LogicalPlan): Seq[Seq[String]] = {
    def collectTempViews(child: LogicalPlan): Seq[Seq[String]] = {
      child.flatMap {
        case view: View if view.isTempView => Seq(view.desc.ident.asMultipartIdentifier)
        case plan => plan.expressions.flatMap(_.flatMap {
          case e: SubqueryExpression => collectTempViews(e.plan)
          case _ => Seq.empty
        })
      }.distinct
    }
    collectTempViews(child)
  }

  /**
   * Collect all temporary SQL variables and return the identifiers separately.
   */
  private def collectTemporaryVariables(child: LogicalPlan): Seq[Seq[String]] = {
    def collectTempVars(child: LogicalPlan): Seq[Seq[String]] = {
      child.flatMap { plan =>
        plan.expressions.flatMap(_.flatMap {
          case e: SubqueryExpression => collectTempVars(e.plan)
          case r: VariableReference => Seq(r.originalNameParts)
          case _ => Seq.empty
        })
      }.distinct
    }
    collectTempVars(child)
  }
}
