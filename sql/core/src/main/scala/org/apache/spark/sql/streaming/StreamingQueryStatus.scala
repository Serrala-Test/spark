/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.spark.sql.streaming

import java.{util => ju}

import scala.collection.JavaConverters._

import org.apache.spark.annotation.Experimental

/**
 * :: Experimental ::
 * A class used to report information about the progress of a [[StreamingQuery]].
 *
 * @param name The query name. This name is unique across all active queries.
 * @param id The query id. This id is unique across
 *          all queries that have been started in the current process.
 * @param timestamp Timestamp (ms) of when this query was generated
 * @param inputRate Current rate (rows/sec) at which data is being generated by all the sources
 * @param processingRate Current rate (rows/sec) at which the query is processing data from
 *                       all the sources
 * @param latency  Current average latency between the data being available in source and the sink
 *                   writing the corresponding output
 * @param sourceStatuses Current statuses of the sources.
 * @param sinkStatus Current status of the sink.
 * @param triggerStatus Low-level detailed status of the last completed/currently active trigger
 * @since 2.0.0
 */
@Experimental
class StreamingQueryStatus private(
  val name: String,
  val id: Long,
  val timestamp: Long,
  val inputRate: Double,
  val processingRate: Double,
  val latency: Option[Double],
  val sourceStatuses: Array[SourceStatus],
  val sinkStatus: SinkStatus,
  val triggerStatus: ju.Map[String, String]) {

  override def toString: String = {
    val indent = "    "

    val sourceStatusStrings =
      sourceStatuses.zipWithIndex.flatMap { case (s, i) =>
        Seq(s"Source $i:") ++ s.prettyStrings.map(indent + _)
      }.map(s"|$indent" + _).mkString("\n")
    val sinkStatusString =
      sinkStatus.prettyStrings.map(s"|$indent" + _).mkString("\n")
    val triggerStatusString =
      triggerStatus.asScala.map { case (k, v) => s"|$indent$k: $v" }.mkString("\n")

    val allString = s"""
        |Name: $name
        |Id: $id
        |Timestamp: $timestamp
        |Input rate: $inputRate rows/sec
        |Processing rate $processingRate rows/sec
        |Latency: ${latency.getOrElse("-")} ms
        |Trigger status:
        $triggerStatusString
        |Source statuses:
        $sourceStatusStrings
        |Sink status:
        $sinkStatusString""".stripMargin.split("\n").map(indent + _).mkString("\n")

    s"StreamingQueryStatus:$allString"
  }
}

/** Companion object, primarily for creating StreamingQueryInfo instances internally */
private[sql] object StreamingQueryStatus {
  def apply(
      name: String,
      id: Long,
      timestamp: Long,
      inputRate: Double,
      processingRate: Double,
      latency: Option[Double],
      sourceStatuses: Array[SourceStatus],
      sinkStatus: SinkStatus,
      triggerStatus: Map[String, String]): StreamingQueryStatus = {
    new StreamingQueryStatus(name, id, timestamp, inputRate, processingRate,
      latency, sourceStatuses, sinkStatus, triggerStatus.asJava)
  }
}
