#!/usr/bin/env bash

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

export SPARK_HOME="$(cd `dirname $0`/..; pwd)"
ORIG_ARGS=("$@")

# Load utility functions
. "$SPARK_HOME/bin/utils.sh"

while (($#)); do
  if [ "$1" = "--deploy-mode" ]; then
    DEPLOY_MODE=$2
  elif [ "$1" = "--driver-memory" ]; then
    DRIVER_MEMORY=$2
  elif [ "$1" = "--properties-file" ]; then
    PROPERTIES_FILE=$2
  elif [ "$1" = "--driver-library-path" ]; then
    export SPARK_SUBMIT_LIBRARY_PATH=$2
  elif [ "$1" = "--driver-class-path" ]; then
    export SPARK_SUBMIT_CLASSPATH=$2
  elif [ "$1" = "--driver-java-options" ]; then
    export SPARK_SUBMIT_OPTS=$2
  fi
  shift
done

DEPLOY_MODE=${DEPLOY_MODE:-"client"}
DEFAULT_PROPERTIES_FILE="$SPARK_HOME/conf/spark-defaults.conf"
PROPERTIES_FILE=${PROPERTIES_FILE:-"$DEFAULT_PROPERTIES_FILE"}

unset DRIVER_EXTRA_JAVA_OPTIONS
unset EXECUTOR_EXTRA_JAVA_OPTIONS

# A few Spark configs must be parsed early on before launching the JVM:
#
#   [spark.driver.extra*]
#     These configs encode java options, class paths, and library paths
#     needed to launch the JVM if we are running Spark in client mode
#
#   [spark.*.extraJavaOptions]
#     The escaped characters in these configs must be preserved for
#     splitting the arguments in Java later. For these configs, we
#     export the raw values as environment variables.
#
if [[ -f "$PROPERTIES_FILE" ]]; then
  echo "Using properties file $PROPERTIES_FILE." 1>&2
  # Parse the properties file here only if these special configs exist
  should_parse=$(grep -e "spark.driver.extra*\|spark.*.extraJavaOptions" "$PROPERTIES_FILE")
  if [[ -n "$should_parse" ]]; then
    # This exports the value of the given key into JAVA_PROPERTY_VALUE
    parse_java_property "spark.driver.memory"
    DRIVER_MEMORY_CONF="$JAVA_PROPERTY_VALUE"
    parse_java_property "spark.driver.extraLibraryPath"
    DRIVER_EXTRA_LIBRARY_PATH="$JAVA_PROPERTY_VALUE"
    parse_java_property "spark.driver.extraClassPath"
    DRIVER_EXTRA_CLASSPATH="$JAVA_PROPERTY_VALUE"
    parse_java_property "spark.driver.extraJavaOptions"
    DRIVER_EXTRA_JAVA_OPTS="$JAVA_PROPERTY_VALUE"
    parse_java_property "spark.executor.extraJavaOptions"
    EXECUTOR_EXTRA_JAVA_OPTS="$JAVA_PROPERTY_VALUE"
    # Export these for SparkSubmitArguments.scala to consume
    if [[ -n "DRIVER_EXTRA_JAVA_OPTS" ]]; then
      export DRIVER_EXTRA_JAVA_OPTS
    fi
    if [[ -n "EXECUTOR_EXTRA_JAVA_OPTS" ]]; then
      export EXECUTOR_EXTRA_JAVA_OPTS
    fi
  fi
elif [[ "$PROPERTIES_FILE" != "$DEFAULT_PROPERTIES_FILE" ]]; then
  echo "Warning: properties file $PROPERTIES_FILE does not exist." 1>&2
fi

# For client mode, the driver will be launched in the JVM that launches
# SparkSubmit, so we need to handle the class paths, java options, and
# memory preemptively in bash. Otherwise, it will be too late by the
# time the JVM has started.

if [[ $DEPLOY_MODE == "client" ]]; then
  if [[ -n "$DRIVER_EXTRA_JAVA_OPTS" ]]; then
    export SPARK_SUBMIT_OPTS="$SPARK_SUBMIT_OPTS $DRIVER_EXTRA_JAVA_OPTS"
  fi
  if [[ -n "$DRIVER_EXTRA_CLASSPATH" ]]; then
    export SPARK_SUBMIT_CLASSPATH="$SPARK_SUBMIT_CLASSPATH:$DRIVER_EXTRA_CLASSPATH"
  fi
  if [[ -n "$DRIVER_EXTRA_LIBRARY_PATH" ]]; then
    export SPARK_SUBMIT_LIBRARY_PATH="$SPARK_SUBMIT_LIBRARY_PATH:$DRIVER_EXTRA_LIBRARY_PATH"
  fi
  # Favor command line memory over config memory
  DRIVER_MEMORY=${DRIVER_MEMORY:-"$DRIVER_MEMORY_CONF"}
  if [[ -n "$DRIVER_MEMORY" ]]; then
    export SPARK_DRIVER_MEMORY=$DRIVER_MEMORY
  fi
fi

exec $SPARK_HOME/bin/spark-class org.apache.spark.deploy.SparkSubmit "${ORIG_ARGS[@]}"

