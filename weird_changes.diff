commit 20b9b9350b650eda7601e49249a1780b32cd3f07
Author: Richard Yu <richard.yu@databricks.com>
Date:   Mon Jun 12 10:36:47 2023 -0700

    Adding error analysis test

diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/NamedArgumentExpression.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/NamedArgumentExpression.scala
index c6b3f99c20d..20f7f30a280 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/NamedArgumentExpression.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/NamedArgumentExpression.scala
@@ -25,9 +25,6 @@ import org.apache.spark.sql.types.DataType
  * SQL Syntax: key => value
  * SQL grammar: key=identifier FAT_ARROW value=expression
  *
- * NamedArgumentExpression is expected to be resolved
- * and replaced in class extending [[NamedArgumentFunction]]
- *
  * Example usage in encode:
  * SELECT encode("abc", charset => "utf-8");
  * SELECT encode(charset => "utf-8", value => "abc");
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
index 377f83367ff..64e0b9a0985 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
@@ -45,7 +45,7 @@ import org.apache.spark.sql.catalyst.util.DateTimeUtils.{convertSpecialDate, con
 import org.apache.spark.sql.connector.catalog.{CatalogV2Util, SupportsNamespaces, TableCatalog}
 import org.apache.spark.sql.connector.catalog.TableChange.ColumnPosition
 import org.apache.spark.sql.connector.expressions.{ApplyTransform, BucketTransform, DaysTransform, Expression => V2Expression, FieldReference, HoursTransform, IdentityTransform, LiteralValue, MonthsTransform, Transform, YearsTransform}
-import org.apache.spark.sql.errors.{QueryCompilationErrors, QueryParsingErrors}
+import org.apache.spark.sql.errors.QueryParsingErrors
 import org.apache.spark.sql.internal.SQLConf
 import org.apache.spark.sql.types._
 import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}
@@ -277,10 +277,10 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
 
   /**
    * Parameters used for writing query to a table:
-   *   (table ident, tableColumnList, partitionKeys, ifPartitionNotExists, byName).
+   *   (UnresolvedRelation, tableColumnList, partitionKeys, ifPartitionNotExists).
    */
-  type InsertTableParams =
-    (IdentifierReferenceContext, Seq[String], Map[String, Option[String]], Boolean, Boolean)
+  type InsertTableParams = (IdentifierReferenceContext,
+    Seq[String], Map[String, Option[String]], Boolean)
 
   /**
    * Parameters used for writing query to a directory: (isLocal, CatalogStorageFormat, provider).
@@ -291,7 +291,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
    * Add an
    * {{{
    *   INSERT OVERWRITE TABLE tableIdentifier [partitionSpec [IF NOT EXISTS]]? [identifierList]
-   *   INSERT INTO [TABLE] tableIdentifier [partitionSpec] ([BY NAME] | [identifierList])
+   *   INSERT INTO [TABLE] tableIdentifier [partitionSpec]  [identifierList]
    *   INSERT INTO [TABLE] tableIdentifier REPLACE whereClause
    *   INSERT OVERWRITE [LOCAL] DIRECTORY STRING [rowFormat] [createFileFormat]
    *   INSERT OVERWRITE [LOCAL] DIRECTORY [STRING] tableProvider [OPTIONS tablePropertyList]
@@ -302,29 +302,25 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
       ctx: InsertIntoContext,
       query: LogicalPlan): LogicalPlan = withOrigin(ctx) {
     ctx match {
-      // We cannot push withIdentClause() into the write command because:
-      //   1. `PlanWithUnresolvedIdentifier` is not a NamedRelation
-      //   2. Write commands do not hold the table logical plan as a child, and we need to add
-      //      additional resolution code to resolve identifiers inside the write commands.
       case table: InsertIntoTableContext =>
-        val (relationCtx, cols, partition, ifPartitionNotExists, byName)
-        = visitInsertIntoTable(table)
-        withIdentClause(relationCtx, ident => {
+        val (relation, cols, partition, ifPartitionNotExists) = visitInsertIntoTable(table)
+        // We cannot push withIdentClause() into the InsertIntoStatement because
+        // InsertIntoStatement() is a unary node. Changing that two binary will bypass streaming
+        // specific code in InsertIntoStatement resolution in the analyzer
+        withIdentClause(relation, ident => {
           InsertIntoStatement(
-            createUnresolvedRelation(relationCtx, ident),
+            createUnresolvedRelation(relation, ident),
             partition,
             cols,
             query,
             overwrite = false,
-            ifPartitionNotExists,
-            byName)
+            ifPartitionNotExists)
         })
       case table: InsertOverwriteTableContext =>
-        val (relationCtx, cols, partition, ifPartitionNotExists, _)
-        = visitInsertOverwriteTable(table)
-        withIdentClause(relationCtx, ident => {
+        val (relation, cols, partition, ifPartitionNotExists) = visitInsertOverwriteTable(table)
+        withIdentClause(relation, ident => {
           InsertIntoStatement(
-            createUnresolvedRelation(relationCtx, ident),
+            createUnresolvedRelation(relation, ident),
             partition,
             cols,
             query,
@@ -361,7 +357,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
       operationNotAllowed("INSERT INTO ... IF NOT EXISTS", ctx)
     }
 
-    (ctx.identifierReference, cols, partitionKeys, false, ctx.NAME() != null)
+    (ctx.identifierReference(), cols, partitionKeys, false)
   }
 
   /**
@@ -379,7 +375,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
         dynamicPartitionKeys.keys.mkString(", "), ctx)
     }
 
-    (ctx.identifierReference, cols, partitionKeys, ctx.EXISTS() != null, false)
+    (ctx.identifierReference(), cols, partitionKeys, ctx.EXISTS() != null)
   }
 
   /**
@@ -413,7 +409,9 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
 
   override def visitDeleteFromTable(
       ctx: DeleteFromTableContext): LogicalPlan = withOrigin(ctx) {
-    val table = createUnresolvedRelation(ctx.identifierReference)
+    val table = withIdentClause(
+      ctx.identifierReference,
+      createUnresolvedRelation(ctx.identifierReference, _))
     val tableAlias = getTableAliasWithoutColumnAlias(ctx.tableAlias(), "DELETE")
     val aliasedTable = tableAlias.map(SubqueryAlias(_, table)).getOrElse(table)
     val predicate = if (ctx.whereClause() != null) {
@@ -425,7 +423,9 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
   }
 
   override def visitUpdateTable(ctx: UpdateTableContext): LogicalPlan = withOrigin(ctx) {
-    val table = createUnresolvedRelation(ctx.identifierReference)
+    val table = withIdentClause(
+      ctx.identifierReference,
+      createUnresolvedRelation(ctx.identifierReference, _))
     val tableAlias = getTableAliasWithoutColumnAlias(ctx.tableAlias(), "UPDATE")
     val aliasedTable = tableAlias.map(SubqueryAlias(_, table)).getOrElse(table)
     val assignments = withAssignments(ctx.setClause().assignmentList())
@@ -447,12 +447,12 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
     }
 
   override def visitMergeIntoTable(ctx: MergeIntoTableContext): LogicalPlan = withOrigin(ctx) {
-    val targetTable = createUnresolvedRelation(ctx.target)
+    val targetTable = withIdentClause(ctx.target, createUnresolvedRelation(ctx.target, _ ))
     val targetTableAlias = getTableAliasWithoutColumnAlias(ctx.targetAlias, "MERGE")
     val aliasedTarget = targetTableAlias.map(SubqueryAlias(_, targetTable)).getOrElse(targetTable)
 
     val sourceTableOrQuery = if (ctx.source != null) {
-      createUnresolvedRelation(ctx.source)
+      withIdentClause(ctx.source, createUnresolvedRelation(ctx.source, _))
     } else if (ctx.sourceQuery != null) {
       visitQuery(ctx.sourceQuery)
     } else {
@@ -1488,14 +1488,14 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
    * }}}
    */
   override def visitTable(ctx: TableContext): LogicalPlan = withOrigin(ctx) {
-    createUnresolvedRelation(ctx.identifierReference)
+    withIdentClause(ctx.identifierReference, UnresolvedRelation(_))
   }
 
   /**
    * Create an aliased table reference. This is typically used in FROM clauses.
    */
   override def visitTableName(ctx: TableNameContext): LogicalPlan = withOrigin(ctx) {
-    val relation = createUnresolvedRelation(ctx.identifierReference)
+    val relation = withIdentClause(ctx.identifierReference, UnresolvedRelation(_))
     val table = mayApplyAliasPlan(
       ctx.tableAlias, relation.optionalMap(ctx.temporalClause)(withTimeTravel))
     table.optionalMap(ctx.sample)(withSample)
@@ -1536,31 +1536,26 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
     } else {
       Seq.empty
     }
-
-    withIdentClause(
-      func.functionName.expression,
-      () => getFunctionMultiparts(func.functionName),
-      name => {
-        if (name.length > 1) {
-          throw QueryParsingErrors.invalidTableValuedFunctionNameError(name, ctx)
-        }
-        val args = func.functionArgument.asScala.map { e =>
-          if (e.namedArgumentExpression != null) {
-            val key = e.namedArgumentExpression.key.strictIdentifier
-            val value = e.namedArgumentExpression.value
-            NamedArgumentExpression(key.getText, expression(value))
-          } else {
-            expression(e)
-          }
+    withFuncIdentClause(func.functionName, name => {
+      if (name.length > 1) {
+        throw QueryParsingErrors.invalidTableValuedFunctionNameError(name, ctx)
+      }
+      val args = func.functionArgument.asScala.map { e =>
+        if (e.namedArgumentExpression != null) {
+          val key = e.namedArgumentExpression.key.strictIdentifier
+          val value = e.namedArgumentExpression.value
+          NamedArgumentExpression(key.getText, expression(value))
+        } else {
+          expression(e)
         }
+      }
 
-        val tvf = UnresolvedTableValuedFunction(name, args)
+      val tvf = UnresolvedTableValuedFunction(name, args)
 
-        val tvfAliases = if (aliases.nonEmpty) UnresolvedTVFAliases(name, tvf, aliases) else tvf
+      val tvfAliases = if (aliases.nonEmpty) UnresolvedTVFAliases(name, tvf, aliases) else tvf
 
-        tvfAliases.optionalMap(func.tableAlias.strictIdentifier)(aliasPlan)
-      }
-    )
+      tvfAliases.optionalMap(func.tableAlias.strictIdentifier)(aliasPlan)
+    })
   }
 
   /**
@@ -2171,10 +2166,12 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
   }
 
   /**
-   * Create an expression for the IDENTIFIER() clause.
+   * Create a IDENTIFIER() clause.
    */
   override def visitIdentifierClause(ctx: IdentifierClauseContext): Expression = withOrigin(ctx) {
-    ExpressionWithUnresolvedIdentifier(expression(ctx.expression), UnresolvedAttribute(_))
+    // Create the function call.
+    val expr: Expression = expression(ctx.expression())
+    UnresolvedAttributeIdentifierClause(expr)
   }
 
   /**
@@ -2204,18 +2201,19 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
     val filter = Option(ctx.where).map(expression(_))
     val ignoreNulls =
       Option(ctx.nullsOption).map(_.getType == SqlBaseParser.IGNORE).getOrElse(false)
-    val funcCtx = ctx.functionName
-    val func = withIdentClause(funcCtx.expression, () => getFunctionMultiparts(funcCtx), ident => {
-      UnresolvedFunction(ident, arguments, isDistinct, filter, ignoreNulls)
-    })
+    val function = Option(ctx.functionName.expression()).map(p =>
+      UnresolvedFunctionIdentifierClause(expression(p),
+        arguments, isDistinct, filter, ignoreNulls)).getOrElse(
+      UnresolvedFunction(getFunctionMultiparts(ctx.functionName),
+        arguments, isDistinct, filter, ignoreNulls))
 
     // Check if the function is evaluated in a windowed context.
     ctx.windowSpec match {
       case spec: WindowRefContext =>
-        UnresolvedWindowExpression(func, visitWindowRef(spec))
+        UnresolvedWindowExpression(function, visitWindowRef(spec))
       case spec: WindowDefContext =>
-        WindowExpression(func, visitWindowDef(spec))
-      case _ => func
+        WindowExpression(function, visitWindowDef(spec))
+      case _ => function
     }
   }
 
@@ -2719,14 +2717,6 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
     }
   }
 
-  /**
-   * Create an [[UnresolvedRelation]] from an identifier reference.
-   */
-  private def createUnresolvedRelation(
-      ctx: IdentifierReferenceContext): LogicalPlan = withOrigin(ctx) {
-    withIdentClause(ctx, UnresolvedRelation(_))
-  }
-
   /**
    * Create an [[UnresolvedRelation]] from a multi-part identifier.
    */
@@ -2770,7 +2760,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
       ctx: ParserRuleContext,
       ident: Seq[String],
       commandName: String,
-      allowTempView: Boolean): UnresolvedTableOrView = withOrigin(ctx) {
+      allowTempView: Boolean ): UnresolvedTableOrView = withOrigin(ctx) {
     UnresolvedTableOrView(ident, commandName, allowTempView)
   }
 
@@ -3360,20 +3350,6 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
     }
   }
 
-  /**
-   * Parse a key-value map from an [[ExpressionPropertyListContext]], assuming all values are
-   * specified.
-   */
-  override def visitExpressionPropertyList(
-      ctx: ExpressionPropertyListContext): OptionsListExpressions = {
-    val options = ctx.expressionProperty.asScala.map { property =>
-      val key: String = visitPropertyKey(property.key)
-      val value: Expression = Option(property.value).map(expression).getOrElse(null)
-      key -> value
-    }.toSeq
-    OptionsListExpressions(options)
-  }
-
   override def visitStringLit(ctx: StringLitContext): Token = {
     if (ctx != null) {
       if (ctx.STRING_LITERAL != null) {
@@ -3408,7 +3384,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
    */
   type TableClauses = (
       Seq[Transform], Seq[StructField], Option[BucketSpec], Map[String, String],
-      OptionsListExpressions, Option[String], Option[String], Option[SerdeInfo])
+      Map[String, String], Option[String], Option[String], Option[SerdeInfo])
 
   /**
    * Validate a create table statement and return the [[TableIdentifier]].
@@ -3668,8 +3644,8 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
         ctx.EXTENDED != null)
     }
 
-  def cleanTableProperties[ValueType](
-      ctx: ParserRuleContext, properties: Map[String, ValueType]): Map[String, ValueType] = {
+  def cleanTableProperties(
+      ctx: ParserRuleContext, properties: Map[String, String]): Map[String, String] = {
     import TableCatalog._
     val legacyOn = conf.getConf(SQLConf.LEGACY_PROPERTY_NON_RESERVED)
     properties.filter {
@@ -3703,26 +3679,18 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
 
   def cleanTableOptions(
       ctx: ParserRuleContext,
-      options: OptionsListExpressions,
-      location: Option[String]): (OptionsListExpressions, Option[String]) = {
+      options: Map[String, String],
+      location: Option[String]): (Map[String, String], Option[String]) = {
     var path = location
-    val filtered = cleanTableProperties(ctx, options.options.toMap).filter {
-      case (key, value) if key.equalsIgnoreCase("path") =>
-        val newValue: String =
-          if (value == null) {
-            ""
-          } else value match {
-            case Literal(_, _: StringType) => value.toString
-            case _ => throw QueryCompilationErrors.optionMustBeLiteralString(key)
-          }
-        if (path.nonEmpty) {
-          throw QueryParsingErrors.duplicatedTablePathsFoundError(path.get, newValue, ctx)
-        }
-        path = Some(newValue)
+    val filtered = cleanTableProperties(ctx, options).filter {
+      case (k, v) if k.equalsIgnoreCase("path") && path.nonEmpty =>
+        throw QueryParsingErrors.duplicatedTablePathsFoundError(path.get, v, ctx)
+      case (k, v) if k.equalsIgnoreCase("path") =>
+        path = Some(v)
         false
       case _ => true
     }
-    (OptionsListExpressions(filtered.toSeq), path)
+    (filtered, path)
   }
 
   /**
@@ -3880,8 +3848,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
     val bucketSpec = ctx.bucketSpec().asScala.headOption.map(visitBucketSpec)
     val properties = Option(ctx.tableProps).map(visitPropertyKeyValues).getOrElse(Map.empty)
     val cleanedProperties = cleanTableProperties(ctx, properties)
-    val options = Option(ctx.options).map(visitExpressionPropertyList)
-      .getOrElse(OptionsListExpressions(Seq.empty))
+    val options = Option(ctx.options).map(visitPropertyKeyValues).getOrElse(Map.empty)
     val location = visitLocationSpecList(ctx.locationSpec())
     val (cleanedOptions, newLocation) = cleanTableOptions(ctx, options, location)
     val comment = visitCommentSpecList(ctx.commentSpec())
@@ -3961,8 +3928,8 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
     val columns = Option(ctx.createOrReplaceTableColTypeList())
       .map(visitCreateOrReplaceTableColTypeList).getOrElse(Nil)
     val provider = Option(ctx.tableProvider).map(_.multipartIdentifier.getText)
-    val (partTransforms, partCols, bucketSpec, properties, options, location,
-      comment, serdeInfo) = visitCreateTableClauses(ctx.createTableClauses())
+    val (partTransforms, partCols, bucketSpec, properties, options, location, comment, serdeInfo) =
+      visitCreateTableClauses(ctx.createTableClauses())
 
     if (provider.isDefined && serdeInfo.isDefined) {
       operationNotAllowed(s"CREATE TABLE ... USING ... ${serdeInfo.get.describe}", ctx)
@@ -3976,7 +3943,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
 
     val partitioning =
       partitionExpressions(partTransforms, partCols, ctx) ++ bucketSpec.map(_.asTransform)
-    val tableSpec = UnresolvedTableSpec(properties, provider, location, comment,
+    val tableSpec = TableSpec(properties, provider, options, location, comment,
       serdeInfo, external)
 
     Option(ctx.query).map(plan) match {
@@ -3993,15 +3960,14 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
 
       case Some(query) =>
         CreateTableAsSelect(withIdentClause(identifierContext, UnresolvedIdentifier(_)),
-          partitioning, query, tableSpec, Map.empty, ifNotExists, optionsListExpressions = options)
+          partitioning, query, tableSpec, Map.empty, ifNotExists)
 
       case _ =>
         // Note: table schema includes both the table columns list and the partition columns
         // with data type.
         val schema = StructType(columns ++ partCols)
         CreateTable(withIdentClause(identifierContext, UnresolvedIdentifier(_)),
-          schema, partitioning, tableSpec, ignoreIfExists = ifNotExists,
-          optionsListExpressions = options)
+          schema, partitioning, tableSpec, ignoreIfExists = ifNotExists)
     }
   }
 
@@ -4046,8 +4012,8 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
 
     val partitioning =
       partitionExpressions(partTransforms, partCols, ctx) ++ bucketSpec.map(_.asTransform)
-    val tableSpec = UnresolvedTableSpec(properties, provider, location, comment,
-      serdeInfo, external = false)
+    val tableSpec = TableSpec(properties, provider, options, location, comment,
+      serdeInfo, false)
 
     Option(ctx.query).map(plan) match {
       case Some(_) if columns.nonEmpty =>
@@ -4064,8 +4030,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
       case Some(query) =>
         ReplaceTableAsSelect(
           withIdentClause(ctx.replaceTableHeader.identifierReference(), UnresolvedIdentifier(_)),
-          partitioning, query, tableSpec, writeOptions = Map.empty, orCreate = orCreate,
-          optionsListExpressions = options)
+          partitioning, query, tableSpec, writeOptions = Map.empty, orCreate = orCreate)
 
       case _ =>
         // Note: table schema includes both the table columns list and the partition columns
@@ -4073,7 +4038,7 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
         val schema = StructType(columns ++ partCols)
         ReplaceTable(
           withIdentClause(ctx.replaceTableHeader.identifierReference(), UnresolvedIdentifier(_)),
-          schema, partitioning, tableSpec, orCreate = orCreate, optionsListExpressions = options)
+          schema, partitioning, tableSpec, orCreate = orCreate)
     }
   }
 
@@ -4108,12 +4073,15 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
    * Create a [[ShowTables]] command.
    */
   override def visitShowTables(ctx: ShowTablesContext): LogicalPlan = withOrigin(ctx) {
-    val ns = if (ctx.identifierReference() != null) {
-      withIdentClause(ctx.identifierReference, UnresolvedNamespace(_))
+    if (ctx.identifierReference() != null) {
+      ShowTables(
+        withIdentClause(ctx.identifierReference, UnresolvedNamespace(_)),
+        Option(ctx.pattern).map(x => string(visitStringLit(x))))
     } else {
-      UnresolvedNamespace(Seq.empty[String])
+    ShowTables(
+      UnresolvedNamespace(Seq.empty[String]),
+      Option(ctx.pattern).map(x => string(visitStringLit(x))))
     }
-    ShowTables(ns, Option(ctx.pattern).map(x => string(visitStringLit(x))))
   }
 
   /**
@@ -4124,24 +4092,32 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
     val partitionKeys = Option(ctx.partitionSpec).map { specCtx =>
       UnresolvedPartitionSpec(visitNonOptionalPartitionSpec(specCtx), None)
     }
-    val ns = if (ctx.identifierReference() != null) {
-      withIdentClause(ctx.identifierReference, UnresolvedNamespace(_))
+    if (ctx.identifierReference() != null) {
+      ShowTableExtended(
+        withIdentClause(ctx.identifierReference, UnresolvedNamespace(_)),
+        string(visitStringLit(ctx.pattern)),
+        partitionKeys)
     } else {
-      UnresolvedNamespace(Seq.empty[String])
+      ShowTableExtended(
+        UnresolvedNamespace(Seq.empty[String]),
+        string(visitStringLit(ctx.pattern)),
+        partitionKeys)
     }
-    ShowTableExtended(ns, string(visitStringLit(ctx.pattern)), partitionKeys)
   }
 
   /**
    * Create a [[ShowViews]] command.
    */
   override def visitShowViews(ctx: ShowViewsContext): LogicalPlan = withOrigin(ctx) {
-    val ns = if (ctx.identifierReference() != null) {
-      withIdentClause(ctx.identifierReference, UnresolvedNamespace(_))
+    if (ctx.identifierReference() != null) {
+      ShowViews(
+        withIdentClause(ctx.identifierReference, UnresolvedNamespace(_)),
+        Option(ctx.pattern).map(x => string(visitStringLit(x))))
     } else {
-      UnresolvedNamespace(Seq.empty[String])
+      ShowViews(
+        UnresolvedNamespace(Seq.empty[String]),
+        Option(ctx.pattern).map(x => string(visitStringLit(x))))
     }
-    ShowViews(ns, Option(ctx.pattern).map(x => string(visitStringLit(x))))
   }
 
   override def visitColPosition(ctx: ColPositionContext): ColumnPosition = {
@@ -4602,12 +4578,15 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
       ctx.identifier.getText.toLowerCase(Locale.ROOT) != "noscan") {
       throw QueryParsingErrors.computeStatisticsNotExpectedError(ctx.identifier())
     }
-    val ns = if (ctx.identifierReference() != null) {
-      withIdentClause(ctx.identifierReference, UnresolvedNamespace(_))
+    if (ctx.identifierReference() != null) {
+        AnalyzeTables(
+          withIdentClause(
+            ctx.identifierReference,
+            UnresolvedNamespace(_)),
+          noScan = ctx.identifier != null)
     } else {
-      UnresolvedNamespace(Seq.empty[String])
+      AnalyzeTables(UnresolvedNamespace(Seq.empty[String]), noScan = ctx.identifier != null)
     }
-    AnalyzeTables(ns, noScan = ctx.identifier != null)
   }
 
   /**
@@ -4680,17 +4659,19 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
 
     val query = Option(ctx.query).map(plan)
     withIdentClause(ctx.identifierReference, ident => {
-      if (query.isDefined && ident.length > 1) {
-        val catalogAndNamespace = ident.init
+      val relation = createUnresolvedRelation(ctx.identifierReference, ident)
+      val tableName = relation.multipartIdentifier
+      if (query.isDefined && tableName.length > 1) {
+        val catalogAndNamespace = tableName.init
         throw QueryParsingErrors.addCatalogInCacheTableAsSelectNotAllowedError(
           catalogAndNamespace.quoted, ctx)
       }
       val options = Option(ctx.options).map(visitPropertyKeyValues).getOrElse(Map.empty)
       val isLazy = ctx.LAZY != null
       if (query.isDefined) {
-        CacheTableAsSelect(ident.head, query.get, source(ctx.query()), isLazy, options)
+        CacheTableAsSelect(tableName.head, query.get, source(ctx.query()), isLazy, options)
       } else {
-        CacheTable(createUnresolvedRelation(ctx.identifierReference, ident), ident, isLazy, options)
+        CacheTable(relation, tableName, isLazy, options)
       }
     })
   }
@@ -4699,7 +4680,11 @@ class AstBuilder extends SqlBaseParserBaseVisitor[AnyRef] with SQLConfHelper wit
    * Create an [[UncacheTable]] logical plan.
    */
   override def visitUncacheTable(ctx: UncacheTableContext): LogicalPlan = withOrigin(ctx) {
-    UncacheTable(createUnresolvedRelation(ctx.identifierReference), ctx.EXISTS != null)
+    UncacheTable(
+      withIdentClause(
+        ctx.identifierReference,
+        createUnresolvedRelation(ctx.identifierReference, _)),
+      ctx.EXISTS != null)
   }
 
   /**
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala
index 069fce237f2..986e7534a1e 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala
@@ -30,7 +30,7 @@ import org.apache.spark._
 import org.apache.spark.sql.{AnalysisException, DataFrame, Dataset, QueryTest, Row, SaveMode}
 import org.apache.spark.sql.catalyst.FunctionIdentifier
 import org.apache.spark.sql.catalyst.analysis.{Parameter, UnresolvedGenerator}
-import org.apache.spark.sql.catalyst.expressions.{Grouping, Literal, RowNumber}
+import org.apache.spark.sql.catalyst.expressions.{Grouping, Literal, NamedArgumentExpression, RowNumber}
 import org.apache.spark.sql.catalyst.expressions.CodegenObjectFactoryMode._
 import org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext
 import org.apache.spark.sql.catalyst.expressions.objects.InitializeJavaBean
@@ -837,6 +837,18 @@ class QueryExecutionErrorsSuite
       sqlState = "XX000")
   }
 
+  test("INTERNAL_ERROR: Calling eval on Unevaluable NamedArgumentExpression") {
+    val e = intercept[SparkException] {
+      NamedArgumentExpression("arg0", Literal("value0")).eval()
+    }
+    checkError(
+      exception = e,
+      errorClass = "INTERNAL_ERROR",
+      parameters = Map("message" -> "Cannot evaluate expression: arg0 => value0"),
+      sqlState = "XX000"
+    )
+  }
+
   test("INTERNAL_ERROR: Calling doGenCode on unresolved") {
     val e = intercept[SparkException] {
       val ctx = new CodegenContext
