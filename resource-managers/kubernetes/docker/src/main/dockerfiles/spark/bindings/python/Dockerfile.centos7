#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

ARG base_img

FROM $base_img
WORKDIR /

# Reset to root to run installation tasks
USER 0

RUN mkdir ${SPARK_HOME}/python
RUN set -ex && \
    yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make libffi-devel -y && \
    wget -O ${SPARK_HOME}/work-dir/Python-3.9.0.tgz https://www.python.org/ftp/python/3.9.0/Python-3.9.0.tgz && \
    cd ${SPARK_HOME}/work-dir/ && \
    tar zxvf Python-3.9.0.tgz && \
    cd Python-3.9.0 && \
    ./configure prefix=/usr/lib/python3 && \
    make && make install && \
    ln -s /usr/lib/python3/bin/python3.9  /usr/bin/python3.9 && \
    ln -s /usr/lib/python3/bin/python3.9  /usr/bin/python3 && \
    ln -s /usr/lib/python3/bin/python3.9 /usr/local/lib/python3.9 && \
    ln -s /usr/lib/python3/bin/python3.9 /usr/local/lib/python3 && \
    ln -s /usr/lib/python3/bin/pip3.9 /usr/bin/pip3.9 && \
    ln -s /usr/lib/python3/bin/pip3.9 /usr/bin/pip3  && \
    ln -s /usr/lib/python3/bin/pip3.9 /usr/bin/pip  && \
    pip3 install --upgrade pip setuptools && \
    rm -rf ${SPARK_HOME}/work-dir/Python-3.9.0* && \
    rm -rf /var/cache/yum/*

COPY python/pyspark ${SPARK_HOME}/python/pyspark
COPY python/lib ${SPARK_HOME}/python/lib

WORKDIR /opt/spark/work-dir
ENTRYPOINT [ "/opt/entrypoint.sh" ]

# Specify the User that the actual main process will run as
USER ${spark_uid}