Using /Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home as default JAVA_HOME.
Note, this will be overridden by -java-home if it is set.
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0
[0m[[0minfo[0m] [0mLoading project definition from /Users/royl/git/spark/project/project[0m
[0m[[0minfo[0m] [0mLoading project definition from /Users/royl/.sbt/0.13/staging/ad8e8574a5bcb2d22d23/sbt-pom-reader/project[0m
[0m[[33mwarn[0m] [0mMultiple resolvers having different access mechanism configured with same name 'sbt-plugin-releases'. To avoid conflict, Remove duplicate project resolvers (`resolvers`) or rename publishing resolver (`publishTo`).[0m
[0m[[0minfo[0m] [0mLoading project definition from /Users/royl/git/spark/project[0m
[0m[[0minfo[0m] [0mSet current project to spark-parent (in build file:/Users/royl/git/spark/)[0m
[0m[[0minfo[0m] [0mANTLR: Grammar file 'org/apache/spark/sql/catalyst/parser/SparkSqlLexer.g' detected.[0m
[0m[[0minfo[0m] [0mANTLR: Grammar file 'org/apache/spark/sql/catalyst/parser/SparkSqlParser.g' detected.[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 894 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for test-tags/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 952 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for spark/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 151 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for unsafe/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 136 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-flume-sink/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 123 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for launcher/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 15 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for network-common/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 12 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for network-shuffle/test:testOnly[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/core/src/main/scala/org/apache/spark/SparkEnv.scala:99: value actorSystem in class SparkEnv is deprecated: Actor system is no longer supported as of 1.4.0[0m
[0m[[33mwarn[0m] [0m      actorSystem.shutdown()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala:124: method mapReduceTriplets in class Graph is deprecated: use aggregateMessages[0m
[0m[[33mwarn[0m] [0m    var messages = g.mapReduceTriplets(sendMsg, mergeMsg)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala:138: method mapReduceTriplets in class Graph is deprecated: use aggregateMessages[0m
[0m[[33mwarn[0m] [0m      messages = g.mapReduceTriplets([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/streaming/src/main/scala/org/apache/spark/streaming/receiver/ActorReceiver.scala:191: value actorSystem in class SparkEnv is deprecated: Actor system is no longer supported as of 1.4.0[0m
[0m[[33mwarn[0m] [0m  protected lazy val actorSupervisor = SparkEnv.get.actorSystem.actorOf(Props(new Supervisor),[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 21 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-mqtt-assembly/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 13 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0m[36mRun completed in 14 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for tools/test:testOnly[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-flume-assembly/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 12 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-kafka-assembly/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 76 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for core/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 35 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-twitter/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 68 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-flume/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 57 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-mqtt/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 42 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-zeromq/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 19 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for graphx/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 17 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-kafka/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 18 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming/test:testOnly[0m
[0m[[0minfo[0m] [0mCompiling 1 Scala source to /Users/royl/git/spark/mllib/target/scala-2.10/classes...[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 13 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for catalyst/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 14 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for sql/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 15 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for docker-integration-tests/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 20 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for hive/test:testOnly[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/PowerIterationClustering.scala:388: method setRuns in class KMeans is deprecated: Support for runs is deprecated. This param will have no effect in 2.0.0.[0m
[0m[[33mwarn[0m] [0m      .setRuns(5)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala:516: method setRuns in class KMeans is deprecated: Support for runs is deprecated. This param will have no effect in 2.0.0.[0m
[0m[[33mwarn[0m] [0m      .setRuns(runs)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala:541: method setRuns in class KMeans is deprecated: Support for runs is deprecated. This param will have no effect in 2.0.0.[0m
[0m[[33mwarn[0m] [0m      .setRuns(runs)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/mllib/src/main/scala/org/apache/spark/mllib/api/python/PythonMLLibAPI.scala:343: method setRuns in class KMeans is deprecated: Support for runs is deprecated. This param will have no effect in 2.0.0.[0m
[0m[[33mwarn[0m] [0m      .setRuns(runs)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 19 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for assembly/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 20 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for repl/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 16 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for examples/test:testOnly[0m
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128M; support was removed in 8.0
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=1g; support was removed in 8.0
[0m[[0minfo[0m] [0m[32mStreamingLinearRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- parameter accuracy (11 seconds, 789 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parameter convergence (1 second, 550 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- predictions (310 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- training and prediction (1 second, 316 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- handling empty RDDs in a stream (329 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mFPGrowthSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- FP-Growth using String type (214 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- FP-Growth String type association rule generation (94 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- FP-Growth using Int type (156 milliseconds)[0m[0m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[0m[[0minfo[0m] [0m[32m- model save/load with String type (2 seconds, 444 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load with Int type (312 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBinaryClassificationMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- binary evaluation metrics (169 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- binary evaluation metrics for RDD where all examples have positive label (95 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- binary evaluation metrics for RDD where all examples have negative label (96 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- binary evaluation metrics with downsampling (55 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLinearRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- linear regression (385 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- linear regression without intercept (386 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse linear regression without intercept (996 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (266 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLinearRegressionClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (4 seconds, 627 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mHashingTFSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- hashing tf on a single doc (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- hashing tf on an RDD (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPeriodicRDDCheckpointerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Persisting (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Checkpointing (150 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mKernelDensitySuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- kernel density single sample (32 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- kernel density multiple samples (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPrefixSpanSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan internal (integer seq, 0 delim) run, singleton itemsets (149 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan internal (integer seq, -1 delim) run, variable-size itemsets (36 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan projections with multiple partial starts (59 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan Integer type, variable-size itemsets (47 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan String type, variable-size itemsets (57 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mStreamingTestSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for null hypothesis using welch t-test (407 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for alternative hypothesis using welch t-test (277 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for null hypothesis using student t-test (282 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for alternative hypothesis using student t-test (284 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- batches within same test window are grouped (342 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- entries in peace period are dropped (10 seconds, 247 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- null hypothesis when only data from one group is present (265 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBinaryClassificationPMMLModelExportSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression PMML export (26 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- linear SVM PMML export (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mRidgeRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- ridge regression can help avoid overfitting (1 second, 778 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (163 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRidgeRegressionClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (4 seconds, 502 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGradientBoostedTreesSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression with continuous features: SquaredError (4 seconds, 179 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression with continuous features: Absolute Error (3 seconds, 728 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features: Log Loss (3 seconds, 804 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SPARK-5496: BoostingStrategy.defaultParams should recognize Classification (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (586 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- runWithValidation stops early and performs better on a validation dataset (8 seconds, 388 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Checkpointing (454 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMatrixFactorizationModelSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- constructor (48 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- save/load (402 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- batch predict API recommendProductsForUsers (65 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- batch predict API recommendUsersForProducts (27 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mWord2VecSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Word2Vec (109 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Word2Vec throws exception when vocabulary is empty (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Word2VecModel (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- model load / save (198 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- big model load / save (4 seconds, 384 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mTestingUtilsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Comparing doubles using relative error. (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Comparing doubles using absolute error. (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Comparing vectors using relative error. (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Comparing vectors using absolute error. (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMultivariateOnlineSummarizerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- basic error handing (24 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense vector input (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector input (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- mixing dense and sparse vector input (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- merging two summarizers (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- merging summarizer with empty summarizer (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- merging summarizer when one side has zero mean (SPARK-4355) (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- merging summarizer with weighted samples (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mChiSqSelectorSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- ChiSqSelector transform test (sparse & dense vector) (57 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model load / save (171 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRowMatrixSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- size (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- empty rows (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBreeze (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- gram (18 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- similar columns (111 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- svd of a full-rank matrix (640 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- svd of a low-rank matrix (36 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- validate k in svd (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- pca (100 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multiply a local matrix (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- compute column summary statistics (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- QR Decomposition (102 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- compute covariance (43 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- covariance matrix is symmetric (SPARK-10875) (27 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRowMatrixClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in svd (4 seconds, 805 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in summarize (204 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLassoSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Lasso local random SGD (453 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Lasso local random SGD with initial weights (444 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (145 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLassoClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (4 seconds, 503 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNaiveBayesSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- model types (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- get, set params (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- Naive Bayes Multinomial (176 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Naive Bayes Bernoulli (342 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- detect negative values (53 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- detect non zero or one values in Bernoulli (26 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load: 2.0 to 2.0 (353 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load: 1.0 to 2.0 (174 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNaiveBayesClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (3 seconds, 511 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLabeledPointSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- parse labeled points (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parse labeled points with whitespaces (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parse labeled points with v0.9 format (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMultilabelMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Multilabel evaluation metrics (112 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBreezeVectorConversionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- dense to breeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse to breeze (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense breeze to vector (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse breeze to vector (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse breeze with partially-used arrays to vector (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mDecisionTreeSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features: split and bin calculation (43 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with binary (ordered) categorical features: split and bin calculation (20 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with 3-ary (ordered) categorical features, with no samples for one category (17 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- extract categories from a number for multiclass classification (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- find splits for a continuous feature (271 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification with unordered categorical features: split and bin calculations (21 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification with ordered categorical features: split and bin calculations (31 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Avoid aggregation on the last level (43 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Avoid aggregation if impurity is 0.0 (36 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Second level node building with vs. without groups (182 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with ordered categorical features (61 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression stump with 3-ary (ordered) categorical features (52 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression stump with binary (ordered) categorical features (58 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with fixed label 0 for Gini (97 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with fixed label 1 for Gini (110 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with fixed label 0 for Entropy (88 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with fixed label 1 for Entropy (91 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with 3-ary (unordered) categorical features (93 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with 1 continuous feature, to check off-by-1 error (35 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with 2 continuous features (42 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with unordered categorical features, with just enough bins (89 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with continuous features (167 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with continuous + unordered categorical features (162 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with 10-ary (ordered) categorical features (110 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification tree with 10-ary (ordered) categorical features, with just enough bins (83 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- split must satisfy min instances per node requirements (39 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- do not choose split that does not satisfy min instance per node requirements (34 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- split must satisfy min info gain requirements (36 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Node.subtreeIterator (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (391 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mALSSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-1 matrices (750 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-1 matrices bulk (688 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices (690 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices bulk (794 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-1 matrices implicit (928 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-1 matrices implicit bulk (1 second, 12 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices implicit (904 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices implicit bulk (1 second, 119 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices implicit negative (901 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices with different user and product blocks (693 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pseudorandomness (342 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Storage Level for RDDs in model (203 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- negative ids (589 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- NNALS, rank 2 (653 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBaggedPointSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: without subsampling (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: with subsampling with replacement (fraction = 1.0) (109 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: with subsampling with replacement (fraction = 0.5) (72 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: with subsampling without replacement (fraction = 1.0) (62 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: with subsampling without replacement (fraction = 0.5) (57 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPMMLModelExportFactorySuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory create KMeansPMMLModelExport when passing a KMeansModel (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory create GeneralizedLinearPMMLModelExport when passing a LinearRegressionModel, RidgeRegressionModel or LassoModel (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory create BinaryClassificationPMMLModelExport when passing a LogisticRegressionModel or SVMModel (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory throw IllegalArgumentException when passing a Multinomial Logistic Regression (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory throw IllegalArgumentException when passing an unsupported model (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mRandomForestSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features: comparing DecisionTree vs. RandomForest(numTrees = 1) (601 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features and node Id cache : comparing DecisionTree vs. RandomForest(numTrees = 1) (649 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression with continuous features: comparing DecisionTree vs. RandomForest(numTrees = 1) (447 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression with continuous features and node Id cache : comparing DecisionTree vs. RandomForest(numTrees = 1) (461 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features: subsampling features (367 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features and node Id cache: subsampling features (344 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- alternating categorical and continuous features with multiclass labels to test indexing (50 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- subsampling rate in RandomForest (128 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (352 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mKMeansPMMLModelExportSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- KMeansPMMLModelExport generate PMML format (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRDDFunctionsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- sliding (1 second, 120 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sliding with empty partitions (12 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mKMeansSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster (1 second, 328 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- no distinct points (203 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- more clusters than points (194 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- deterministic initialization (967 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster with big dataset (1 second, 523 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster with sparse data (2 seconds, 160 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- k-means|| initialization (601 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- two clusters (324 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (340 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Initialize using given cluster centers (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mKMeansClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (10 seconds, 776 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mStandardScalerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with dense input when means and stds are provided (80 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with dense input (71 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with sparse input when means and stds are provided (33 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with sparse input (32 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with constant input when means and stds are provided (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with constant input (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- StandardScalerModel argument nulls are properly handled (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mStreamingLogisticRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- parameter accuracy (2 seconds, 325 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parameter convergence (2 seconds, 199 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- predictions (266 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- training and prediction (913 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- handling empty RDDs in a stream (309 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMultivariateGaussianSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- univariate (25 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multivariate (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multivariate degenerate (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SPARK-11302 (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mAssociationRulesSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- association rules using String type (34 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRandomDataGeneratorSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- UniformGenerator (32 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- StandardNormalGenerator (53 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LogNormalGenerator (257 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PoissonGenerator (2 seconds, 338 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- ExponentialGenerator (318 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- GammaGenerator (395 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- WeibullGenerator (596 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMLUtilsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- epsilon computation (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- fast squared distance (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadLibSVMFile (78 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadLibSVMFile throws IllegalArgumentException when indices is zero-based (21 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadLibSVMFile throws IllegalArgumentException when indices is not in ascending order (20 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- saveAsLibSVMFile (37 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- appendBias (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- kFold (3 seconds, 432 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadVectors (63 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadLabeledPoints (57 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- log1pExp (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBlockMatrixSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- size (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- grid partitioner (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toCoordinateMatrix (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toIndexedRowMatrix (28 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBreeze and toLocalMatrix (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- add (131 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multiply (232 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- simulate multiply (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- validate (116 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- transpose (25 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNNLSSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- NNLS: exact solution cases (20 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- NNLS: nonnegativity constraint active (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- NNLS: objective value test (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mMatricesSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- dense matrix construction (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense matrix construction with wrong dimension (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse matrix construction (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse matrix construction with wrong number of elements (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- index in matrices incorrect input (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- equals (20 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- matrix copies are deep copies (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- matrix indexing and updating (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toSparse, toDense (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- map, update (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- transpose (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- foreachActive (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- horzcat, vertcat, eye, speye (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- zeros (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- ones (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- eye (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rand (147 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- randn (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- diag (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sprand (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sprandn (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- MatrixUDT (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toString (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- numNonzeros and numActives (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mMLPairRDDFunctionsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- topByKey (12 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mIDFSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- idf (37 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- idf minimum document frequency filtering (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mIndexedRowMatrixSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- size (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- empty rows (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBreeze (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toRowMatrix (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toCoordinateMatrix (17 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBlockMatrix (30 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multiply a local matrix (26 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- gram (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- svd (40 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- validate matrix sizes of svd (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- validate k in svd (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- similar columns (30 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mCorrelationSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(x, y) pearson, 1 value in data (76 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(x, y) default, pearson (97 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(x, y) spearman (209 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(X) default, pearson (22 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(X) spearman (33 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- method identification (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mFPTreeSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- add transaction (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- merge tree (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- extract freq itemsets (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLogisticRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with SGD (678 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with LBFGS (692 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with initial weights with SGD (670 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with initial weights and non-default regularization parameter (519 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with initial weights with LBFGS (586 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- numerical stability of scaling features using logistic regression with LBFGS (3 seconds, 820 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multinomial logistic regression with LBFGS (29 seconds, 851 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load: binary classification (307 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load: multiclass classification (149 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLogisticRegressionClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction using SGD optimizer (4 seconds, 433 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction using LBFGS optimizer (2 seconds, 257 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBLASSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- copy (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- scal (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- axpy(a: Double, x: SparseVector, y: SparseVector) (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- axpy (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dot (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- spr (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- syr (5 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- gemm (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- gemv (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGeneralizedLinearPMMLModelExportSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- linear regression PMML export (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- ridge regression PMML export (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- lasso PMML export (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mAreaUnderCurveSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- auc computation (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- auc of an empty curve (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- auc of a curve with a single point (5 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPeriodicGraphCheckpointerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Persisting (73 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Checkpointing (399 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPowerIterationClusteringSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- power iteration clustering (610 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- power iteration clustering on graph (539 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- normalize and powerIter (103 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (176 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mIsotonicRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- increasing isotonic regression (34 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (177 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with size 0 (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with size 1 (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression strictly increasing sequence (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression strictly decreasing sequence (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with last element violating monotonicity (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with first element violating monotonicity (25 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with negative labels (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with unordered input (17 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- weighted isotonic regression (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- weighted isotonic regression with weights lower than 1 (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- weighted isotonic regression with negative weights (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- weighted isotonic regression with zero weights (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression prediction (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression prediction with duplicate features (19 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- antitonic regression prediction with duplicate features (24 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression RDD prediction (24 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- antitonic regression prediction (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model construction (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNumericParserSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- parser (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- parser with whitespaces (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mMulticlassMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass evaluation metrics (48 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRandomRDDsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- RandomRDD sizes (40 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- randomRDD for different distributions (1 second, 646 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- randomVectorRDD for different distributions (1 second, 768 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNormalizerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Normalization using L1 distance (19 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Normalization using L2 distance (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Normalization using L^Inf distance. (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBreezeMatrixConversionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- dense matrix to breeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense breeze matrix to matrix (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse matrix to breeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse breeze matrix to sparse matrix (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mCoordinateMatrixSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- size (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- empty entries (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBreeze (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- transpose (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toIndexedRowMatrix (23 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toRowMatrix (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBlockMatrix (20 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGradientDescentSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Assert the loss is decreasing. (645 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Test the loss and gradient of first iteration with regularization. (254 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- iteration should end with convergence tolerance (205 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGradientDescentClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small (4 seconds, 46 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mVectorsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- dense vector construction with varargs (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense vector construction from a double array (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector construction (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector construction with unordered elements (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector construction with mismatched indices/values array (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector construction with too many indices vs size (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense to array (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense argmax (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse to array (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse argmax (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- vector equals (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- vectors equals with explicit 0 (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- indexing dense vectors (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- indexing sparse vectors (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parse vectors (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- zeros (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- Vector.copy (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- VectorUDT (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- fromBreeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sqdist (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- foreachActive (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- vector p-norm (5 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Vector numActive and numNonzeros (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Vector toSparse and toDense (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Vector.compressed (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SparseVector.slice (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- toJson/fromJson (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPCASuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Correct computing use a PCA wrapper (46 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGaussianMixtureSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster (159 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- two clusters (23 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- two clusters with distributed decompositions (162 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster with sparse data (142 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- two clusters with sparse data (26 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save / load (272 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model prediction, parallel and local (81 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLBFGSSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- LBFGS loss should be decreasing and match the result of Gradient Descent. (3 seconds, 520 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LBFGS and Gradient Descent with L2 regularization should get the same result. (3 seconds, 349 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- The convergence criteria should work as we expect. (1 second, 298 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Optimize via class LBFGS. (3 seconds, 697 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLBFGSClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small (5 seconds, 981 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRegressionMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- regression metrics for unbiased (includes intercept term) predictor (17 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- regression metrics for biased (no intercept term) predictor (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- regression metrics with complete fitting (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mStreamingKMeansSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for single center and equivalence to grand average (439 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for two centers (381 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- detecting dying clusters (375 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SPARK-7946 setDecayFactor (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mPythonMLLibAPISuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle vector (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle labeled point (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle double (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle matrix (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle rating (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mSVMSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- SVM with threshold (1 second, 150 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SVM using local random SGD (869 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SVM local random SGD with initial weights (774 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SVM with invalid labels (6 seconds, 138 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (302 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mSVMClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (4 seconds, 352 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBisectingKMeansSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- default values (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- setter/getter (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- 1D data (94 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- points are the same (27 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- more desired clusters than points (79 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- min divisible cluster (95 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- larger clusters get selected first (53 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- 2D data (119 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLDASuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- LocalLDAModel (12 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- running and DistributedLDAModel with default Optimizer (EM) (359 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- vertex indexing (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- setter alias (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- initializing with alpha length != k or 1 fails (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- initializing with elements in alpha < 0 fails (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer initialization (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer one iteration (51 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer with toy data (1 second, 334 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LocalLDAModel logLikelihood (22 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LocalLDAModel logPerplexity (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LocalLDAModel predict (30 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer with asymmetric prior (1 second, 311 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer alpha hyperparameter optimization (1 second, 219 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (824 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- EMLDAOptimizer with empty docs (124 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer with empty docs (47 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mImpuritySuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Gini impurity does not support negative labels (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- Entropy does not support negative labels (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mElementwiseProductSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- elementwise (hadamard) product should properly apply vector to dense data set (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- elementwise (hadamard) product should properly apply vector to sparse data set (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mHypothesisTestSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- chi squared pearson goodness of fit (5 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- chi squared pearson matrix independence (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- chi squared pearson RDD[LabeledPoint] (1 second, 719 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- 1 sample Kolmogorov-Smirnov test: apache commons math3 implementation equivalence (2 seconds, 376 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- 1 sample Kolmogorov-Smirnov test: R implementation equivalence (33 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRankingMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Ranking metrics: map, ndcg (63 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaNaiveBayesSuite[0m.[36mtestPredictJavaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaNaiveBayesSuite[0m.[36mrunUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaNaiveBayesSuite[0m.[36mrunUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaNaiveBayesSuite[0m.[36mtestModelTypeSetters[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 4 total, 0.228s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaStreamingLogisticRegressionSuite[0m.[36mjavaAPI[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.294s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.fpm.[33mJavaFPGrowthSuite[0m.[36mrunFPGrowthSaveLoad[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.fpm.[33mJavaFPGrowthSuite[0m.[36mrunFPGrowth[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.317s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.fpm.[33mJavaPrefixSpanSuite[0m.[36mrunPrefixSpan[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.09s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaStreamingKMeansSuite[0m.[36mjavaAPI[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.216s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLinearRegressionSuite[0m.[36mtestPredictJavaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLinearRegressionSuite[0m.[36mrunLinearRegressionUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLinearRegressionSuite[0m.[36mrunLinearRegressionUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 3 total, 1.098s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaLogisticRegressionSuite[0m.[36mrunLRUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaLogisticRegressionSuite[0m.[36mrunLRUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 5.957s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaGaussianMixtureSuite[0m.[36mrunGaussianMixture[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.061s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaStreamingLinearRegressionSuite[0m.[36mjavaAPI[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.263s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaKMeansSuite[0m.[36mtestPredictJavaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaKMeansSuite[0m.[36mrunKMeansUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaKMeansSuite[0m.[36mrunKMeansUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 3 total, 0.506s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.feature.[33mJavaTfIdfSuite[0m.[36mtfIdfMinimumDocumentFrequency[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.feature.[33mJavaTfIdfSuite[0m.[36mtfIdf[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.757s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.stat.[33mJavaStatisticsSuite[0m.[36mtestCorr[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.stat.[33mJavaStatisticsSuite[0m.[36mchiSqTest[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.stat.[33mJavaStatisticsSuite[0m.[36mstreamingTest[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.stat.[33mJavaStatisticsSuite[0m.[36mkolmogorovSmirnovTest[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 4 total, 0.411s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaIsotonicRegressionSuite[0m.[36mtestIsotonicRegressionJavaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaIsotonicRegressionSuite[0m.[36mtestIsotonicRegressionPredictionsJavaRDD[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.134s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunALSUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunImplicitALSUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunRecommend[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunImplicitALSWithNegativeWeight[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunImplicitALSUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunALSUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 6 total, 5.458s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestNormalVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestArbitrary[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestLogNormalVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestExponentialVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestUniformRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestRandomVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestGammaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestUniformVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestPoissonRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestNormalRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestPoissonVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestGammaVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestExponentialRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestLNormalRDD[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 14 total, 0.731s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.tree.[33mJavaDecisionTreeSuite[0m.[36mrunDTUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.tree.[33mJavaDecisionTreeSuite[0m.[36mrunDTUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.209s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaVectorsSuite[0m.[36mdenseArrayConstruction[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaVectorsSuite[0m.[36msparseArrayConstruction[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.001s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaLDASuite[0m.[36monlineOptimizerCompatibility[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaLDASuite[0m.[36mdistributedLDAModel[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaLDASuite[0m.[36mlocalLDAModel[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaLDASuite[0m.[36mlocalLdaMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 4 total, 0.506s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaRidgeRegressionSuite[0m.[36mrunRidgeRegressionUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaRidgeRegressionSuite[0m.[36mrunRidgeRegressionUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 3.119s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaSVMSuite[0m.[36mrunSVMUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaSVMSuite[0m.[36mrunSVMUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 1.846s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.feature.[33mJavaWord2VecSuite[0m.[36mword2Vec[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.092s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.evaluation.[33mJavaRankingMetricsSuite[0m.[36mrankingMetrics[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.043s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.fpm.[33mJavaAssociationRulesSuite[0m.[36mrunAssociationRules[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.039s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36mzerosMatrixConstruction[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36midentityMatrixConstruction[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36mconcatenateMatrices[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36msparseDenseConversion[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36mrandMatrixConstruction[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36mdiagonalMatrixConstruction[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 6 total, 0.004s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLassoSuite[0m.[36mrunLassoUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLassoSuite[0m.[36mrunLassoUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 4.53s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaBisectingKMeansSuite[0m.[36mtwoDimensionalData[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.113s[0m[0m
-- org.jblas INFO Deleting /Users/royl/git/spark/target/tmp/jblas4558071759314704620/libjblas.dylib
-- org.jblas INFO Deleting /Users/royl/git/spark/target/tmp/jblas4558071759314704620/libjblas_arch_flavor.dylib
-- org.jblas INFO Deleting /Users/royl/git/spark/target/tmp/jblas4558071759314704620
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 4 minutes, 32 seconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 452[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 83, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 452, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[32mAll tests passed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 523, Failed 0, Errors 0, Passed 523[0m
[0m[[32msuccess[0m] [0mTotal time: 286 s, completed Jan 15, 2016 2:42:10 PM[0m
