Using /Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home as default JAVA_HOME.
Note, this will be overridden by -java-home if it is set.
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0
[0m[[0minfo[0m] [0mLoading project definition from /Users/royl/git/spark/project/project[0m
[0m[[0minfo[0m] [0mLoading project definition from /Users/royl/.sbt/0.13/staging/ad8e8574a5bcb2d22d23/sbt-pom-reader/project[0m
[0m[[33mwarn[0m] [0mMultiple resolvers having different access mechanism configured with same name 'sbt-plugin-releases'. To avoid conflict, Remove duplicate project resolvers (`resolvers`) or rename publishing resolver (`publishTo`).[0m
[0m[[0minfo[0m] [0mLoading project definition from /Users/royl/git/spark/project[0m
[0m[[0minfo[0m] [0mSet current project to spark-parent (in build file:/Users/royl/git/spark/)[0m
[0m[[0minfo[0m] [0mANTLR: Grammar file 'org/apache/spark/sql/catalyst/parser/SparkSqlLexer.g' detected.[0m
[0m[[0minfo[0m] [0mANTLR: Grammar file 'org/apache/spark/sql/catalyst/parser/SparkSqlParser.g' detected.[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 1 second, 192 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0m[36mRun completed in 1 second, 217 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for test-tags/test:testOnly[0m
[0m[[0minfo[0m] [0mNo tests to run for spark/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 34 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0m[36mRun completed in 35 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for launcher/test:testOnly[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for unsafe/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 21 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-flume-sink/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 15 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for network-common/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 14 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for network-shuffle/test:testOnly[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/core/src/main/scala/org/apache/spark/SparkEnv.scala:99: value actorSystem in class SparkEnv is deprecated: Actor system is no longer supported as of 1.4.0[0m
[0m[[33mwarn[0m] [0m      actorSystem.shutdown()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala:124: method mapReduceTriplets in class Graph is deprecated: use aggregateMessages[0m
[0m[[33mwarn[0m] [0m    var messages = g.mapReduceTriplets(sendMsg, mergeMsg)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala:138: method mapReduceTriplets in class Graph is deprecated: use aggregateMessages[0m
[0m[[33mwarn[0m] [0m      messages = g.mapReduceTriplets([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/streaming/src/main/scala/org/apache/spark/streaming/receiver/ActorReceiver.scala:191: value actorSystem in class SparkEnv is deprecated: Actor system is no longer supported as of 1.4.0[0m
[0m[[33mwarn[0m] [0m  protected lazy val actorSupervisor = SparkEnv.get.actorSystem.actorOf(Props(new Supervisor),[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 13 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-flume-assembly/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 16 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-mqtt-assembly/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 19 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for tools/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 13 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-kafka-assembly/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 30 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-zeromq/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 39 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for core/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 76 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-mqtt/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 107 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-twitter/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 116 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-flume/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 44 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming-kafka/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 18 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for streaming/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 19 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for graphx/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 12 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for catalyst/test:testOnly[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/PowerIterationClustering.scala:388: method setRuns in class KMeans is deprecated: Support for runs is deprecated. This param will have no effect in 2.0.0.[0m
[0m[[33mwarn[0m] [0m      .setRuns(5)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala:516: method setRuns in class KMeans is deprecated: Support for runs is deprecated. This param will have no effect in 2.0.0.[0m
[0m[[33mwarn[0m] [0m      .setRuns(runs)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala:541: method setRuns in class KMeans is deprecated: Support for runs is deprecated. This param will have no effect in 2.0.0.[0m
[0m[[33mwarn[0m] [0m      .setRuns(runs)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/royl/git/spark/mllib/src/main/scala/org/apache/spark/mllib/api/python/PythonMLLibAPI.scala:343: method setRuns in class KMeans is deprecated: Support for runs is deprecated. This param will have no effect in 2.0.0.[0m
[0m[[33mwarn[0m] [0m      .setRuns(runs)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 12 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for assembly/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 16 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for repl/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 16 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for sql/test:testOnly[0m
[0m[[0minfo[0m] [0mCompiling 1 Scala source to /Users/royl/git/spark/mllib/target/scala-2.10/test-classes...[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 13 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for docker-integration-tests/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 14 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for examples/test:testOnly[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 16 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 0[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 0, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[33mNo tests were executed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 0, Failed 0, Errors 0, Passed 0[0m
[0m[[0minfo[0m] [0mNo tests to run for hive/test:testOnly[0m
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128M; support was removed in 8.0
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=1g; support was removed in 8.0
[0m[[0minfo[0m] [0m[32mStreamingLinearRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- parameter accuracy (11 seconds, 163 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parameter convergence (1 second, 623 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- predictions (10 seconds, 299 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- training and prediction (1 second, 361 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- handling empty RDDs in a stream (375 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mFPGrowthSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- FP-Growth using String type (238 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- FP-Growth String type association rule generation (110 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- FP-Growth using Int type (163 milliseconds)[0m[0m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[0m[[0minfo[0m] [0m[32m- model save/load with String type (2 seconds, 412 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load with Int type (316 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBinaryClassificationMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- binary evaluation metrics (177 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- binary evaluation metrics for RDD where all examples have positive label (108 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- binary evaluation metrics for RDD where all examples have negative label (95 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- binary evaluation metrics with downsampling (53 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLinearRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- linear regression (405 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- linear regression without intercept (356 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse linear regression without intercept (1 second, 61 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (276 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLinearRegressionClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (5 seconds, 543 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mHashingTFSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- hashing tf on a single doc (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- hashing tf on an RDD (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPeriodicRDDCheckpointerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Persisting (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Checkpointing (155 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mKernelDensitySuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- kernel density single sample (28 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- kernel density multiple samples (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPrefixSpanSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan internal (integer seq, 0 delim) run, singleton itemsets (152 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan internal (integer seq, -1 delim) run, variable-size itemsets (34 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan projections with multiple partial starts (62 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan Integer type, variable-size itemsets (55 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PrefixSpan String type, variable-size itemsets (46 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mStreamingTestSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for null hypothesis using welch t-test (405 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for alternative hypothesis using welch t-test (277 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for null hypothesis using student t-test (285 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for alternative hypothesis using student t-test (271 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- batches within same test window are grouped (339 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- entries in peace period are dropped (10 seconds, 279 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- null hypothesis when only data from one group is present (277 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBinaryClassificationPMMLModelExportSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression PMML export (24 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- linear SVM PMML export (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mRidgeRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- ridge regression can help avoid overfitting (2 seconds, 155 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (199 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRidgeRegressionClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (5 seconds, 428 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGradientBoostedTreesSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression with continuous features: SquaredError (4 seconds, 174 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression with continuous features: Absolute Error (3 seconds, 676 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features: Log Loss (3 seconds, 829 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SPARK-5496: BoostingStrategy.defaultParams should recognize Classification (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (51 minutes, 44 seconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- runWithValidation stops early and performs better on a validation dataset (10 seconds, 620 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Checkpointing (474 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMatrixFactorizationModelSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- constructor (50 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- save/load (420 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- batch predict API recommendProductsForUsers (66 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- batch predict API recommendUsersForProducts (30 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mWord2VecSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Word2Vec (176 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Word2Vec throws exception when vocabulary is empty (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Word2VecModel (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model load / save (233 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- big model load / save (4 seconds, 683 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mTestingUtilsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Comparing doubles using relative error. (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Comparing doubles using absolute error. (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- Comparing vectors using relative error. (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Comparing vectors using absolute error. (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMultivariateOnlineSummarizerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- basic error handing (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense vector input (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector input (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- mixing dense and sparse vector input (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- merging two summarizers (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- merging summarizer with empty summarizer (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- merging summarizer when one side has zero mean (SPARK-4355) (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- merging summarizer with weighted samples (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mChiSqSelectorSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- ChiSqSelector transform test (sparse & dense vector) (69 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model load / save (199 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRowMatrixSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- size (19 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- empty rows (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBreeze (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- gram (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- similar columns (125 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- svd of a full-rank matrix (729 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- svd of a low-rank matrix (49 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- validate k in svd (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pca (106 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multiply a local matrix (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- compute column summary statistics (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- QR Decomposition (114 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- compute covariance (48 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- covariance matrix is symmetric (SPARK-10875) (29 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRowMatrixClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in svd (5 seconds, 792 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in summarize (232 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLassoSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Lasso local random SGD (716 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Lasso local random SGD with initial weights (458 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (201 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLassoClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (5 seconds, 104 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNaiveBayesSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- model types (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- get, set params (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Naive Bayes Multinomial (200 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Naive Bayes Bernoulli (395 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- detect negative values (55 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- detect non zero or one values in Bernoulli (26 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load: 2.0 to 2.0 (373 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load: 1.0 to 2.0 (187 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNaiveBayesClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (3 seconds, 766 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLabeledPointSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- parse labeled points (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parse labeled points with whitespaces (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parse labeled points with v0.9 format (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mMultilabelMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Multilabel evaluation metrics (108 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBreezeVectorConversionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- dense to breeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse to breeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense breeze to vector (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse breeze to vector (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse breeze with partially-used arrays to vector (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mDecisionTreeSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features: split and bin calculation (50 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with binary (ordered) categorical features: split and bin calculation (20 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with 3-ary (ordered) categorical features, with no samples for one category (18 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- extract categories from a number for multiclass classification (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- find splits for a continuous feature (284 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification with unordered categorical features: split and bin calculations (21 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification with ordered categorical features: split and bin calculations (34 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Avoid aggregation on the last level (48 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Avoid aggregation if impurity is 0.0 (37 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Second level node building with vs. without groups (180 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with ordered categorical features (59 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression stump with 3-ary (ordered) categorical features (51 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression stump with binary (ordered) categorical features (56 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with fixed label 0 for Gini (101 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with fixed label 1 for Gini (95 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with fixed label 0 for Entropy (89 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with fixed label 1 for Entropy (97 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with 3-ary (unordered) categorical features (97 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with 1 continuous feature, to check off-by-1 error (44 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification stump with 2 continuous features (34 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with unordered categorical features, with just enough bins (88 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with continuous features (168 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with continuous + unordered categorical features (165 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification stump with 10-ary (ordered) categorical features (121 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass classification tree with 10-ary (ordered) categorical features, with just enough bins (86 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- split must satisfy min instances per node requirements (46 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- do not choose split that does not satisfy min instance per node requirements (46 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- split must satisfy min info gain requirements (42 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Node.subtreeIterator (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (381 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mALSSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-1 matrices (796 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-1 matrices bulk (785 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices (667 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices bulk (824 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-1 matrices implicit (897 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-1 matrices implicit bulk (1 second, 7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices implicit (908 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices implicit bulk (1 second, 168 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices implicit negative (905 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rank-2 matrices with different user and product blocks (695 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pseudorandomness (313 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Storage Level for RDDs in model (196 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- negative ids (656 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- NNALS, rank 2 (650 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBaggedPointSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: without subsampling (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: with subsampling with replacement (fraction = 1.0) (100 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: with subsampling with replacement (fraction = 0.5) (80 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: with subsampling without replacement (fraction = 1.0) (54 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- BaggedPoint RDD: with subsampling without replacement (fraction = 0.5) (63 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPMMLModelExportFactorySuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory create KMeansPMMLModelExport when passing a KMeansModel (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory create GeneralizedLinearPMMLModelExport when passing a LinearRegressionModel, RidgeRegressionModel or LassoModel (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory create BinaryClassificationPMMLModelExport when passing a LogisticRegressionModel or SVMModel (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory throw IllegalArgumentException when passing a Multinomial Logistic Regression (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- PMMLModelExportFactory throw IllegalArgumentException when passing an unsupported model (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mRandomForestSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features: comparing DecisionTree vs. RandomForest(numTrees = 1) (625 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features and node Id cache : comparing DecisionTree vs. RandomForest(numTrees = 1) (642 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression with continuous features: comparing DecisionTree vs. RandomForest(numTrees = 1) (434 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Regression with continuous features and node Id cache : comparing DecisionTree vs. RandomForest(numTrees = 1) (457 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features: subsampling features (337 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Binary classification with continuous features and node Id cache: subsampling features (345 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- alternating categorical and continuous features with multiclass labels to test indexing (53 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- subsampling rate in RandomForest (126 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (382 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mKMeansPMMLModelExportSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- KMeansPMMLModelExport generate PMML format (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mRDDFunctionsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- sliding (1 second, 204 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sliding with empty partitions (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mKMeansSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster (815 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- no distinct points (110 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- more clusters than points (101 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- deterministic initialization (488 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster with big dataset (766 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster with sparse data (1 second, 161 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- k-means|| initialization (331 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- two clusters (198 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (399 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Initialize using given cluster centers (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mKMeansClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (7 seconds, 238 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mStandardScalerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with dense input when means and stds are provided (89 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with dense input (64 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with sparse input when means and stds are provided (37 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with sparse input (30 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with constant input when means and stds are provided (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Standardization with constant input (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- StandardScalerModel argument nulls are properly handled (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mStreamingLogisticRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- parameter accuracy (2 seconds, 331 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parameter convergence (2 seconds, 263 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- predictions (276 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- training and prediction (903 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- handling empty RDDs in a stream (320 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMultivariateGaussianSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- univariate (26 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multivariate (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multivariate degenerate (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- SPARK-11302 (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mAssociationRulesSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- association rules using String type (39 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRandomDataGeneratorSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- UniformGenerator (33 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- StandardNormalGenerator (49 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LogNormalGenerator (265 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- PoissonGenerator (2 seconds, 296 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- ExponentialGenerator (274 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- GammaGenerator (403 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- WeibullGenerator (625 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMLUtilsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- epsilon computation (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- fast squared distance (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadLibSVMFile (74 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadLibSVMFile throws IllegalArgumentException when indices is zero-based (21 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadLibSVMFile throws IllegalArgumentException when indices is not in ascending order (19 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- saveAsLibSVMFile (38 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- appendBias (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- kFold (3 seconds, 508 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadVectors (63 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- loadLabeledPoints (58 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- log1pExp (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBlockMatrixSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- size (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- grid partitioner (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toCoordinateMatrix (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toIndexedRowMatrix (27 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBreeze and toLocalMatrix (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- add (141 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multiply (226 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- simulate multiply (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- validate (111 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- transpose (27 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNNLSSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- NNLS: exact solution cases (21 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- NNLS: nonnegativity constraint active (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- NNLS: objective value test (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMatricesSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- dense matrix construction (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense matrix construction with wrong dimension (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse matrix construction (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse matrix construction with wrong number of elements (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- index in matrices incorrect input (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- equals (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- matrix copies are deep copies (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- matrix indexing and updating (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- toSparse, toDense (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- map, update (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- transpose (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- foreachActive (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- horzcat, vertcat, eye, speye (12 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- zeros (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- ones (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- eye (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- rand (125 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- randn (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- diag (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- sprand (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sprandn (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- MatrixUDT (5 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toString (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- numNonzeros and numActives (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mMLPairRDDFunctionsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- topByKey (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mIDFSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- idf (25 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- idf minimum document frequency filtering (23 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mIndexedRowMatrixSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- size (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- empty rows (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBreeze (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toRowMatrix (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toCoordinateMatrix (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBlockMatrix (30 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multiply a local matrix (31 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- gram (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- svd (35 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- validate matrix sizes of svd (16 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- validate k in svd (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- similar columns (28 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mCorrelationSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(x, y) pearson, 1 value in data (79 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(x, y) default, pearson (98 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(x, y) spearman (214 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(X) default, pearson (22 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- corr(X) spearman (33 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- method identification (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mFPTreeSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- add transaction (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- merge tree (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- extract freq itemsets (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mLogisticRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with SGD (639 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with LBFGS (681 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with initial weights with SGD (696 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with initial weights and non-default regularization parameter (497 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- logistic regression with initial weights with LBFGS (595 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- numerical stability of scaling features using logistic regression with LBFGS (3 seconds, 650 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- multinomial logistic regression with LBFGS (28 seconds, 980 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load: binary classification (301 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load: multiclass classification (136 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLogisticRegressionClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction using SGD optimizer (4 seconds, 493 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction using LBFGS optimizer (2 seconds, 222 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBLASSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- copy (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- scal (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- unitedIndices (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- axpy (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dot (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- spr (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- syr (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- gemm (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- gemv (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGeneralizedLinearPMMLModelExportSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- linear regression PMML export (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- ridge regression PMML export (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- lasso PMML export (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mAreaUnderCurveSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- auc computation (12 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- auc of an empty curve (5 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- auc of a curve with a single point (5 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPeriodicGraphCheckpointerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Persisting (94 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Checkpointing (427 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPowerIterationClusteringSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- power iteration clustering (600 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- power iteration clustering on graph (518 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- normalize and powerIter (93 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (182 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mIsotonicRegressionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- increasing isotonic regression (41 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (184 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with size 0 (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with size 1 (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression strictly increasing sequence (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression strictly decreasing sequence (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with last element violating monotonicity (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with first element violating monotonicity (23 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with negative labels (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression with unordered input (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- weighted isotonic regression (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- weighted isotonic regression with weights lower than 1 (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- weighted isotonic regression with negative weights (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- weighted isotonic regression with zero weights (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression prediction (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression prediction with duplicate features (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- antitonic regression prediction with duplicate features (17 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- isotonic regression RDD prediction (27 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- antitonic regression prediction (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model construction (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNumericParserSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- parser (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parser with whitespaces (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mMulticlassMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Multiclass evaluation metrics (52 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRandomRDDsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- RandomRDD sizes (40 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- randomRDD for different distributions (1 second, 551 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- randomVectorRDD for different distributions (1 second, 763 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mNormalizerSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Normalization using L1 distance (19 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Normalization using L2 distance (12 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Normalization using L^Inf distance. (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBreezeMatrixConversionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- dense matrix to breeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense breeze matrix to matrix (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse matrix to breeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse breeze matrix to sparse matrix (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mCoordinateMatrixSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- size (8 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- empty entries (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBreeze (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- transpose (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toIndexedRowMatrix (14 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toRowMatrix (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- toBlockMatrix (26 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGradientDescentSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Assert the loss is decreasing. (641 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Test the loss and gradient of first iteration with regularization. (231 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- iteration should end with convergence tolerance (180 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGradientDescentClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small (4 seconds, 162 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mVectorsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- dense vector construction with varargs (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense vector construction from a double array (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector construction (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector construction with unordered elements (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector construction with mismatched indices/values array (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse vector construction with too many indices vs size (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense to array (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- dense argmax (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse to array (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sparse argmax (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- vector equals (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- vectors equals with explicit 0 (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- indexing dense vectors (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- indexing sparse vectors (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- parse vectors (3 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- zeros (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Vector.copy (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- VectorUDT (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- fromBreeze (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sqdist (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- foreachActive (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- vector p-norm (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Vector numActive and numNonzeros (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- Vector toSparse and toDense (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- Vector.compressed (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SparseVector.slice (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- toJson/fromJson (7 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mPCASuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Correct computing use a PCA wrapper (47 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mGaussianMixtureSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster (157 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- two clusters (28 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- two clusters with distributed decompositions (165 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- single cluster with sparse data (140 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- two clusters with sparse data (21 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save / load (265 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model prediction, parallel and local (86 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLBFGSSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- LBFGS loss should be decreasing and match the result of Gradient Descent. (3 seconds, 298 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LBFGS and Gradient Descent with L2 regularization should get the same result. (3 seconds, 205 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- The convergence criteria should work as we expect. (1 second, 193 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- Optimize via class LBFGS. (3 seconds, 361 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLBFGSClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small (5 seconds, 968 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRegressionMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- regression metrics for unbiased (includes intercept term) predictor (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- regression metrics for biased (no intercept term) predictor (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- regression metrics with complete fitting (6 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mStreamingKMeansSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for single center and equivalence to grand average (408 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- accuracy for two centers (386 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- detecting dying clusters (474 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SPARK-7946 setDecayFactor (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mPythonMLLibAPISuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle vector (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle labeled point (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle double (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle matrix (0 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- pickle rating (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mSVMSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- SVM with threshold (1 second, 12 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SVM using local random SGD (904 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SVM local random SGD with initial weights (818 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- SVM with invalid labels (5 seconds, 920 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (291 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mSVMClusterSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- task size should be small in both training and prediction (4 seconds, 401 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mBisectingKMeansSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- default values (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- setter/getter (4 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- 1D data (112 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- points are the same (18 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- more desired clusters than points (76 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- min divisible cluster (98 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- larger clusters get selected first (43 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- 2D data (129 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mLDASuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- LocalLDAModel (11 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- running and DistributedLDAModel with default Optimizer (EM) (347 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- vertex indexing (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- setter alias (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- initializing with alpha length != k or 1 fails (2 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- initializing with elements in alpha < 0 fails (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer initialization (15 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer one iteration (42 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer with toy data (1 second, 397 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LocalLDAModel logLikelihood (20 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LocalLDAModel logPerplexity (10 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- LocalLDAModel predict (30 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer with asymmetric prior (1 second, 290 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer alpha hyperparameter optimization (1 second, 222 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- model save/load (796 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- EMLDAOptimizer with empty docs (117 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- OnlineLDAOptimizer with empty docs (55 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mImpuritySuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Gini impurity does not support negative labels (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- Entropy does not support negative labels (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32mElementwiseProductSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- elementwise (hadamard) product should properly apply vector to dense data set (9 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- elementwise (hadamard) product should properly apply vector to sparse data set (13 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mHypothesisTestSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- chi squared pearson goodness of fit (5 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- chi squared pearson matrix independence (1 millisecond)[0m[0m
[0m[[0minfo[0m] [0m[32m- chi squared pearson RDD[LabeledPoint] (1 second, 654 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- 1 sample Kolmogorov-Smirnov test: apache commons math3 implementation equivalence (2 seconds, 424 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- 1 sample Kolmogorov-Smirnov test: R implementation equivalence (33 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32mRankingMetricsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- Ranking metrics: map, ndcg (64 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaNaiveBayesSuite[0m.[36mtestPredictJavaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaNaiveBayesSuite[0m.[36mrunUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaNaiveBayesSuite[0m.[36mrunUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaNaiveBayesSuite[0m.[36mtestModelTypeSetters[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 4 total, 0.21s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaStreamingLogisticRegressionSuite[0m.[36mjavaAPI[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.296s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.fpm.[33mJavaFPGrowthSuite[0m.[36mrunFPGrowthSaveLoad[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.fpm.[33mJavaFPGrowthSuite[0m.[36mrunFPGrowth[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.321s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.fpm.[33mJavaPrefixSpanSuite[0m.[36mrunPrefixSpan[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.11s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaStreamingKMeansSuite[0m.[36mjavaAPI[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.224s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLinearRegressionSuite[0m.[36mtestPredictJavaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLinearRegressionSuite[0m.[36mrunLinearRegressionUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLinearRegressionSuite[0m.[36mrunLinearRegressionUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 3 total, 1.116s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaLogisticRegressionSuite[0m.[36mrunLRUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaLogisticRegressionSuite[0m.[36mrunLRUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 5.793s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaGaussianMixtureSuite[0m.[36mrunGaussianMixture[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.059s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaStreamingLinearRegressionSuite[0m.[36mjavaAPI[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.273s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaKMeansSuite[0m.[36mtestPredictJavaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaKMeansSuite[0m.[36mrunKMeansUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaKMeansSuite[0m.[36mrunKMeansUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 3 total, 0.501s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.feature.[33mJavaTfIdfSuite[0m.[36mtfIdfMinimumDocumentFrequency[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.feature.[33mJavaTfIdfSuite[0m.[36mtfIdf[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.763s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.stat.[33mJavaStatisticsSuite[0m.[36mtestCorr[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.stat.[33mJavaStatisticsSuite[0m.[36mchiSqTest[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.stat.[33mJavaStatisticsSuite[0m.[36mstreamingTest[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.stat.[33mJavaStatisticsSuite[0m.[36mkolmogorovSmirnovTest[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 4 total, 0.435s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaIsotonicRegressionSuite[0m.[36mtestIsotonicRegressionJavaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaIsotonicRegressionSuite[0m.[36mtestIsotonicRegressionPredictionsJavaRDD[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.125s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunALSUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunImplicitALSUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunRecommend[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunImplicitALSWithNegativeWeight[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunImplicitALSUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.recommendation.[33mJavaALSSuite[0m.[36mrunALSUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 6 total, 5.56s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestNormalVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestArbitrary[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestLogNormalVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestExponentialVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestUniformRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestRandomVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestGammaRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestUniformVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestPoissonRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestNormalRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestPoissonVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestGammaVectorRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestExponentialRDD[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.random.[33mJavaRandomRDDsSuite[0m.[36mtestLNormalRDD[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 14 total, 0.768s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.tree.[33mJavaDecisionTreeSuite[0m.[36mrunDTUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.tree.[33mJavaDecisionTreeSuite[0m.[36mrunDTUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.224s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaVectorsSuite[0m.[36mdenseArrayConstruction[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaVectorsSuite[0m.[36msparseArrayConstruction[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.001s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaLDASuite[0m.[36monlineOptimizerCompatibility[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaLDASuite[0m.[36mdistributedLDAModel[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaLDASuite[0m.[36mlocalLDAModel[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaLDASuite[0m.[36mlocalLdaMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 4 total, 0.532s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaRidgeRegressionSuite[0m.[36mrunRidgeRegressionUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaRidgeRegressionSuite[0m.[36mrunRidgeRegressionUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 3.217s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaSVMSuite[0m.[36mrunSVMUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.classification.[33mJavaSVMSuite[0m.[36mrunSVMUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 1.959s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.feature.[33mJavaWord2VecSuite[0m.[36mword2Vec[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.093s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.evaluation.[33mJavaRankingMetricsSuite[0m.[36mrankingMetrics[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.043s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.fpm.[33mJavaAssociationRulesSuite[0m.[36mrunAssociationRules[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.035s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36mzerosMatrixConstruction[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36midentityMatrixConstruction[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36mconcatenateMatrices[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36msparseDenseConversion[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36mrandMatrixConstruction[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.linalg.[33mJavaMatricesSuite[0m.[36mdiagonalMatrixConstruction[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 6 total, 0.004s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLassoSuite[0m.[36mrunLassoUsingConstructor[0m started[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.regression.[33mJavaLassoSuite[0m.[36mrunLassoUsingStaticMethods[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 4.676s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest org.apache.spark.mllib.clustering.[33mJavaBisectingKMeansSuite[0m.[36mtwoDimensionalData[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 0.124s[0m[0m
-- org.jblas INFO Deleting /Users/royl/git/spark/target/tmp/jblas3179948738685033231/libjblas.dylib
-- org.jblas INFO Deleting /Users/royl/git/spark/target/tmp/jblas3179948738685033231/libjblas_arch_flavor.dylib
-- org.jblas INFO Deleting /Users/royl/git/spark/target/tmp/jblas3179948738685033231
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 56 minutes, 25 seconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 452[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 83, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 452, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[32mAll tests passed.[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 523, Failed 0, Errors 0, Passed 523[0m
[0m[[32msuccess[0m] [0mTotal time: 3402 s, completed Jan 13, 2016 9:51:42 AM[0m
